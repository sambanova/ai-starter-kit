asr:
  datasets:
    datasets_path: ./data/datasets
    dataset_name: PCA_dataset
    dataset_description: Dataset for Post Call Analysis AISK
    dataset_source_file: ./data/datasets/source.json
    dataset_source_type: localMachine
    dataset_language: english
    
  apps:
    asr_with_diarization_app_id: b6aefdf7-02a4-4384-9c3c-8a81d735a54e
    application_field: language

  urls:
    base_url: https://your.sambastrudio.environment.com
    datasets_url: /api/datasets
    projects_url: /api/projects
    jobs_url: /{project_id}/jobs
    download_results_url: /results/download
    
  projects:
    project_name: PCA_Project
    project_description: This project will process ASR with diarization jobs regarding Post Call Analysis AISK.
  
  jobs:
    job_name: PCA job pipeline
    job_description: PCA - ASR with diarization and batch prediction
    job_task: ASR With Diarization
    job_type: batch_predict
    model_checkpoint: Diarization_ASR_Pipeline_V2

  output:
    output_path: results/output.csv

llm: 
    "api": "sambastudio" # set either sambastudio or sambaverse
    "temperature": 0.06
    "max_tokens_to_generate": 500
    "sambaverse_model_name": "Meta/Meta-Llama-3-8B-Instruct"
    "coe": True #set as true if using Sambastudio CoE endpoint
    "select_expert": "Meta-Llama-3-8B-Instruct" #set if using Sambaverse or SambaStudio CoE llm expert

embedding_model: 
    "type": "sambastudio" # set either sambastudio or cpu
    "batch_size": 1 #set depending of your endpoint configuration (1 if CoE embedding expert)
    "coe": True #set true if using Sambastudio embeddings in a CoE endpoint 
    "select_expert": "e5-mistral-7b-instruct" #set if using SambaStudio CoE embedding expert

retrieval:
    "chunk_size": 1000
    "chunk_overlap": 200
    "db_type": "faiss"