{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f594c94e-0e5e-4852-a132-4e3e24ed0b41",
   "metadata": {},
   "source": [
    "# Deploy a Model or Bundle to an Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a795bb7-8801-455c-bd2d-e3d192821fdf",
   "metadata": {},
   "source": [
    "Welcome to this tutorial on deploying a model or a model bundle to a SambaNova dedicated node!\n",
    "\n",
    "Before you get started, please follow the set up instructions given in the [README](./README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebfc10-eb09-4da5-82e9-35f9f78cdca7",
   "metadata": {},
   "source": [
    "## 1.  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd40d05-10f3-47d7-8c57-507798bfca9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11.11 (main, Dec 11 2024, 10:28:39) [Clang 14.0.6 ]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1bf646-5d54-4044-8324-33bbfa235035",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>:root { --jp-notebook-max-width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pprint\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a252b07f-c85f-44a9-8185-505a41fbf6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snsdk import SnSdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d004f8-6ff1-44ad-b33d-601d71528243",
   "metadata": {},
   "source": [
    "## 2. Set up environment connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0b3583-b31f-45c6-87b6-b40a58bee55e",
   "metadata": {},
   "source": [
    "Connects to the remote dedicated environment using the variables defined in `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "772356ae-30a7-4780-a29e-9a71796cb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_env = SnSdk(host_url=os.getenv(\"SAMBASTUDIO_HOST_NAME_e8\"), \n",
    "                   access_key=os.getenv(\"SAMBASTUDIO_ACCESS_KEY_e8\"), \n",
    "                   tenant_id=os.getenv(\"SAMBASTUDIO_TENANT_NAME_e8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddddf132-8410-47ba-8a62-349663d2be8d",
   "metadata": {},
   "source": [
    "## 3. Create or select a project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207976f-9e74-4dc0-96c7-635059c8656c",
   "metadata": {},
   "source": [
    "Projects are a way to organize endpoints and training/inference jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc370bdb-fb42-468e-b21a-d8e5ba697c3e",
   "metadata": {},
   "source": [
    "#### List available projects\n",
    "You can list existing projects in which the endpoint can be created for model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee405d-4dbf-4233-ad23-dec2f075bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = sn_env.list_projects()[\"projects\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a103e075-613a-4f80-8bb9-93c3958ac0d9",
   "metadata": {},
   "source": [
    "#### Create a new project\n",
    "If you do not wish to use an existing project, you may create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14062dd4-9cdc-4d76-8ee7-876b34e1082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"test_project\"\n",
    "new_project = sn_env.create_project(\n",
    "                    project_name=project_name,\n",
    "                    description=\"A test project with a test endpoint\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb162fb2-8da7-4a1b-8c96-762188c49888",
   "metadata": {},
   "source": [
    "## 4. Select model or bundle to deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8003334-9e57-4b0d-8e77-9ab25fceae6c",
   "metadata": {},
   "source": [
    "#### List models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebdbca6-b4d9-4b13-8075-97ade54ecb2c",
   "metadata": {},
   "source": [
    "Get the complete list of models. This includes models that are  \n",
    "  - actually available\n",
    "  - still in the process of uploading\n",
    "  - exist in a remote storage from which they can be made available\n",
    "  - not in a usable state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6a9c775-ef45-473c-aa0e-be46398a51c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = sn_env.list_models()[\"models\"]\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8509da5e-2660-4e76-b150-9e850cbdaac9",
   "metadata": {},
   "source": [
    "Filter down to the models that are actually available on the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49706042-a445-41df-9742-22e8c4329257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_models = [m for m in models if m['status'] == 'Available']\n",
    "len(available_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9830e32a-2775-495c-93f3-77893b178b9b",
   "metadata": {},
   "source": [
    "Print names of the available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a9f8a34-6fc4-473a-9f3f-412ee29310e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeepSeek-R1-Distill-Llama-70B',\n",
       " 'DeepSeek-R1-Distill-Llama-8B',\n",
       " 'EEVE-Korean-Instruct-10.8B-v1.0',\n",
       " 'LLama3-Qwen2-Mixtral',\n",
       " 'Llama 3.1 405B with E5-Mistral',\n",
       " 'Llama 3.1 70B with E5-Mistral',\n",
       " 'Llama 3.1 70B_1B with E5-Mistral',\n",
       " 'Llama 3.1 8B with E5-Mistral',\n",
       " 'Llama-2-13B-chat-hf',\n",
       " 'Llama3-Qwen2-Mixtral',\n",
       " 'Meta-Llama-3-70B-Instruct',\n",
       " 'Meta-Llama-3-8B-Instruct',\n",
       " 'Meta-Llama-3.1-405B-Instruct',\n",
       " 'Meta-Llama-3.1-405B-Instruct-FP8',\n",
       " 'Meta-Llama-3.1-405B-SD-Llama-3.1-8B',\n",
       " 'Meta-Llama-3.1-405B-SD-Llama-3.2-3B',\n",
       " 'Meta-Llama-3.1-70B-Instruct',\n",
       " 'Meta-Llama-3.1-70B-SD-Llama-3.1-8B',\n",
       " 'Meta-Llama-3.1-70B-SD-Llama-3.2-1B',\n",
       " 'Meta-Llama-3.1-8B-Instruct',\n",
       " 'Meta-Llama-3.2-11B-Vision-Instruct',\n",
       " 'Meta-Llama-3.2-1B-Instruct',\n",
       " 'Meta-Llama-3.2-3B-Instruct',\n",
       " 'Meta-Llama-3.2-3B-Instruct-TP16',\n",
       " 'Meta-Llama-3.2-90B-Vision-Instruct',\n",
       " 'Meta-Llama-3.3-70B-Instruct',\n",
       " 'Meta-Llama-3.3-70B-SD-Llama-3.2-1B-TP16',\n",
       " 'Meta-Llama-Guard-3-8B',\n",
       " 'Mistral-7B-Instruct-V0.2',\n",
       " 'Mistral-Nemo-Instruct-2407',\n",
       " 'Mixtral-8x22B-Instruct-v0.1',\n",
       " 'QwQ-32B-Preview',\n",
       " 'Qwen 2.5 72B TP16',\n",
       " 'Qwen-2.5-72B-SD-Qwen-2.5-0.5B',\n",
       " 'Qwen2-72B-Instruct',\n",
       " 'Qwen2-7B-Instruct',\n",
       " 'Qwen2.5-0.5B-Instruct',\n",
       " 'Qwen2.5-72B-Instruct',\n",
       " 'Qwen2.5-7B-Instruct',\n",
       " 'Qwen2.5-Coder-0.5B-Instruct',\n",
       " 'SOLAR-10.7B-Instruct-v1.0',\n",
       " 'Samba-1 Turbo',\n",
       " 'Sarashina2-70B',\n",
       " 'Sarashina2-7B',\n",
       " 'deepseek-coder-33B-instruct',\n",
       " 'deepseek-coder-6.7B-instruct',\n",
       " 'e5-mistral-7B-instruct',\n",
       " 'e5-mistral-7b-instruct-8192',\n",
       " 'gemma-2-9b-it',\n",
       " 'llama-2-70b-chat-hf',\n",
       " 'llama-2-7B-chat-hf',\n",
       " 'llama3-mixtral3',\n",
       " 'meta-llama-3.1-70b',\n",
       " 'meta-llama-3.1-70b-instruct']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([m[\"model_checkpoint_name\"] for m in available_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81c100c6-83b4-4b0d-915c-a3ae1a1c0c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'b2ac2eb1-54d4-4c35-88bf-8f09b6dc609c',\n",
       " 'model_checkpoint_name': 'Mixtral-8x22B-Instruct-v0.1',\n",
       " 'app_id': 'da89eace-e9f2-4174-8b65-a036804d275c',\n",
       " 'user_id': '',\n",
       " 'tenant_id': '',\n",
       " 'checkpoint_type': 'finetuned',\n",
       " 'model_size_gb': 513.9467,\n",
       " 'dataset': '',\n",
       " 'dataset_info': '',\n",
       " 'dataset_url': '',\n",
       " 'path': 'common/checkpoints/b2ac2eb1-54d4-4c35-88bf-8f09b6dc609c/checkpoint',\n",
       " 'sambanova_provided': True,\n",
       " 'version': 2,\n",
       " 'job_config': '',\n",
       " 'description': 'The Mixtral-8x22B-Instruct-v0.1 Large Language Model (LLM) is an instruct fine-tuned version of the Mixtral-8x22B-v0.1. To use the model, simply surround your prompt with [INST] and [/INST] tokens. For example, to ask the model for its favorite condiment, you would use the following prompt: [INST] What is your favourite condiment? [/INST]. https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1',\n",
       " 'status': 'Available',\n",
       " 'params': {'invalidates_checkpoint': {'max_seq_length': 65536,\n",
       "   'model_parameter_count': '8x22b',\n",
       "   'vocab_size': 32768},\n",
       "  'modifiable': None},\n",
       " 'metrics': '',\n",
       " 'steps': 0,\n",
       " 'application_field': 'language',\n",
       " 'hyperparams': {'train': {},\n",
       "  'batch_predict': {},\n",
       "  'deploy': {'SN40L-16': {'sockets': 16,\n",
       "    'supports_data_parallel': False,\n",
       "    'user_params': [{'DATATYPE': 'int',\n",
       "      'DESCRIPTION': 'The number of RDUs to run in model parallel.',\n",
       "      'FIELD_NAME': 'model_parallel_rdus',\n",
       "      'MESSAGE': '',\n",
       "      'TASK_TYPE': ['compile', 'endpoint', 'serve'],\n",
       "      'TYPE_SPECIFIC_SETTINGS': {'serve': {'DEFAULT': '8',\n",
       "        'USER_MODIFIABLE': True}},\n",
       "      'CONSTRAINTS': {'gt': '', 'ge': '', 'lt': '', 'le': '', 'values': ['8']},\n",
       "      'VARIANT_SELECTION': True},\n",
       "     {'DATATYPE': 'int',\n",
       "      'DESCRIPTION': 'Number of tokens to include in each streaming response.',\n",
       "      'FIELD_NAME': 'num_tokens_at_a_time',\n",
       "      'MESSAGE': '',\n",
       "      'TASK_TYPE': ['endpoint', 'serve'],\n",
       "      'TYPE_SPECIFIC_SETTINGS': {'serve': {'DEFAULT': '10',\n",
       "        'USER_MODIFIABLE': True}},\n",
       "      'CONSTRAINTS': {'gt': '', 'ge': '1', 'lt': '', 'le': '', 'values': []},\n",
       "      'VARIANT_SELECTION': False}],\n",
       "    'jobTypes': ['deploy'],\n",
       "    'imageVersion': '2.2.0-202503121',\n",
       "    'runtimeVersion': '5.1.0',\n",
       "    'variantSetVersion': '33e203c00a8d4583ff592f255f385b5d',\n",
       "    'imageVariants': [{'name': 'sn40-16.m=16',\n",
       "      'resources': {'rduArch': 'sn40-16',\n",
       "       'supportedRduArchs': [],\n",
       "       'supportsDataParallel': False,\n",
       "       'modelParallelRdus': '16',\n",
       "       'minCpus': '1',\n",
       "       'minCpuMem': '32G',\n",
       "       'minRduMem': '32G',\n",
       "       'minHugepageMem': '263Gi',\n",
       "       'minSharedMem': ''},\n",
       "      'variantSelection': {'model_parallel_rdus': {'eq': '16'}}}],\n",
       "    'display_name': 'SN40L-16',\n",
       "    'supports_speculative_decoding': False}},\n",
       "  'deploy_with_inference_engine': {'SN40L-16': {'sockets': 16,\n",
       "    'supports_data_parallel': False,\n",
       "    'user_params': [{'DATATYPE': 'int',\n",
       "      'DESCRIPTION': 'The number of RDUs to run in model parallel.',\n",
       "      'FIELD_NAME': 'model_parallel_rdus',\n",
       "      'MESSAGE': '',\n",
       "      'TASK_TYPE': ['compile', 'endpoint', 'serve'],\n",
       "      'TYPE_SPECIFIC_SETTINGS': {'serve': {'DEFAULT': '8',\n",
       "        'USER_MODIFIABLE': True}},\n",
       "      'CONSTRAINTS': {'gt': '', 'ge': '', 'lt': '', 'le': '', 'values': ['8']},\n",
       "      'VARIANT_SELECTION': True},\n",
       "     {'DATATYPE': 'int',\n",
       "      'DESCRIPTION': 'Number of tokens to include in each streaming response.',\n",
       "      'FIELD_NAME': 'num_tokens_at_a_time',\n",
       "      'MESSAGE': '',\n",
       "      'TASK_TYPE': ['endpoint', 'serve'],\n",
       "      'TYPE_SPECIFIC_SETTINGS': {'serve': {'DEFAULT': '10',\n",
       "        'USER_MODIFIABLE': True}},\n",
       "      'CONSTRAINTS': {'gt': '', 'ge': '1', 'lt': '', 'le': '', 'values': []},\n",
       "      'VARIANT_SELECTION': False}],\n",
       "    'jobTypes': ['deploy'],\n",
       "    'imageVersion': '2.2.46',\n",
       "    'runtimeVersion': '5.1.0',\n",
       "    'variantSetVersion': '438dacca6663916cd07b6ffef87b30bc',\n",
       "    'imageVariants': [{'name': 'sn40-16.m=16',\n",
       "      'resources': {'rduArch': 'sn40-16',\n",
       "       'supportedRduArchs': [],\n",
       "       'supportsDataParallel': False,\n",
       "       'modelParallelRdus': '16',\n",
       "       'minCpus': '1',\n",
       "       'minCpuMem': '32G',\n",
       "       'minRduMem': '32G',\n",
       "       'minHugepageMem': '263Gi',\n",
       "       'minSharedMem': ''},\n",
       "      'variantSelection': {'model_parallel_rdus': {'eq': '16'}}}],\n",
       "    'display_name': 'SN40L-16',\n",
       "    'supports_speculative_decoding': False}}},\n",
       " 'architecture': 'Composite',\n",
       " 'pipeline': None,\n",
       " 'model_io': {'train': {'input': {'description': '', 'example': ''},\n",
       "   'output': {'description': '', 'example': ''}},\n",
       "  'infer': {'input': {'description': 'A folder containing .jsonl files where each line is a json object containing a \"prompt\" field and a \"completion\" field.',\n",
       "    'example': ''},\n",
       "   'output': {'description': 'A file called predictions.json which contains the list of generated sequences per input prompt',\n",
       "    'example': ''}},\n",
       "  'serve': {'input': {'description': 'The input prompt to be completed by the generative inference model.',\n",
       "    'example': ''},\n",
       "   'output': {'description': 'The output is a concatenation of the prompt (input) string, and the generated completion.',\n",
       "    'example': ''}}},\n",
       " 'dataset_metadata': {'info': '', 'url': ''},\n",
       " 'preset_ids': [],\n",
       " 'system_prompt_ids': [],\n",
       " 'device': 'rdu',\n",
       " 'evaluation': {},\n",
       " 'time_created': '2025-03-20 22:56:18.23305 +0000 UTC',\n",
       " 'time_updated': '2025-04-30 14:48:17.019291 +0000 UTC',\n",
       " 'app_name': '',\n",
       " 'hidden': False,\n",
       " 'jobTypes': [],\n",
       " 'shared_with': [],\n",
       " 'type': 'Basic',\n",
       " 'dependencies': [],\n",
       " 'replacement_model_id': '',\n",
       " 'replacement_model_name': '',\n",
       " 'deprecation_date': '',\n",
       " 'linked_coe_models': [{'id': 'f6d81345-a12b-4e9c-87fa-4e4507c256db',\n",
       "   'name': 'LLama3-Qwen2-Mixtral',\n",
       "   'description': 'LLama3 and Qwen2 families with Mixtral'},\n",
       "  {'id': '58b1d225-8c36-4c08-a7b1-d4056178b748',\n",
       "   'name': 'llama3-mixtral3',\n",
       "   'description': ''},\n",
       "  {'id': 'b5751da7-9609-4b2f-9295-2a25667365bc',\n",
       "   'name': 'Llama3-Qwen2-Mixtral',\n",
       "   'description': 'Llama3-Qwen2-Mixtral'}],\n",
       " 'model_metadata': {'publisher': 'Mistral AI',\n",
       "  'category': 'General,General tasks,Code completion,Code generation,Instruct',\n",
       "  'license': 'apache-2.0',\n",
       "  'languages': 'English',\n",
       "  'modelArchitecture': 'Mistral',\n",
       "  'isMultiturnChat': True,\n",
       "  'supported_playground_modes': [],\n",
       "  'supported_predict_apis': []},\n",
       " 'model_parallel_rdus': 0,\n",
       " 'metadata': {'labels': {},\n",
       "  'creationTimestamp': '',\n",
       "  'updateTimestamp': '',\n",
       "  'resourceVersion': '',\n",
       "  'tenant': '',\n",
       "  'owner': '',\n",
       "  'permissions': ['ModelView',\n",
       "   'ModelExport',\n",
       "   'ModelDelete',\n",
       "   'ModelEdit',\n",
       "   'ModelShare',\n",
       "   'ModelImport',\n",
       "   'ModelImportDelete',\n",
       "   'ModelImportStatus',\n",
       "   'ModelUpload']},\n",
       " 'tags': [],\n",
       " 'import_status': None,\n",
       " 'warnings': [],\n",
       " 'prompt_template_names': [],\n",
       " 'prompt_templates': [],\n",
       " 'display_model_type': 'Standalone Model',\n",
       " 'config': {'target_model': '', 'draft_model': ''},\n",
       " 'supported_config': [],\n",
       " 'unsupported_config': [],\n",
       " 'downloaded_model_size_gb': 0,\n",
       " 'status_code': 200,\n",
       " 'headers': {'access-control-allow-headers': 'Accept, Content-Type, Content-Length, Accept-Encoding, Authorization, ResponseType, Access-Control-Allow-Origin', 'access-control-allow-methods': 'GET, POST, PATCH, DELETE', 'access-control-allow-origin': 'https://sjc3-e8.sambanova.net', 'content-security-policy': \"default-src 'self'\", 'content-type': 'application/json', 'permissions-policy': 'none', 'referrer-policy': 'no-referrer', 'strict-transport-security': 'max-age=31536000; includeSubDomains, max-age=31536000; includeSubDomains', 'x-content-type-options': 'nosniff', 'x-correlation-id': 'ca29e7cd-4437-4b2c-aeff-fa1ceb2aa873', 'x-frame-options': 'DENY', 'date': 'Fri, 09 May 2025 22:14:02 GMT', 'x-envoy-upstream-service-time': '55', 'server': 'istio-envoy', 'content-encoding': 'gzip', 'vary': 'Accept-Encoding', 'transfer-encoding': 'chunked'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn_env.model_info('Mixtral-8x22B-Instruct-v0.1', 'deploy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eeb8b8-cd74-4774-a136-7946da862ff1",
   "metadata": {},
   "source": [
    "#### Select model to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d0d8fed-196a-4d92-9d90-77a4e201c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = \"qwen_llama_salesforce\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d7d7b2-1c53-43a4-bdcd-1791441f6bd3",
   "metadata": {},
   "source": [
    "## 5. Create endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236474a-19eb-42d5-afa8-338ffcc519ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = selected_model.lower().replace('_','-')\n",
    "endpoint = sn_env.create_endpoint(\n",
    "    project=project_name,\n",
    "    endpoint_name=endpoint_name,\n",
    "    description=\"Endpoint for \" + selected_model,\n",
    "    model_checkpoint=selected_model,\n",
    "    model_version=1,\n",
    "    instances=1,\n",
    "    hyperparams='{\"model_parallel_rdus\": \"16\", \"num_tokens_at_a_time\": \"10\"}',\n",
    "    rdu_arch=\"SN40L-16\",\n",
    "    inference_api_openai_compatible=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a168050-e6fd-40a6-9518-1824649e443f",
   "metadata": {},
   "source": [
    "#### Check the status of the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea3a6a5f-daa8-4f01-8837-b7b288ae45e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SettingUp'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = sn_env.endpoint_info(project_name, endpoint_name)\n",
    "endpoint['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341c9f89-306c-4c3e-8aaf-adfa62f5f72c",
   "metadata": {},
   "source": [
    "## 6. Get Endpoint Details\n",
    "To test the endpoint, we will need to obtain some of its information. Note that this information can be obtained even while the model is setting up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc860c4-ff8e-48be-9707-1d6339dd07da",
   "metadata": {},
   "source": [
    "#### Get the endpoint URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a408fcb-43a5-4a43-9ff8-03f1e85fce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = os.getenv(\"SAMBASTUDIO_HOST_NAME\") + \"/v1/\" + endpoint[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ca1ba7-6c78-44aa-b88a-d46ca708cacb",
   "metadata": {},
   "source": [
    "#### Get the default endpoint API key\n",
    "Note that:\n",
    "  - New keys can be added using the `sn_env.add_endpoint_api_key` function.    \n",
    "  - All keys can be revoked using the `sn_env.edit_endpoint_api_key` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48ada26e-d8bf-40b1-9a51-f6654aca3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_key = endpoint[\"api_keys\"][0][\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09814c6-d819-4c9d-af89-16c4a3ea2336",
   "metadata": {},
   "source": [
    "#### Get model names in the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "071b9498-7c3b-49fa-8108-5580dad2ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_model_id = endpoint['targets'][0][\"model\"]\n",
    "model_info = sn_env.model_info(endpoint_model_id, job_type=\"deploy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c963fe6f-e4c4-4941-9a70-746ddba81a25",
   "metadata": {},
   "source": [
    "#### Check if the model is standalone or composite (bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7643d855-809f-459e-9ada-0aa0439d8337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Composite'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info[\"type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b6a16-1b7b-4705-a415-60083dc2e64d",
   "metadata": {},
   "source": [
    "#### If the model is a composite/bundle, list its constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93440b4e-4b2a-4b0c-b41b-802da793f20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Meta-Llama-3.3-70B-Instruct',\n",
       " 'Qwen-2.5-72B-SD-Qwen-2.5-0.5B',\n",
       " 'Salesforce--Llama-xLAM-2-70b-fc-r',\n",
       " 'Salesforce--Llama-xLAM-2-8b-fc-r']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_constituents = [m[\"name\"] for m in model_info[\"dependencies\"]]\n",
    "sorted(model_constituents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a26b5f-c0fa-471b-a932-3a549ae96cbe",
   "metadata": {},
   "source": [
    "## 7. Test Endpoint\n",
    "Once the endpoint is live, you can test it using the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b659dc-f5ca-4f47-a466-213ea972663b",
   "metadata": {},
   "source": [
    "#### Make sure endpoint is live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc7cf06e-2a85-478d-9431-b4a169292afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Live'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = sn_env.endpoint_info(project_name, endpoint_name)\n",
    "endpoint['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3542e4-fee3-4b98-8366-f1e039cf10f3",
   "metadata": {},
   "source": [
    "#### Create test messages to send to the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bde38fee-2a62-48be-b8f7-2194721782b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "         \"content\": \"You are a helpful assistant\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How large is the Earth?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07484641-1bd0-45de-8182-ff0033c06c40",
   "metadata": {},
   "source": [
    "#### Send test messsages to the endpoint\n",
    "In this example, we test all the constituents of the model bundle. An endpoint may only have one model deployed, in which case this test can be done against that model alone.\n",
    "\n",
    "**Note: If a model uses speculative decoding, its name will not match the name expected by the endpoint. Instead, we need to get and use the name of the target model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3355aefd-3d72-4bf8-81e3-f9dc7f25784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Qwen2.5-72B-Instruct --------\n",
      "The Earth is a nearly spherical object with an average radius of about 6,371 kilometers (3,959 miles). Its diameter, which is the distance from one side of the Earth to the other through its center, is approximately 12,742 kilometers (7,918 miles).\n",
      "\n",
      "The Earth's circumference, which is the distance around the planet at the equator, is about 40,075 kilometers (24,901 miles). However, because the Earth is not a perfect sphere but rather an oblate spheroid (flattened at the poles and bulging at the equator), the distance from the center of the Earth to the surface varies slightly. The equatorial radius is about 6,378 kilometers (3,963 miles), while the polar radius is about 6,357 kilometers (3,950 miles).\n",
      "\n",
      "These measurements give you a sense of the size of the Earth, which is the third planet from the Sun and the largest of the terrestrial planets in our solar system.\n",
      "\n",
      "-------- Meta-Llama-3.3-70B-Instruct --------\n",
      "The Earth is a massive planet, and its size can be measured in various ways. Here are some key dimensions:\n",
      "\n",
      "1. **Diameter**: The Earth's diameter is approximately 12,742 kilometers (7,918 miles). This is the distance from one side of the Earth to the other, passing through its center.\n",
      "2. **Circumference**: The Earth's circumference is about 40,075 kilometers (24,901 miles) at the equator. This is the distance around the Earth, measured at the equator.\n",
      "3. **Radius**: The Earth's radius is approximately 6,371 kilometers (3,959 miles). This is the distance from the center of the Earth to its surface.\n",
      "4. **Surface area**: The Earth's surface area is about 510 million square kilometers (197 million square miles). This includes the area of the oceans, continents, and islands.\n",
      "5. **Volume**: The Earth's volume is approximately 1.083 billion cubic kilometers (259 billion cubic miles).\n",
      "\n",
      "To put these numbers into perspective, consider that:\n",
      "\n",
      "* The Earth is the fifth-largest planet in our solar system, after Jupiter, Saturn, Uranus, and Neptune.\n",
      "* The Earth is about 4.5 times larger than the Moon.\n",
      "* The Earth's diameter is roughly 12 times larger than the diameter of the Grand Canyon.\n",
      "\n",
      "These dimensions are averages, as the Earth is not a perfect sphere. Its shape is slightly flattened at the poles and bulging at the equator due to its rotation.\n",
      "\n",
      "-------- Salesforce--Llama-xLAM-2-8b-fc-r --------\n",
      "The Earth is approximately 12,742 kilometers (7,918 miles) in diameter.\n",
      "\n",
      "-------- Salesforce--Llama-xLAM-2-70b-fc-r --------\n",
      "The Earth is a massive planet, and its size can be measured in various ways. Here are some key dimensions:\n",
      "\n",
      "1. **Diameter**: The Earth's diameter is approximately 12,742 kilometers (7,918 miles). This is the distance from one side of the Earth to the other, passing through its center.\n",
      "2. **Circumference**: The Earth's circumference is about 40,075 kilometers (24,901 miles) at the equator. This is the distance around the Earth, measured at the equator.\n",
      "3. **Radius**: The Earth's radius is approximately 6,371 kilometers (3,959 miles). This is the distance from the center of the Earth to its surface.\n",
      "4. **Surface area**: The Earth's surface area is about 510 million square kilometers (197 million square miles). This includes the area of the oceans, continents, and islands.\n",
      "5. **Volume**: The Earth's volume is approximately 1.083 billion cubic kilometers (259 billion cubic miles).\n",
      "\n",
      "To put these numbers into perspective, consider that:\n",
      "\n",
      "* The Earth is the fifth-largest planet in our solar system, after Jupiter, Saturn, Uranus, and Neptune.\n",
      "* The Earth is about 4.5 billion years old and has a mass of approximately 5.97 x 10^24 kilograms (1.33 x 10^25 pounds).\n",
      "* The Earth's size and mass are just right to support life, with a stable atmosphere and a magnetic field that protects us from harm.\n",
      "\n",
      "I hope that helps you understand the size of our amazing planet!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=endpoint_key,\n",
    "    base_url=endpoint_url,\n",
    ")\n",
    "\n",
    "for constituent_name in model_constituents:    \n",
    "    model_name = constituent_name\n",
    "\n",
    "    # Check for speculative decoding\n",
    "    constituent_info = sn_env.model_info(constituent_name, job_type=\"deploy\")\n",
    "    if 'target_model' in constituent_info['config']:\n",
    "        target_name = constituent_info['config']['target_model']        \n",
    "        if len(target_name) > 0:\n",
    "            model_name = target_name\n",
    "\n",
    "    # Send messages to endpoint\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=test_messages,\n",
    "        temperature =  0.01,\n",
    "        top_p = 0.1\n",
    "    )\n",
    "    print(f\"-------- {model_name} --------\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9424f430-b48a-4e9a-afb3-a6a9e657f629",
   "metadata": {},
   "source": [
    "## 8. Stopping/deleting an endpoint\n",
    "An endpoint can be:\n",
    "  - stopped: sn_env.stop_endpoint(project_name, endpoint_name)\n",
    "  - deleted: sn_env.delete_endpoint(project_name, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e152a5-8dfe-4b6d-96d5-48992d637b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_env.validate_model_bundle(dependencies, rdu_required)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_11_autogen",
   "language": "python",
   "name": "py_3_11_autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
