{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f594c94e-0e5e-4852-a132-4e3e24ed0b41",
   "metadata": {},
   "source": [
    "# Benchmark a Model Bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a795bb7-8801-455c-bd2d-e3d192821fdf",
   "metadata": {},
   "source": [
    "Welcome to this tutorial on benchmarking a model bundle in SambaNova dedicated offerings!\n",
    "\n",
    "**What is a model bundle?**  \n",
    "A model bundle (a.k.a `composite model`) is a group of models that share a hardware node and that can be accessed through a common endpoint. It allows multiple models to share memory in a single hardware node, utilizing the memory better, and making it quick & easy to switch between them.\n",
    "\n",
    "Before you get started, please follow the set up instructions given in the [README](./README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebfc10-eb09-4da5-82e9-35f9f78cdca7",
   "metadata": {},
   "source": [
    "## 1.  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd40d05-10f3-47d7-8c57-507798bfca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import pprint\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a252b07f-c85f-44a9-8185-505a41fbf6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SambaStudio SDK\n",
    "from snsdk import SnSdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d004f8-6ff1-44ad-b33d-601d71528243",
   "metadata": {},
   "source": [
    "## 2. Set up environment connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0b3583-b31f-45c6-87b6-b40a58bee55e",
   "metadata": {},
   "source": [
    "Connects to the remote dedicated environment using the variables defined in `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772356ae-30a7-4780-a29e-9a71796cb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_env = SnSdk(\n",
    "    host_url=os.getenv(\"SAMBASTUDIO_HOST_NAME\"), \n",
    "    access_key=os.getenv(\"SAMBASTUDIO_ACCESS_KEY\"), \n",
    "    tenant_id=os.getenv(\"SAMBASTUDIO_TENANT_NAME\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb162fb2-8da7-4a1b-8c96-762188c49888",
   "metadata": {},
   "source": [
    "## 3. Select models to bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebdbca6-b4d9-4b13-8075-97ade54ecb2c",
   "metadata": {},
   "source": [
    "The models on Sambastudio are divided into the following groups:\n",
    "- actually available\n",
    "- still in the process of uploading\n",
    "- exist in a remote storage from which they can be made available\n",
    "- not in a usable state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f8a34-6fc4-473a-9f3f-412ee29310e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the complete list of models.\n",
    "models = sn_env.list_models()[\"models\"]\n",
    "print('All models: ', len(models))\n",
    "\n",
    "# Filter down to the models that are actually available on the environment\n",
    "available_models = [m for m in models if m['status'] == 'Available']\n",
    "\n",
    "# Print names of the available models for Llama and DeepSeek\n",
    "print('Available models: ', len(available_models))\n",
    "for model in sorted([m[\"model_checkpoint_name\"] for m in available_models]):\n",
    "    if 'llama' in model.lower() or 'deepseek' in model.lower():\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eeb8b8-cd74-4774-a136-7946da862ff1",
   "metadata": {},
   "source": [
    "#### Select models to include in the bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d8fed-196a-4d92-9d90-77a4e201c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the model bundle\n",
    "model_name = 'llama_deepseek_coe'\n",
    "\n",
    "# List of models to include in the bundle\n",
    "selected_models = [\n",
    "    'Meta-Llama-3.1-8B-Instruct',\n",
    "    'Meta-Llama-3.3-70B-Instruct',\n",
    "    'DeepSeek-R1-Distill-Llama-70B'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d7d7b2-1c53-43a4-bdcd-1791441f6bd3",
   "metadata": {},
   "source": [
    "## 4. Create a bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449e4d8-c3a0-48f8-99ab-7a5ad692b677",
   "metadata": {},
   "source": [
    "Set `rdu_required=16` for maximum performance. [RDUs](https://sambanova.ai/technology/sn40l-rdu-ai-chip) are SambaNova's cutting-edge replacements for GPUs.\n",
    "\n",
    "Further checks on bundle compatibility can be achieved using the `sn_env.validate_model_bundle(dependencies, rdu_required)` function. If that or the following command fails, please try changing the constituents of `selected_models`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236474a-19eb-42d5-afa8-338ffcc519ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_model = sn_env.add_composite_model(\n",
    "    name=model_name,\n",
    "    description=\"Bundle containing Meta-Llama-3.1-8B-Instruct,  Meta-Llama-3.3-70B-Instruct, and DeepSeek-R1-Distill-Llama-70B.\",\n",
    "    dependencies=[{'name': model} for model in selected_models],\n",
    "    rdu_required=16,\n",
    "    config_params={},\n",
    "    app=\"\"\n",
    ")\n",
    "\n",
    "print(composite_model['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb00c28-047a-4757-a906-b9b8a289847c",
   "metadata": {},
   "source": [
    "Once created, a bundle can be deleted using `sn_env.delete_model(bundle_name)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad0a21",
   "metadata": {},
   "source": [
    "## 5. Create or select a project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a078f",
   "metadata": {},
   "source": [
    "Projects are a way to organize endpoints and training/inference jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c06e06",
   "metadata": {},
   "source": [
    "#### List available projects\n",
    "You can list existing projects in which the endpoint can be created for model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa53274",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = sn_env.list_projects()[\"projects\"]\n",
    "sorted([project[\"name\"] for project in projects])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52d608",
   "metadata": {},
   "source": [
    "#### Create a new project\n",
    "If you do not wish to use an existing project, you may create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"coe_benchmarking_francesca\"\n",
    "new_project = sn_env.create_project(\n",
    "                    project_name=project_name,\n",
    "                    description=\"A test project for CoE benchmarking..\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d6c33",
   "metadata": {},
   "source": [
    "#### Deleting a project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a537dd9",
   "metadata": {},
   "source": [
    "If required, a project can be deleted using the `sn_env.delete_project(project_name)` function. Please be sure to stop and delete all endpoints and jobs before deleting a project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b880b8-313a-434d-9b72-ec655d38135f",
   "metadata": {},
   "source": [
    "## 5. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b265bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = model_name.lower().replace('_','-')\n",
    "endpoint = sn_env.create_endpoint(\n",
    "    project=project_name,\n",
    "    endpoint_name=endpoint_name,\n",
    "    description=\"Endpoint for \" + model_name,\n",
    "    model_checkpoint=model_name,\n",
    "    model_version=1,\n",
    "    instances=1,\n",
    "    hyperparams='{\"model_parallel_rdus\": \"16\", \"num_tokens_at_a_time\": \"10\"}',\n",
    "    rdu_arch=\"SN40L-16\",\n",
    "    inference_api_openai_compatible=True\n",
    ")\n",
    "\n",
    "endpoint = sn_env.endpoint_info(project_name, endpoint_name)\n",
    "print(endpoint['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e779c8",
   "metadata": {},
   "source": [
    "## 6. Get Endpoint Details\n",
    "To test the endpoint, we will need to obtain some of its information. Note that this information can be obtained even while the model is setting up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2cb6f6",
   "metadata": {},
   "source": [
    "#### Get the endpoint URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf06a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = os.getenv(\"SAMBASTUDIO_HOST_NAME\") + \"/v1/\" + endpoint[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc678a2",
   "metadata": {},
   "source": [
    "#### Get the default endpoint API key\n",
    "Note that:\n",
    "  - New keys can be added using the `sn_env.add_endpoint_api_key` API.    \n",
    "  - All keys can be revoked using the `sn_env.edit_endpoint_api_key` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ef3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_key = endpoint[\"api_keys\"][0][\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b33b36",
   "metadata": {},
   "source": [
    "#### Get model names in the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_model_id = endpoint['targets'][0][\"model\"]\n",
    "model_info = sn_env.model_info(endpoint_model_id, job_type=\"deploy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1646d9",
   "metadata": {},
   "source": [
    "#### Check if the model is standalone or composite (bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb38662",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info[\"type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a452ae83",
   "metadata": {},
   "source": [
    "#### If the model is a composite/bundle, list its constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa0881",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_constituents = [m[\"name\"] for m in model_info[\"dependencies\"]]\n",
    "sorted(model_constituents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196b313",
   "metadata": {},
   "source": [
    "## 7. Test Endpoint\n",
    "Once the endpoint is live, you can test it using the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca46867",
   "metadata": {},
   "source": [
    "#### Make sure endpoint is live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = sn_env.endpoint_info(project_name, endpoint_name)\n",
    "endpoint['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04002f14",
   "metadata": {},
   "source": [
    "#### Create test messages to send to the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "         \"content\": \"You are a helpful assistant\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How large is the Earth?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a49983f",
   "metadata": {},
   "source": [
    "#### Send test messsages to the endpoint\n",
    "In this example, we test all the constituents of the model bundle. An endpoint may only have one model deployed, in which case this test can be done against that model alone.\n",
    "\n",
    "**Note: If a model uses speculative decoding, its name will not match the name expected by the endpoint. Instead, we need to get and use the name of the target model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=endpoint_key,\n",
    "    base_url=endpoint_url,\n",
    ")\n",
    "\n",
    "for constituent_name in model_constituents:    \n",
    "    model_name = constituent_name\n",
    "\n",
    "    # Check for speculative decoding\n",
    "    constituent_info = sn_env.model_info(constituent_name, job_type=\"deploy\")\n",
    "    if 'target_model' in constituent_info['config']:\n",
    "        target_name = constituent_info['config']['target_model']        \n",
    "        if len(target_name) > 0:\n",
    "            model_name = target_name\n",
    "\n",
    "    # Send messages to endpoint\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=test_messages,\n",
    "        temperature =  0.01,\n",
    "        top_p = 0.1\n",
    "    )\n",
    "    print(f\"-------- {model_name} --------\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b220021",
   "metadata": {},
   "source": [
    "## 8. Stopping/deleting an Endpoint\n",
    "An endpoint can be:\n",
    "  - stopped: sn_env.stop_endpoint(project_name, endpoint_name)\n",
    "  - deleted: sn_env.delete_endpoint(project_name, endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0ceddb",
   "metadata": {},
   "source": [
    "## 9. Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb356415",
   "metadata": {},
   "source": [
    "Modify the following files:\n",
    "- _PATH TO AISK REPO HERE/benchmarking/benchmarking_scripts/config.yaml_\n",
    "\n",
    "    With the desired input and output paths.\n",
    "\n",
    "    ```yaml\n",
    "    model_configs_path: '<PATH TO AISK REPO HERE>/benchmarking/benchmarking_scripts/model_configs_example.csv'\n",
    "    llm_api: 'sncloud'\n",
    "    output_files_dir: '<PATH TO AISK REPO HERE>/benchmarking/data/benchmarking_tracking_tests/logs/output_files'\n",
    "    consolidated_results_dir: '<PATH TO AISK REPO HERE>/benchmarking/data/benchmarking_tracking_tests/consolidated_results'\n",
    "    timeout: 3600\n",
    "    time_delay: 0\n",
    "    ```\n",
    "\n",
    "- _PATH TO AISK REPO HERE/benchmarking/benchmarking_scripts/model_configs_example.csv_\n",
    "\n",
    "    With the desired model configurations to test.\n",
    "\n",
    "    ```csv\n",
    "    model_name,input_tokens,output_tokens,num_requests,concurrent_requests,qps,qps_distribution,multimodal_img_size\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be6125",
   "metadata": {},
   "source": [
    "Run the following commands.\n",
    "\n",
    "```bash\n",
    "cd ai-starter-kit\n",
    "python benchmarking/benchmarking_scripts/synthetic_performance_eval_script.py\n",
    "```\n",
    "\n",
    "benchmarking results will be saved accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
