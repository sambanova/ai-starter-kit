{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f594c94e-0e5e-4852-a132-4e3e24ed0b41",
   "metadata": {},
   "source": [
    "# Deploy a Model to an Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a795bb7-8801-455c-bd2d-e3d192821fdf",
   "metadata": {},
   "source": [
    "Welcome to this tutorial on deploying a model or a model bundle to a SambaNova dedicated node!\n",
    "\n",
    "Before you get started, please follow the set up instructions given in the [README](./README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebfc10-eb09-4da5-82e9-35f9f78cdca7",
   "metadata": {},
   "source": [
    "## 1.  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd40d05-10f3-47d7-8c57-507798bfca9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11.11 (main, Dec 11 2024, 10:28:39) [Clang 14.0.6 ]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1bf646-5d54-4044-8324-33bbfa235035",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>:root { --jp-notebook-max-width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pprint\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a252b07f-c85f-44a9-8185-505a41fbf6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snsdk import SnSdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d004f8-6ff1-44ad-b33d-601d71528243",
   "metadata": {},
   "source": [
    "## 2. Set up environment connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0b3583-b31f-45c6-87b6-b40a58bee55e",
   "metadata": {},
   "source": [
    "Connects to the remote dedicated environment using the variables defined in `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "772356ae-30a7-4780-a29e-9a71796cb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_env = SnSdk(host_url=os.getenv(\"SAMBASTUDIO_HOST_NAME\"), \n",
    "                   access_key=os.getenv(\"SAMBASTUDIO_ACCESS_KEY\"), \n",
    "                   tenant_id=os.getenv(\"SAMBASTUDIO_TENANT_NAME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddddf132-8410-47ba-8a62-349663d2be8d",
   "metadata": {},
   "source": [
    "## 3. Create or select a project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207976f-9e74-4dc0-96c7-635059c8656c",
   "metadata": {},
   "source": [
    "Projects are a way to organize endpoints and training/inference jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc370bdb-fb42-468e-b21a-d8e5ba697c3e",
   "metadata": {},
   "source": [
    "#### List available projects\n",
    "You can list existing projects in which the endpoint can be created for model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ee405d-4dbf-4233-ad23-dec2f075bfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['benchmarking', 'test_project', 'test_project1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects = sn_env.list_projects()[\"projects\"]\n",
    "sorted([project[\"name\"] for project in projects])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a103e075-613a-4f80-8bb9-93c3958ac0d9",
   "metadata": {},
   "source": [
    "#### Create a new project\n",
    "If you do not wish to use an existing project, you may create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14062dd4-9cdc-4d76-8ee7-876b34e1082f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b004dc34-42a7-4529-90e4-8ce71e15a715'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name = \"test_project\"\n",
    "new_project = sn_env.create_project(\n",
    "                    project_name=project_name,\n",
    "                    description=\"A test project with a test endpoint\"\n",
    "                )\n",
    "try:\n",
    "    project_id = new_project['id']\n",
    "except:\n",
    "    new_project = sn_env.project_info(project_name)\n",
    "    project_id = new_project['id']\n",
    "project_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e870356-2601-4faa-bd4f-c88e392890a7",
   "metadata": {},
   "source": [
    "#### Deleting a project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b2e46e-ce68-473e-a4fe-bbb37045ead5",
   "metadata": {},
   "source": [
    "If required, a project can be deleted using the `sn_env.delete_project(project_name)` function. Please be sure to stop and delete all endpoints and jobs before deleting a project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb162fb2-8da7-4a1b-8c96-762188c49888",
   "metadata": {},
   "source": [
    "## 4. Select model or bundle to deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8003334-9e57-4b0d-8e77-9ab25fceae6c",
   "metadata": {},
   "source": [
    "#### List models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebdbca6-b4d9-4b13-8075-97ade54ecb2c",
   "metadata": {},
   "source": [
    "Get the complete list of models. This includes models that are  \n",
    "  - actually available\n",
    "  - still in the process of uploading\n",
    "  - exist in a remote storage from which they can be made available\n",
    "  - not in a usable state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d1e30f-540a-4843-8ab1-7d01cfb406b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = sn_env.list_models()[\"models\"]\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8509da5e-2660-4e76-b150-9e850cbdaac9",
   "metadata": {},
   "source": [
    "Filter down to the models that are actually available on the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49706042-a445-41df-9742-22e8c4329257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_models = [m for m in models if m['status'] == 'Available']\n",
    "len(available_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9830e32a-2775-495c-93f3-77893b178b9b",
   "metadata": {},
   "source": [
    "Print names of the available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a9f8a34-6fc4-473a-9f3f-412ee29310e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeepSeek-R1',\n",
       " 'DeepSeek-R1-Distill-Llama-70B',\n",
       " 'DeepSeek-V3',\n",
       " 'Meta-Llama-3-70B-Instruct',\n",
       " 'Meta-Llama-3-8B-Instruct',\n",
       " 'Meta-Llama-3.1-405B-Instruct',\n",
       " 'Meta-Llama-3.1-70B-Instruct',\n",
       " 'Meta-Llama-3.1-70B-SD-Llama-3.2-1B',\n",
       " 'Meta-Llama-3.1-8B-Instruct',\n",
       " 'Meta-Llama-3.2-1B-Instruct',\n",
       " 'Meta-Llama-3.3-70B-Instruct',\n",
       " 'Meta-Llama-3.3-70B-SD-Llama-3.2-1B-TP16',\n",
       " 'Mistral-7B-Instruct-V0.2',\n",
       " 'QwQ-32B-Preview',\n",
       " 'QwQ-32B-Preview-SD-Qwen-2.5-QWQ-0.5B',\n",
       " 'Qwen 2.5 72B TP16',\n",
       " 'Qwen-2.5-72B-SD-Qwen-2.5-0.5B',\n",
       " 'Qwen2-72B-Instruct',\n",
       " 'Qwen2-7B-Instruct',\n",
       " 'Qwen2.5-0.5B-Instruct',\n",
       " 'Qwen2.5-0.5B-SFT-Instruct',\n",
       " 'Qwen2.5-72B-Instruct',\n",
       " 'Qwen2.5-7B-Instruct',\n",
       " 'Salesforce--Llama-xLAM-2-70b-fc-r',\n",
       " 'Salesforce--Llama-xLAM-2-70b-fc-r-SD-Llama-3.2-1B-TP16-ge-16k',\n",
       " 'Salesforce--Llama-xLAM-2-70b-fc-r-SD-Llama-3.2-1B-TP16-le-16k',\n",
       " 'Salesforce--Llama-xLAM-2-8b-fc-r',\n",
       " 'Samba-1 Turbo',\n",
       " 'e5-mistral-7B-instruct',\n",
       " 'meta-llama-3.1-70b',\n",
       " 'numind--NuExtract-1.5-tiny',\n",
       " 'qwen_llama_salesforce']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([m[\"model_checkpoint_name\"] for m in available_models])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eeb8b8-cd74-4774-a136-7946da862ff1",
   "metadata": {},
   "source": [
    "#### Select model to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d0d8fed-196a-4d92-9d90-77a4e201c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = \"numind--NuExtract-1.5-tiny\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d7d7b2-1c53-43a4-bdcd-1791441f6bd3",
   "metadata": {},
   "source": [
    "## 5. Create endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d236474a-19eb-42d5-afa8-338ffcc519ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = selected_model.lower().replace('_','-')\n",
    "endpoint = sn_env.create_endpoint(\n",
    "    project=project_name,\n",
    "    endpoint_name=endpoint_name,\n",
    "    description=\"Endpoint for \" + selected_model,\n",
    "    model_checkpoint=selected_model,\n",
    "    model_version=1,\n",
    "    instances=1,\n",
    "    hyperparams='{\"model_parallel_rdus\": \"16\", \"num_tokens_at_a_time\": \"10\"}',\n",
    "    rdu_arch=\"SN40L-16\",\n",
    "    inference_api_openai_compatible=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a168050-e6fd-40a6-9518-1824649e443f",
   "metadata": {},
   "source": [
    "#### Check the status of the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3a6a5f-daa8-4f01-8837-b7b288ae45e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SettingUp'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = sn_env.endpoint_info(project_name, endpoint_name)\n",
    "endpoint['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341c9f89-306c-4c3e-8aaf-adfa62f5f72c",
   "metadata": {},
   "source": [
    "## 6. Get Endpoint Details\n",
    "To test the endpoint, we will need to obtain some of its information. Note that this information can be obtained even while the model is setting up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc860c4-ff8e-48be-9707-1d6339dd07da",
   "metadata": {},
   "source": [
    "#### Get the endpoint URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a408fcb-43a5-4a43-9ff8-03f1e85fce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = os.getenv(\"SAMBASTUDIO_HOST_NAME\") + \"/v1/\" + endpoint[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ca1ba7-6c78-44aa-b88a-d46ca708cacb",
   "metadata": {},
   "source": [
    "#### Get the default endpoint API key\n",
    "Note that:\n",
    "  - New keys can be added using the `sn_env.add_endpoint_api_key` API.    \n",
    "  - All keys can be revoked using the `sn_env.edit_endpoint_api_key` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48ada26e-d8bf-40b1-9a51-f6654aca3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_key = endpoint[\"api_keys\"][0][\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09814c6-d819-4c9d-af89-16c4a3ea2336",
   "metadata": {},
   "source": [
    "#### Get model names in the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "071b9498-7c3b-49fa-8108-5580dad2ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_model_id = endpoint['targets'][0][\"model\"]\n",
    "model_info = sn_env.model_info(endpoint_model_id, job_type=\"deploy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c963fe6f-e4c4-4941-9a70-746ddba81a25",
   "metadata": {},
   "source": [
    "#### Check if the model is standalone or composite (bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7643d855-809f-459e-9ada-0aa0439d8337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Basic'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info[\"type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a26b5f-c0fa-471b-a932-3a549ae96cbe",
   "metadata": {},
   "source": [
    "## 7. Test Endpoint\n",
    "Once the endpoint is live, you can test it using the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b659dc-f5ca-4f47-a466-213ea972663b",
   "metadata": {},
   "source": [
    "#### Make sure endpoint is live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc7cf06e-2a85-478d-9431-b4a169292afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Live'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = sn_env.endpoint_info(project_name, endpoint_name)\n",
    "endpoint['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3542e4-fee3-4b98-8366-f1e039cf10f3",
   "metadata": {},
   "source": [
    "#### Create test messages to send to the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bde38fee-2a62-48be-b8f7-2194721782b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"\"\"<|input|>\n",
    " ### Template:\n",
    " {\n",
    "    \"Model\": {\n",
    "        \"Name\": \"\",\n",
    "        \"Number of parameters\": \"\",\n",
    "        \"Number of max token\": \"\",\n",
    "        \"Architecture\": []\n",
    "    },\n",
    "    \"Usage\": {\n",
    "        \"Use case\": [],\n",
    "        \"Licence\": \"\"\n",
    "    }\n",
    "}\n",
    "### Text:\n",
    "We introduce Mistral 7B, a 7–billion-parameter language model engineered for\n",
    "superior performance and efficiency. Mistral 7B outperforms the best open 13B\n",
    "model (Llama 2) across all evaluated benchmarks, and the best released 34B\n",
    "model (Llama 1) in reasoning, mathematics, and code generation. Our model\n",
    "leverages grouped-query attention (GQA) for faster inference, coupled with sliding\n",
    "window attention (SWA) to effectively handle sequences of arbitrary length with a\n",
    "reduced inference cost. We also provide a model fine-tuned to follow instructions,\n",
    "Mistral 7B – Instruct, that surpasses Llama 2 13B – chat model both on human and\n",
    "automated benchmarks. Our models are released under the Apache 2.0 license.\n",
    "Code: <https://github.com/mistralai/mistral-src>\n",
    "Webpage: <https://mistral.ai/news/announcing-mistral-7b/>\n",
    "<|output|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07484641-1bd0-45de-8182-ff0033c06c40",
   "metadata": {},
   "source": [
    "#### Send test messsages to the endpoint\n",
    "In this example, we test all the constituents of the model bundle. An endpoint may only have one model deployed, in which case this test can be done against that model alone.\n",
    "\n",
    "**Note: If a model uses speculative decoding, its name will not match the name expected by the endpoint. Instead, we need to get and use the name of the target model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3355aefd-3d72-4bf8-81e3-f9dc7f25784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Model\": {\n",
      "        \"Name\": \"Mistral 7B\",\n",
      "        \"Number of parameters\": \"7\\u2013billion\",\n",
      "        \"Number of max token\": \"\",\n",
      "        \"Architecture\": [\n",
      "            \"grouped-query attention\",\n",
      "            \"sliding window attention\"\n",
      "        ]\n",
      "    },\n",
      "    \"Usage\": {\n",
      "        \"Use case\": [\n",
      "            \"superior performance and efficiency\",\n",
      "            \"reasoning\",\n",
      "            \"mathematics\",\n",
      "            \"code generation\"\n",
      "        ],\n",
      "        \"Licence\": \"Apache 2.0\"\n",
      "    }\n",
      "}\n",
      "  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=endpoint_key,\n",
    "    base_url=endpoint_url,\n",
    ")\n",
    "  \n",
    "model_name = selected_model\n",
    "\n",
    "# Check for speculative decoding\n",
    "constituent_info = sn_env.model_info(selected_model, job_type=\"deploy\")\n",
    "if 'target_model' in constituent_info['config']:\n",
    "    target_name = constituent_info['config']['target_model']        \n",
    "    if len(target_name) > 0:\n",
    "        model_name = target_name\n",
    "\n",
    "# Send messages to endpoint\n",
    "response = client.completions.create(\n",
    "    model=model_name,\n",
    "    prompt=test_prompt,    \n",
    "    temperature=0.01\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898a89c-b517-447b-b9e4-e4684c04e82e",
   "metadata": {},
   "source": [
    "## 8. Stopping/deleting an Endpoint\n",
    "An endpoint can be:\n",
    "  - stopped: sn_env.stop_endpoint(project_name, endpoint_name)\n",
    "  - deleted: sn_env.delete_endpoint(project_name, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985fd077-68ca-4c6c-a804-7a9423d1e545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_11_autogen",
   "language": "python",
   "name": "py_3_11_autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
