{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook Covers the steps needed to implement Function calling capabilities with Sambastudio and Sambaverse models, leveraging Langchain Tools and Langchain integrations \n",
    "\n",
    "We also provide the [FunctionCallingLlm module](../src/function_calling.py) and the [usage notebook](./usage.ipynb), these can be used as a quick start to use function calling, and this notebook can be used as a guide for further customizing your function calling model and tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import operator\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, Union\n",
    "from langchain_community.llms.sambanova import SambaStudio, Sambaverse\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import StructuredTool, ToolException, Tool, tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(False)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "load_dotenv(os.path.join(repo_dir, '.env'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are defined several langchain tools and custom tools showing different. ways of implementing them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most simple way of implementing a custom langchain tool is using the `@tool` decorator and defining your arguments schema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get time tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool schema\n",
    "class GetTimeSchema(BaseModel):\n",
    "    \"\"\"Returns current date, current time or both.\"\"\"\n",
    "\n",
    "    kind: Optional[str] = Field(description='kind of information to retrieve \"date\", \"time\" or \"both\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition using @tool decorator\n",
    "@tool(args_schema=GetTimeSchema)\n",
    "def get_time(kind: str = 'both') -> str:\n",
    "    \"\"\"Returns current date, current time or both.\n",
    "\n",
    "    Args:\n",
    "        kind: date, time or both\n",
    "    \"\"\"\n",
    "    if kind == 'date':\n",
    "        date = datetime.now().strftime('%d/%m/%Y')\n",
    "        return f'Current date: {date}'\n",
    "    elif kind == 'time':\n",
    "        time = datetime.now().strftime('%H:%M:%S')\n",
    "        return f'Current time: {time}'\n",
    "    else:\n",
    "        date = datetime.now().strftime('%d/%m/%Y')\n",
    "        time = datetime.now().strftime('%H:%M:%S')\n",
    "        return f'Current date: {date}, Current time: {time}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current time: 10:48:41'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time.invoke({'kind': 'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'GetTimeSchema',\n",
       " 'description': 'Returns current date, current time or both.',\n",
       " 'type': 'object',\n",
       " 'properties': {'kind': {'title': 'Kind',\n",
       "   'description': 'kind of information to retrieve \"date\", \"time\" or \"both\"',\n",
       "   'type': 'string'}}}"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized error handling tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a more complex tool that is able to raise specific tool error with some information, that can be send to the llm in order to fix the original call if its possible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculator tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool schema\n",
    "class CalculatorSchema(BaseModel):\n",
    "    \"\"\"allow calculation of only basic operations: + - * and /\n",
    "    with a string input expression\"\"\"\n",
    "\n",
    "    expression: str = Field(..., description=\"expression to calculate, example '12 * 3'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to use in the tool\n",
    "def calculator(expression: str) -> Union[str, int, float]:\n",
    "    \"\"\"\n",
    "    allow calculation of basic operations\n",
    "    with a string input expression\n",
    "    Args:\n",
    "        expression: expression to calculate\n",
    "    \"\"\"\n",
    "    ops = {\n",
    "        '+': operator.add,\n",
    "        '-': operator.sub,\n",
    "        '*': operator.mul,\n",
    "        'x': operator.mul,\n",
    "        'X': operator.mul,\n",
    "        '÷': operator.truediv,\n",
    "        '/': operator.truediv,\n",
    "    }\n",
    "    tokens = re.findall(r'\\d+\\.?\\d*|\\+|\\-|\\*|\\/|÷|x|X', expression)\n",
    "\n",
    "    if len(tokens) == 0:\n",
    "        raise ToolException(\n",
    "            f\"Invalid expression '{expression}', should only contain one of the following operators + - * x and ÷\"\n",
    "        )\n",
    "\n",
    "    current_value = float(tokens.pop(0))\n",
    "\n",
    "    while len(tokens) > 0:\n",
    "        # The next token should be an operator\n",
    "        op = tokens.pop(0)\n",
    "\n",
    "        # The next token should be a number\n",
    "        if len(tokens) == 0:\n",
    "            raise ToolException(f\"Incomplete expression '{expression}'\")\n",
    "        try:\n",
    "            next_value = float(tokens.pop(0))\n",
    "\n",
    "        except ValueError:\n",
    "            raise ToolException('Invalid number format')\n",
    "\n",
    "        except:\n",
    "            raise ToolException('Invalid operation')\n",
    "\n",
    "        # check division by 0\n",
    "        if op in ['/', '÷'] and next_value == 0:\n",
    "            raise ToolException('cannot divide by 0')\n",
    "\n",
    "        current_value = ops[op](current_value, next_value)\n",
    "\n",
    "    result = current_value\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# tool error handler\n",
    "def _handle_error(error: ToolException) -> str:\n",
    "    return f'The following errors occurred during Calculator tool execution: `{error.args}`'\n",
    "\n",
    "\n",
    "# tool definition\n",
    "calculator = StructuredTool.from_function(\n",
    "    func=calculator,\n",
    "    args_schema=CalculatorSchema,\n",
    "    handle_tool_error=_handle_error,  # set as True if you want the tool to trow a generic ToolError message \"Tool execution error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421.59999999999997"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.invoke('18*23.7 -5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The following errors occurred during Calculator tool execution: `('cannot divide by 0',)`\""
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.invoke('7 / 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'CalculatorSchema',\n",
       " 'description': 'allow calculation of only basic operations: + - * and /\\nwith a string input expression',\n",
       " 'type': 'object',\n",
       " 'properties': {'expression': {'title': 'Expression',\n",
       "   'description': \"expression to calculate, example '12 * 3'\",\n",
       "   'type': 'string'}},\n",
       " 'required': ['expression']}"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(There are several built-in tools available in langchain library that can be directly used by the model, you can find a list of available tools [here](https://python.langchain.com/v0.1/docs/integrations/tools/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python standard shell, or REPL (Read-Eval-Print Loop) tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool schema\n",
    "class ReplSchema(BaseModel):\n",
    "    \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\"\n",
    "\n",
    "    command: str = Field(..., description='python code to evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool definition\n",
    "python_repl = PythonREPL()\n",
    "python_repl = Tool(\n",
    "    name='python_repl',\n",
    "    description='A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.',\n",
    "    func=python_repl.run,\n",
    "    args_schema=ReplSchema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0\\n1\\n2\\n3\\n4\\n'"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl.invoke({'command': 'for i in range(0,5):\\n\\tprint(i)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ReplSchema',\n",
       " 'description': 'A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.',\n",
       " 'type': 'object',\n",
       " 'properties': {'command': {'title': 'Command',\n",
       "   'description': 'python code to evaluate',\n",
       "   'type': 'string'}},\n",
       " 'required': ['command']}"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL calling tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool is a demonstration of how to implement an SQL query tool leveraging the build in QuerySQLDataBaseTool langchain tool, for this example we are passing the db schema to Llama3 8B model, but you can get better performance with your own fine tuned model.\n",
    ">For fine tuning your own sql model go to [fine_tuning_sql kit](../../fine_tuning_sql/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['albums', 'artists', 'customers', 'employees', 'genres', 'invoice_items', 'invoices', 'media_types', 'playlist_track', 'playlists', 'tracks']\n",
      "[(1, 'Rock'), (2, 'Jazz'), (3, 'Metal'), (4, 'Alternative & Punk'), (5, 'Rock And Roll'), (6, 'Blues'), (7, 'Latin'), (8, 'Reggae'), (9, 'Pop'), (10, 'Soundtrack'), (11, 'Bossa Nova'), (12, 'Easy Listening'), (13, 'Heavy Metal'), (14, 'R&B/Soul'), (15, 'Electronica/Dance'), (16, 'World'), (17, 'Hip Hop/Rap'), (18, 'Science Fiction'), (19, 'TV Shows'), (20, 'Sci Fi & Fantasy'), (21, 'Drama'), (22, 'Comedy'), (23, 'Alternative'), (24, 'Classical'), (25, 'Opera')]\n"
     ]
    }
   ],
   "source": [
    "# example sql query call\n",
    "db_path = os.path.join(kit_dir, 'data/chinook.db')\n",
    "db_uri = f'sqlite:///{db_path}'\n",
    "db = SQLDatabase.from_uri(db_uri)\n",
    "print(db.get_usable_table_names())\n",
    "print(db.run('SELECT * FROM genres;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool schema\n",
    "class QueryDBSchema(BaseModel):\n",
    "    \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\"\n",
    "\n",
    "    query: str = Field(..., description='natural language question or instruction.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_finder(text):\n",
    "    \"\"\"Search in a string for a SQL query or code with format\"\"\"\n",
    "\n",
    "    # regex for finding sql_code_pattern with format:\n",
    "    # ```sql\n",
    "    #    <query>\n",
    "    # ```\n",
    "    sql_code_pattern = re.compile(r'```sql\\s+(.*?)\\s+```', re.DOTALL)\n",
    "    match = sql_code_pattern.search(text)\n",
    "    if match is not None:\n",
    "        query = match.group(1)\n",
    "        return query\n",
    "    else:\n",
    "        # regex for finding sql_code_pattern with format:\n",
    "        # ```\n",
    "        # <quey>\n",
    "        # ```\n",
    "        code_pattern = re.compile(r'```\\s+(.*?)\\s+```', re.DOTALL)\n",
    "        match = code_pattern.search(text)\n",
    "        if match is not None:\n",
    "            query = match.group(1)\n",
    "            return query\n",
    "        else:\n",
    "            raise Exception('No SQL code found in LLM generation')\n",
    "\n",
    "\n",
    "@tool(args_schema=QueryDBSchema)\n",
    "def query_db(query):\n",
    "    \"\"\"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\"\"\"\n",
    "\n",
    "    # Using Sambaverse expert as model for generating the SQL Query\n",
    "    # llm = Sambaverse(\n",
    "    #     sambaverse_model_name='Meta/Meta-Llama-3-8B-Instruct',\n",
    "    #     streaming=True,\n",
    "    #     model_kwargs={\n",
    "    #         'max_tokens_to_generate': 512,\n",
    "    #         'select_expert': 'Meta-Llama-3-8B-Instruct',\n",
    "    #         'temperature': 0.0,\n",
    "    #         'repetition_penalty': 1.0,\n",
    "    #         'top_k': 1,\n",
    "    #         'top_p': 1.0,\n",
    "    #         'do_sample': False,\n",
    "    #         'process_prompt': True,\n",
    "    #     },\n",
    "    # )\n",
    "\n",
    "    # Using SambaStudio CoE expert as model for generating the SQL Query\n",
    "    llm = SambaStudio(\n",
    "        streaming=True,\n",
    "        model_kwargs={\n",
    "            'max_tokens_to_generate': 512,\n",
    "            'select_expert': 'Meta-Llama-3-8B-Instruct',\n",
    "            'temperature': 0.0,\n",
    "            'repetition_penalty': 1.0,\n",
    "            'top_k': 1,\n",
    "            'top_p': 1.0,\n",
    "            'do_sample': False,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "        \n",
    "        {table_info}\n",
    "        \n",
    "        Generate a query using valid SQLite to answer the following questions for the summarized tables schemas provided above.\n",
    "        Do not assume the values on the database tables before generating the SQL query, always generate a SQL that query what is asked.\n",
    "        The query must be in the format: ```sql\\nquery\\n```\n",
    "        \n",
    "        Example:\n",
    "        \n",
    "        ```sql\n",
    "        SELECT * FROM mainTable;\n",
    "        ```\n",
    "        \n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\\\n",
    "            \n",
    "        {input}\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "    )\n",
    "\n",
    "    # Chain that receives the natural language input and the table schema, then pass the teh formmated prompt to the llm\n",
    "    # and finally execute the sql finder method, retrieving only the filtered SQL query\n",
    "    query_generation_chain = prompt | llm | RunnableLambda(sql_finder)\n",
    "    table_info = db.get_table_info()\n",
    "    query = query_generation_chain.invoke({'input': query, 'table_info': table_info})\n",
    "    print(query)\n",
    "    query_executor = QuerySQLDataBaseTool(db=db)\n",
    "    result = query_executor.invoke(query)\n",
    "\n",
    "    result = f'Query {query} executed with result {result}'\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examples of query_db tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) \n",
      "FROM genres;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Query SELECT COUNT(*) \\nFROM genres; executed with result [(25,)]'"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'How many genres of music are in the chinook db'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO genres (GenreId, Name)\n",
      "VALUES ((SELECT MAX(GenreId) + 1 FROM genres), 'Salsa');\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Query INSERT INTO genres (GenreId, Name)\\nVALUES ((SELECT MAX(GenreId) + 1 FROM genres), 'Salsa'); executed with result \""
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'add a new genre in the chinook db called Salsa'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) \n",
      "FROM genres;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Query SELECT COUNT(*) \\nFROM genres; executed with result [(26,)]'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'How many genres of music are in the chinook db'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT t.Name, t.Milliseconds\n",
      "FROM tracks t\n",
      "ORDER BY t.Milliseconds DESC\n",
      "LIMIT 1;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Query SELECT t.Name, t.Milliseconds\\nFROM tracks t\\nORDER BY t.Milliseconds DESC\\nLIMIT 1; executed with result [('Occupation / Precipice', 5286953)]\""
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'What is the longest track in the chinook db'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * \n",
      "FROM invoices \n",
      "ORDER BY Total DESC \n",
      "LIMIT 5;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Query SELECT * \\nFROM invoices \\nORDER BY Total DESC \\nLIMIT 5; executed with result [(404, 6, '2013-11-13 00:00:00', 'Rilská 3174/6', 'Prague', None, 'Czech Republic', '14300', 25.86), (299, 26, '2012-08-05 00:00:00', '2211 W Berry Street', 'Fort Worth', 'TX', 'USA', '76110', 23.86), (96, 45, '2010-02-18 00:00:00', 'Erzsébet krt. 58.', 'Budapest', None, 'Hungary', 'H-1073', 21.86), (194, 46, '2011-04-28 00:00:00', '3 Chatham Street', 'Dublin', 'Dublin', 'Ireland', None, 21.86), (89, 7, '2010-01-18 00:00:00', 'Rotenturmstraße 4, 1010 Innere Stadt', 'Vienne', None, 'Austria', '1010', 18.86)]\""
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'list of the 5 highest value invoices registered in the database'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO tracks (Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice)\n",
      "VALUES ('El Preso', NULL, 1, 3, 'Fruco y sus tesos', 123000, NULL, 1.2);\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Query INSERT INTO tracks (Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice)\\nVALUES ('El Preso', NULL, 1, 3, 'Fruco y sus tesos', 123000, NULL, 1.2); executed with result \""
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke(\n",
    "    {\n",
    "        'query': 'add in the db a new song called \"El Preso\" from the artist \"Fruco y sus tesos\", with a duration 123000 seconds with a price of 1.2 usd'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Composer\n",
      "FROM tracks\n",
      "WHERE Name = 'El Preso';\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Query SELECT Composer\\nFROM tracks\\nWHERE Name = 'El Preso'; executed with result [('Fruco y sus tesos',)]\""
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'who is the composer of the song with name \"El Preso\"'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE movies (\n",
      "    \"MovieId\" INTEGER PRIMARY KEY,\n",
      "    \"MovieTitle\" NVARCHAR(200) NOT NULL\n",
      ");\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Query CREATE TABLE movies (\\n    \"MovieId\" INTEGER PRIMARY KEY,\\n    \"MovieTitle\" NVARCHAR(200) NOT NULL\\n); executed with result '"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke(\n",
    "    {'query': 'create a new table in the chinook db called movies, with a column for id and column for movieTitle'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO movies (MovieId, MovieTitle)\n",
      "VALUES (NULL, 'Star Wars');\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Query INSERT INTO movies (MovieId, MovieTitle)\\nVALUES (NULL, 'Star Wars'); executed with result \""
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for exectuing this query it is needed to reinitialize the query db to get the new schema including movies table\n",
    "query_db.invoke({'query': 'add a new register in movies table for \"star wars\"'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default response tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a default tool to return conversational responses to the user, for this we will only define the schema of the tool and manually handle the behavior of the system when this tool is called by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ConversationalResponse',\n",
       " 'description': 'Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query',\n",
       " 'type': 'object',\n",
       " 'properties': {'response': {'title': 'Response',\n",
       "   'description': 'Conversational response to the user. must be in the same language as the user query',\n",
       "   'type': 'string'}},\n",
       " 'required': ['response']}"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tool schema\n",
    "class ConversationalResponse(BaseModel):\n",
    "    \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\"\n",
    "\n",
    "    response: str = Field(\n",
    "        ..., description='Conversational response to the user. must be in the same language as the user query'\n",
    "    )\n",
    "\n",
    "\n",
    "ConversationalResponse.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tools_schemas(tools: Union[Tool, list] = None, default: Union[Tool, BaseModel] = None):\n",
    "    if tools is None or isinstance(tools, list):\n",
    "        pass\n",
    "    elif isinstance(tools, Tool) or isinstance(tools, StructuredTool):\n",
    "        tools = [tools]\n",
    "    else:\n",
    "        raise TypeError('tools must be a Tool or a list of Tools')\n",
    "\n",
    "    tools_schemas = []\n",
    "\n",
    "    for tool in tools:\n",
    "        tool_schema = tool.get_input_schema().schema()\n",
    "        schema = {'name': tool.name, 'description': tool_schema['description'], 'properties': tool_schema['properties']}\n",
    "        if 'required' in schema:\n",
    "            schema['required'] = tool_schema['required']\n",
    "        tools_schemas.append(schema)\n",
    "\n",
    "    if default is not None:\n",
    "        if isinstance(default, Tool) or isinstance(default, StructuredTool):\n",
    "            tool_schema = default.get_input_schema().schema()\n",
    "        elif issubclass(default, BaseModel):\n",
    "            tool_schema = default.schema()\n",
    "        else:\n",
    "            raise TypeError('default must be a Tool or a BaseModel')\n",
    "        schema = {\n",
    "            'name': tool_schema['title'],\n",
    "            'description': tool_schema['description'],\n",
    "            'properties': tool_schema['properties'],\n",
    "        }\n",
    "        if 'required' in schema:\n",
    "            schema['required'] = tool_schema['required']\n",
    "        tools_schemas.append(schema)\n",
    "\n",
    "    return tools_schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_time, calculator, python_repl, query_db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\\n'\n",
      " '  \"name\": \"get_time\",\\n'\n",
      " '  \"description\": \"Returns current date, current time or both.\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"kind\": {\\n'\n",
      " '      \"title\": \"Kind\",\\n'\n",
      " '      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" '\n",
      " 'or \\\\\"both\\\\\"\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}\\n'\n",
      " '{\\n'\n",
      " '  \"name\": \"calculator\",\\n'\n",
      " '  \"description\": \"allow calculation of only basic operations: + - * and '\n",
      " '/\\\\nwith a string input expression\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"expression\": {\\n'\n",
      " '      \"title\": \"Expression\",\\n'\n",
      " '      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}\\n'\n",
      " '{\\n'\n",
      " '  \"name\": \"python_repl\",\\n'\n",
      " '  \"description\": \"A Python shell. Use this to evaluate python commands. '\n",
      " 'Input should be a valid python commands and expressions. If you want to see '\n",
      " 'the output of a value, you should print it out with `print(...)`, if you '\n",
      " 'need a specific module you should import it.\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"command\": {\\n'\n",
      " '      \"title\": \"Command\",\\n'\n",
      " '      \"description\": \"python code to evaluate\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}\\n'\n",
      " '{\\n'\n",
      " '  \"name\": \"query_db\",\\n'\n",
      " '  \"description\": \"A query generation tool. Use this to generate sql queries '\n",
      " 'and retrieve the results from a database. Do not pass sql queries directly. '\n",
      " 'Input must be a natural language question or instruction.\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"query\": {\\n'\n",
      " '      \"title\": \"Query\",\\n'\n",
      " '      \"description\": \"natural language question or instruction.\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}\\n'\n",
      " '{\\n'\n",
      " '  \"name\": \"ConversationalResponse\",\\n'\n",
      " '  \"description\": \"Respond conversationally only if no other tools should be '\n",
      " 'called for a given query, or if you have a final answer. response must be in '\n",
      " 'the same language as the user query\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"response\": {\\n'\n",
      " '      \"title\": \"Response\",\\n'\n",
      " '      \"description\": \"Conversational response to the user. must be in the '\n",
      " 'same language as the user query\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "tools_schemas = get_tools_schemas(tools, default=ConversationalResponse)\n",
    "tools_schemas = '\\n'.join([json.dumps(tool, indent=2) for tool in tools_schemas])\n",
    "pprint(tools_schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sambaverse CoE expert as model for tool calling\n",
    "# llm = Sambaverse(\n",
    "#     sambaverse_model_name='Meta/Meta-Llama-3-70B-Instruct',\n",
    "#     model_kwargs={\n",
    "#         'max_tokens_to_generate': 2048,\n",
    "#         'select_expert': 'Meta-Llama-3-70B-Instruct',\n",
    "#         'process_prompt': True,\n",
    "#         'temperature': 0.01,\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# Using SambaStudio CoE expert as model for tool calling\n",
    "llm = SambaStudio(\n",
    "    streaming=True,\n",
    "    model_kwargs={\n",
    "        'max_tokens_to_generate': 2048,\n",
    "        'select_expert': 'Meta-Llama-3-70B-Instruct',\n",
    "        'process_prompt': False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of som util methods to parse the llm output and invoke available tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_map = {'get_time': get_time, 'calculator': calculator, 'python_repl': python_repl, 'query_db': query_db}\n",
    "\n",
    "\n",
    "def execute(tools):\n",
    "    \"\"\"\n",
    "    Given a list of tool executions the llm return as required\n",
    "    execute them given the name with the mane in tools_map and the input arguments\n",
    "    if there is only one tool call and it is default conversational one, the response is marked as final response\n",
    "    \"\"\"\n",
    "    tool_msg = \"Tool '{name}'response: {response}\"\n",
    "    tools_msgs = []\n",
    "    if len(tools) == 1 and tools[0]['tool'].lower() == 'conversationalresponse':\n",
    "        final_answer = True\n",
    "        return final_answer, tools[0]['tool_input']['response']\n",
    "    for tool in tools:\n",
    "        final_answer = False\n",
    "        if tool['tool'].lower() != 'conversationalresponse':\n",
    "            response = tools_map[tool['tool'].lower()].invoke(tool['tool_input'])\n",
    "            tools_msgs.append(tool_msg.format(name=tool['tool'], response=str(response)))\n",
    "    return final_answer, tools_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonFinder(input_string):\n",
    "    \"\"\"\n",
    "    find json structures ina  llm string response, if bad formatted using LLM to correct it\n",
    "    \"\"\"\n",
    "    json_pattern = re.compile(r'(\\{.*\\}|\\[.*\\])', re.DOTALL)\n",
    "    # Find the first JSON structure in the string\n",
    "    json_match = json_pattern.search(input_string)\n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "        try:\n",
    "            json.loads(json_str)\n",
    "        except:\n",
    "            json_correction_prompt = \"\"\"|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a json format corrector tool<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "            fix the following json file: {json} \n",
    "            <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "            fixed json: \"\"\"\n",
    "            json_correction_prompt_template = PromptTemplate.from_template(json_correction_prompt)\n",
    "            json_correction_chain = json_correction_prompt_template | llm\n",
    "            json_str = json_correction_chain.invoke(json_str)\n",
    "    else:\n",
    "        # implement here not finding json format parsing to json or error rising\n",
    "        json_str = None\n",
    "    return json_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agentic prompt template for function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_function_calling_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an helpful assistant and you have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "You must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\n",
    "\n",
    "```json\n",
    "[{{\n",
    "  \"tool\": <name of the selected tool>,\n",
    "  \"tool_input\": <parameters for the selected tool, matching the tool's JSON schema>\n",
    "}}]\n",
    "```\n",
    "\n",
    "Think step by step\n",
    "Do not call a tool if the input depends on another tool output you dont have yet.\n",
    "Do not try to answer until you get tools output, if you dont have an answer yet you can continue calling tools until you do..\n",
    "Your answer should be in the same language as the initial query.\n",
    "\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "User: {usr_msg} \n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "Assistant:\"\"\"\n",
    "\n",
    "function_calling_prompt_template = PromptTemplate.from_template(example_function_calling_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json parsing Chain for parsing tool calling output from llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_parsing_chain = RunnableLambda(jsonFinder) | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain for passing through the tools schemas to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = {\n",
    "    'tools': lambda x: tools_schemas,\n",
    "    'usr_msg': RunnablePassthrough(),\n",
    "} | function_calling_prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of chin to do one full pass of the query to the model \n",
    "Here we will see the first tool execution call generated by the model and the result of this first execution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_fc_chain = prompt_template | llm | json_parsing_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'ConversationalResponse', 'tool_input': {'response': 'Hi! How can I assist you today?'}}]\n",
      "Hi! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = 'hi'\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "print(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'get_time', 'tool_input': {'kind': 'time'}}]\n",
      "[\"Tool 'get_time'response: Current time: 10:58:40\"]\n"
     ]
    }
   ],
   "source": [
    "query = 'it is time to go to sleep?'\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "pprint(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'calculator', 'tool_input': {'expression': '347 / 60'}}]\n",
      "[\"Tool 'calculator'response: 5.783333333333333\"]\n"
     ]
    }
   ],
   "source": [
    "query = 'whats is 347 min in hours and minutes?'\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "print(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'python_repl',\n",
      "  'tool_input': {'command': \"print('saippuakivikauppias' \"\n",
      "                            \"=='saippuakivikauppias'[::-1])\"}}]\n",
      "[\"Tool 'python_repl'response: True\\n\"]\n"
     ]
    }
   ],
   "source": [
    "query = \"is this word is a palindrome? 'saippuakivikauppias'\"\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "pprint(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'python_repl',\n",
      "  'tool_input': {'command': \"print(sorted(['screwdriver', 'pliers', \"\n",
      "                            \"'hammer']))\"}}]\n",
      "[\"Tool 'python_repl'response: ['hammer', 'pliers', 'screwdriver']\\n\"]\n"
     ]
    }
   ],
   "source": [
    "query = \"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\"\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "pprint(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are defining a iterative pipeline to give the model the ability of getting the tools execution as inputs and continue generating the answer until having a final response "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the system message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_calling_system_prompt = \"\"\"you are an helpful assistant and you have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "You must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\n",
    "\n",
    "```json\n",
    "[{{\n",
    "  \"tool\": <name of the selected tool>,\n",
    "  \"tool_input\": <parameters for the selected tool, matching the tool's JSON schema>\n",
    "}}]\n",
    "```\n",
    "\n",
    "Think step by step\n",
    "Do not call a tool if the input depends on another tool output that you do not have yet\n",
    "Do not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\n",
    "Your answer should be in the same language as the initial query.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of chat prompt template, having as first interaction the system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['tools'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tools'], template='you are an helpful assistant and you have access to the following tools:\\n\\n{tools}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n'))])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_calling_chat_template = ChatPromptTemplate.from_messages([('system', function_calling_system_prompt)])\n",
    "function_calling_chat_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility to add convert and format each interaction from the user, model or tool to a langchain message with role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msgs_to_llama3_str(msgs: list):\n",
    "    \"\"\"\n",
    "    convert a list of langchain messages with roles to expected LLmana 3 input\n",
    "    \"\"\"\n",
    "    formatted_msgs = []\n",
    "    for msg in msgs:\n",
    "        if msg.type == 'system':\n",
    "            sys_placeholder = '<|begin_of_text|><|start_header_id|>system<|end_header_id|> {msg}'\n",
    "            formatted_msgs.append(sys_placeholder.format(msg=msg.content))\n",
    "        elif msg.type == 'human':\n",
    "            human_placeholder = '<|eot_id|><|start_header_id|>user<|end_header_id|>\\nUser: {msg} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\nAssistant:'\n",
    "            formatted_msgs.append(human_placeholder.format(msg=msg.content))\n",
    "        elif msg.type == 'ai':\n",
    "            assistant_placeholder = '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\nAssistant: {msg}'\n",
    "            formatted_msgs.append(assistant_placeholder.format(msg=msg.content))\n",
    "        elif msg.type == 'tool':\n",
    "            tool_placeholder = '<|eot_id|><|start_header_id|>tools<|end_header_id|>\\n{msg} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\nAssistant:'\n",
    "            formatted_msgs.append(tool_placeholder.format(msg=msg.content))\n",
    "        else:\n",
    "            raise ValueError(f'Invalid message type: {msg.type}')\n",
    "    return '\\n'.join(formatted_msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting everything together to have an iterative/agentic pipeline for doing function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_call_llm(query, max_it=5, debug=False):\n",
    "    \"\"\"\n",
    "    invocation method for function calling workflow\n",
    "    \"\"\"\n",
    "    history = function_calling_chat_template.format_prompt(tools=tools_schemas).to_messages()\n",
    "    history.append(HumanMessage(query))\n",
    "    tool_call_id = 0  # identification for each tool calling required to create ToolMessages\n",
    "\n",
    "    for i in range(max_it):\n",
    "        prompt = msgs_to_llama3_str(history)\n",
    "        llm_response = llm.invoke(prompt)\n",
    "        parsed_tools_llm_response = json_parsing_chain.invoke(llm_response)\n",
    "        history.append(AIMessage(llm_response))\n",
    "        final_answer, tools_msgs = execute(parsed_tools_llm_response)\n",
    "        if final_answer:\n",
    "            final_response = tools_msgs\n",
    "            if debug:\n",
    "                pprint(history)\n",
    "            return final_response\n",
    "        else:\n",
    "            history.append(ToolMessage('\\n'.join(tools_msgs), tool_call_id=tool_call_id))\n",
    "            tool_call_id += 1\n",
    "\n",
    "    raise Exception('not a final response yet', json.dumps(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"title\": \"Kind\",\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"title\": \"Expression\",\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"title\": \"Command\",\\n      \"description\": \"python code to evaluate\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"title\": \"Query\",\\n      \"description\": \"natural language question or instruction.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer.\",\\n  \"properties\": {\\n    \"response\": {\\n      \"title\": \"Response\",\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\n\\n'),\n",
      " HumanMessage(content='what time is it?'),\n",
      " AIMessage(content=' \\n\\n[{\\n  \"tool\": \"get_time\",\\n  \"tool_input\": {\\n    \"kind\": \"both\"\\n  }\\n}]'),\n",
      " ToolMessage(content=\"Tool 'get_time'response: Current date: 25/06/2024, Current time: 11:01:30\", tool_call_id='0'),\n",
      " AIMessage(content='  \\n\\n[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"The current date is 25/06/2024 and the time is 11:01:30.\"\\n  }\\n}]')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm('what time is it?', max_it=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current date is 25/06/2024 and the time is 11:01:30.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"title\": \"Kind\",\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"title\": \"Expression\",\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"title\": \"Command\",\\n      \"description\": \"python code to evaluate\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"title\": \"Query\",\\n      \"description\": \"natural language question or instruction.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer.\",\\n  \"properties\": {\\n    \"response\": {\\n      \"title\": \"Response\",\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\n\\n'),\n",
      " HumanMessage(content='it is time to go to sleep, how many hours last to 10pm?'),\n",
      " AIMessage(content=' \\n\\n[{\\n  \"tool\": \"get_time\",\\n  \"tool_input\": {\\n    \"kind\": \"time\"\\n  }\\n}]'),\n",
      " ToolMessage(content=\"Tool 'get_time'response: Current time: 11:01:33\", tool_call_id='0'),\n",
      " AIMessage(content='  \\n\\n[{\\n  \"tool\": \"calculator\",\\n  \"tool_input\": {\\n    \"expression\": \"22 - \" + \"11\"  # assuming the current hour is 11\\n  }\\n}, {\\n  \"tool\": \"calculator\",\\n  \"tool_input\": {\\n    \"expression\": \"60 - \" + \"1\"  # assuming the current minute is 1\\n  }\\n}]\\n'),\n",
      " ToolMessage(content=\"Tool 'calculator'response: 11.0\\nTool 'calculator'response: 59.0\", tool_call_id='1'),\n",
      " AIMessage(content='   \\n\\n[{\\n  \"tool\": \"calculator\",\\n  \"tool_input\": {\\n    \"expression\": \"11 - \" + \"1\"  # subtracting the hours\\n  }\\n}, {\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"You have \" + \"10\" + \" hours and \" + \"59\" + \" minutes left until 10pm.\"\\n  }\\n}]'),\n",
      " ToolMessage(content=\"Tool 'calculator'response: 10.0\", tool_call_id='2'),\n",
      " AIMessage(content='  \\n\\n[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"You have 10 hours and 59 minutes left until 10pm.\"\\n  }\\n}]')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm('it is time to go to sleep, how many hours last to 10pm?', max_it=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You have 10 hours and 59 minutes left until 10pm.'"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"title\": \"Kind\",\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"title\": \"Expression\",\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"title\": \"Command\",\\n      \"description\": \"python code to evaluate\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql querys and retrieve the results from a database. Do not pass sql querys directly Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"title\": \"Query\",\\n      \"description\": \"natural language question or instruction.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer.\",\\n  \"properties\": {\\n    \"response\": {\\n      \"title\": \"Response\",\\n      \"description\": \"Conversational response to the user.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\n\\n'),\n",
      " HumanMessage(content=\"is this word is a palindrome? 'saippuakivikauppias'\"),\n",
      " AIMessage(content='[{\\n  \"tool\": \"python_repl\",\\n  \"tool_input\": {\\n    \"command\": \"print(\\'saippuakivikauppias\\' ==\\'saippuakivikauppias\\'[::-1])\"\\n  }\\n}]'),\n",
      " ToolMessage(content=\"Tool 'python_repl'response: True\\n\", tool_call_id='0'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"Yes, the word\\'saippuakivikauppias\\' is a palindrome.\"\\n  }\\n}]')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm(\"is this word is a palindrome? 'saippuakivikauppias'\", max_it=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, the word'saippuakivikauppias' is a palindrome.\""
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"title\": \"Kind\",\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"title\": \"Expression\",\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"title\": \"Command\",\\n      \"description\": \"python code to evaluate\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql querys and retrieve the results from a database. Do not pass sql querys directly Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"title\": \"Query\",\\n      \"description\": \"natural language question or instruction.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer.\",\\n  \"properties\": {\\n    \"response\": {\\n      \"title\": \"Response\",\\n      \"description\": \"Conversational response to the user.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\n\\n'),\n",
      " HumanMessage(content=\"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\"),\n",
      " AIMessage(content='[\\n  {\\n    \"tool\": \"python_repl\",\\n    \"tool_input\": {\\n      \"command\": \"print(sorted([\\'screwdriver\\', \\'pliers\\', \\'hammer\\']))\"\\n    }\\n  }\\n]'),\n",
      " ToolMessage(content=\"Tool 'python_repl'response: ['hammer', 'pliers', 'screwdriver']\\n\", tool_call_id='0'),\n",
      " AIMessage(content='[\\n  {\\n    \"tool\": \"ConversationalResponse\",\\n    \"tool_input\": {\\n      \"response\": \"The sorted list is: [\\'hammer\\', \\'pliers\\',\\'screwdriver\\']\"\\n    }\\n  }\\n]')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm(\n",
    "    \"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\", max_it=5, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The sorted list is: ['hammer', 'pliers','screwdriver']\""
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT UnitPrice * 0.76 AS PriceUSD\n",
      "FROM tracks\n",
      "WHERE Name = 'Snowballed';\n",
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"title\": \"Kind\",\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"title\": \"Expression\",\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"title\": \"Command\",\\n      \"description\": \"python code to evaluate\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql querys and retrieve the results from a database. Do not pass sql querys directly Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"title\": \"Query\",\\n      \"description\": \"natural language question or instruction.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer.\",\\n  \"properties\": {\\n    \"response\": {\\n      \"title\": \"Response\",\\n      \"description\": \"Conversational response to the user.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\n\\n'),\n",
      " HumanMessage(content='whats the price in colombian pesos of the track \"Snowballed\" in the db if one usd is equal to 3800 cop?'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"query_db\",\\n  \"tool_input\": {\\n    \"query\": \"What is the price in USD of the track \\'Snowballed\\'?\"\\n  }\\n}]'),\n",
      " ToolMessage(content=\"Tool 'query_db'response: Query SELECT UnitPrice * 0.76 AS PriceUSD\\nFROM tracks\\nWHERE Name = 'Snowballed'; executed with result [(0.7524,)]\", tool_call_id='0'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"calculator\",\\n  \"tool_input\": {\\n    \"expression\": \"0.7524 * 3800\"\\n  }\\n}]'),\n",
      " ToolMessage(content=\"Tool 'calculator'response: 2859.12\", tool_call_id='1'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"The price of the track \\'Snowballed\\' in Colombian Pesos is 2859.12 COP.\"\\n  }\\n}]')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm(\n",
    "    'whats the price in colombian pesos of the track \"Snowballed\" in the db if one usd is equal to 3800 cop?',\n",
    "    max_it=5,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
