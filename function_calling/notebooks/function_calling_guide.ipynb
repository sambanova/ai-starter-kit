{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook Covers the steps needed to implement Function calling capabilities with SambaNova models, leveraging Langchain Tools and Langchain integrations \n",
    "\n",
    "We also provide the [FunctionCallingLlm module](../src/function_calling.py) and the [usage notebook](./usage.ipynb), these can be used as a quick start to use function calling, and this notebook can be used as a guide for further customizing your function calling model and tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import operator\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, Union, Type, List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import StructuredTool, ToolException, Tool, tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(False)\n",
    "\n",
    "# Get absolute paths for kit_dir and repo_dir\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "\n",
    "# Adding directories to the Python module search path\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from langchain_sambanova import ChatSambaNova\n",
    "\n",
    "# load env variables from a .env file into Python environment \n",
    "load_dotenv(os.path.join(repo_dir, '.env'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, several langchain tools and custom tools are defined showing different ways of implementing them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most simple way of implementing a custom langchain tool is using the `@tool` decorator and defining your arguments schema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get time tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument schema\n",
    "# a sub-class of the BaseModel in Pydantic, provides information about the input arguments (type and description)\n",
    "class GetTimeSchema(BaseModel):\n",
    "    \"\"\"Returns current date, current time or both.\"\"\"\n",
    "\n",
    "    kind: Optional[str] = Field(description='kind of information to retrieve \"date\", \"time\" or \"both\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition using @tool decorator\n",
    "@tool(args_schema=GetTimeSchema)\n",
    "def get_time(kind: str = 'both') -> str:\n",
    "    \"\"\"Returns current date, current time or both.\n",
    "\n",
    "    Args:\n",
    "        kind(str): date, time or both\n",
    "    \n",
    "    Returns:\n",
    "        str: current date, current time or both\n",
    "    \"\"\"\n",
    "    if kind == 'date':\n",
    "        date = datetime.now().strftime('%d/%m/%Y')\n",
    "        return f'Current date: {date}'\n",
    "    elif kind == 'time':\n",
    "        time = datetime.now().strftime('%H:%M:%S')\n",
    "        return f'Current time: {time}'\n",
    "    else:\n",
    "        date = datetime.now().strftime('%d/%m/%Y')\n",
    "        time = datetime.now().strftime('%H:%M:%S')\n",
    "        return f'Current date: {date}, Current time: {time}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current time: 11:10:02'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time.invoke({'kind': 'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Returns current date, current time or both.',\n",
       " 'properties': {'kind': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'description': 'kind of information to retrieve \"date\", \"time\" or \"both\"',\n",
       "   'title': 'Kind'}},\n",
       " 'required': ['kind'],\n",
       " 'title': 'GetTimeSchema',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized error handling tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a more complex tool that is able to raise specific tool error with some information, that can be send to the llm in order to fix the original call if its possible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculator tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument schema\n",
    "class CalculatorSchema(BaseModel):\n",
    "    \"\"\"allow calculation of only basic operations: + - * and /\n",
    "    with a string input expression\"\"\"\n",
    "\n",
    "    expression: str = Field(..., description=\"expression to calculate, example '12 * 3'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to use in the tool\n",
    "def calculator(expression: str) -> Union[str, int, float]:\n",
    "    \"\"\"\n",
    "    allow calculation of basic operations with a string input expression\n",
    "    \n",
    "    Args:\n",
    "        expression (str): expression to calculate\n",
    "    \n",
    "    Returns:\n",
    "        Union[str, int, float]: calculated value or error message\n",
    "    \"\"\"\n",
    "    ops = {\n",
    "        '+': operator.add,\n",
    "        '-': operator.sub,\n",
    "        '*': operator.mul,\n",
    "        'x': operator.mul,\n",
    "        'X': operator.mul,\n",
    "        'รท': operator.truediv,\n",
    "        '/': operator.truediv,\n",
    "    }\n",
    "    tokens = re.findall(r'\\d+\\.?\\d*|\\+|\\-|\\*|\\/|รท|x|X', expression)\n",
    "\n",
    "    if len(tokens) == 0:\n",
    "        raise ToolException(\n",
    "            f\"Invalid expression '{expression}', should only contain one of the following operators + - * x and รท\"\n",
    "        )\n",
    "\n",
    "    current_value = float(tokens.pop(0))\n",
    "\n",
    "    while len(tokens) > 0:\n",
    "        # The next token should be an operator\n",
    "        op = tokens.pop(0)\n",
    "\n",
    "        # The next token should be a number\n",
    "        if len(tokens) == 0:\n",
    "            raise ToolException(f\"Incomplete expression '{expression}'\")\n",
    "        try:\n",
    "            next_value = float(tokens.pop(0))\n",
    "\n",
    "        except ValueError:\n",
    "            raise ToolException('Invalid number format')\n",
    "\n",
    "        except:\n",
    "            raise ToolException('Invalid operation')\n",
    "\n",
    "        # check division by 0\n",
    "        if op in ['/', 'รท'] and next_value == 0:\n",
    "            raise ToolException('cannot divide by 0')\n",
    "\n",
    "        current_value = ops[op](current_value, next_value)\n",
    "\n",
    "    result = current_value\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# tool error handler\n",
    "def _handle_error(error: ToolException) -> str:\n",
    "    return f'The following errors occurred during Calculator tool execution: `{error.args}`'\n",
    "\n",
    "\n",
    "# tool definition\n",
    "calculator = StructuredTool.from_function(\n",
    "    func=calculator,\n",
    "    args_schema=CalculatorSchema,\n",
    "    handle_tool_error=_handle_error,  # set as True if you want the tool to trow a generic ToolError message \"Tool execution error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421.59999999999997"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.invoke('18*23.7 -5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The following errors occurred during Calculator tool execution: `('cannot divide by 0',)`\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.invoke('7 / 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'allow calculation of only basic operations: + - * and /\\nwith a string input expression',\n",
       " 'properties': {'expression': {'description': \"expression to calculate, example '12 * 3'\",\n",
       "   'title': 'Expression',\n",
       "   'type': 'string'}},\n",
       " 'required': ['expression'],\n",
       " 'title': 'CalculatorSchema',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(There are several built-in tools available in langchain library that can be directly used by the model, you can find a list of available tools [here](https://python.langchain.com/v0.1/docs/integrations/tools/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python standard shell, or REPL (Read-Eval-Print Loop) tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument schema\n",
    "class ReplSchema(BaseModel):\n",
    "    \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\"\n",
    "\n",
    "    command: str = Field(..., description='python code to evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool definition\n",
    "python_repl = PythonREPL()\n",
    "python_repl = Tool(\n",
    "    name='python_repl',\n",
    "    description='A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.',\n",
    "    func=python_repl.run,\n",
    "    args_schema=ReplSchema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0\\n1\\n2\\n3\\n4\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl.invoke({'command': 'for i in range(0,5):\\n\\tprint(i)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.',\n",
       " 'properties': {'command': {'description': 'python code to evaluate',\n",
       "   'title': 'Command',\n",
       "   'type': 'string'}},\n",
       " 'required': ['command'],\n",
       " 'title': 'ReplSchema',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL calling tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool is a demonstration of how to implement an SQL query tool leveraging the build in QuerySQLDataBaseTool langchain tool, for this example we are passing the db schema to Llama3 8B model, but you can get better performance with your own fine tuned model.\n",
    ">For fine tuning your own sql model go to [fine_tuning_sql kit](../../fine_tuning_sql/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['albums', 'artists', 'customers', 'employees', 'genres', 'invoice_items', 'invoices', 'media_types', 'playlist_track', 'playlists', 'tracks']\n",
      "[(1, 'Rock'), (2, 'Jazz'), (3, 'Metal'), (4, 'Alternative & Punk'), (5, 'Rock And Roll'), (6, 'Blues'), (7, 'Latin'), (8, 'Reggae'), (9, 'Pop'), (10, 'Soundtrack'), (11, 'Bossa Nova'), (12, 'Easy Listening'), (13, 'Heavy Metal'), (14, 'R&B/Soul'), (15, 'Electronica/Dance'), (16, 'World'), (17, 'Hip Hop/Rap'), (18, 'Science Fiction'), (19, 'TV Shows'), (20, 'Sci Fi & Fantasy'), (21, 'Drama'), (22, 'Comedy'), (23, 'Alternative'), (24, 'Classical'), (25, 'Opera')]\n"
     ]
    }
   ],
   "source": [
    "# example sql query call\n",
    "db_path = os.path.join(kit_dir, 'data/chinook.db')\n",
    "db_uri = f'sqlite:///{db_path}'\n",
    "db = SQLDatabase.from_uri(db_uri)\n",
    "print(db.get_usable_table_names())\n",
    "print(db.run('SELECT * FROM genres;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument schema\n",
    "class QueryDBSchema(BaseModel):\n",
    "    \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\"\n",
    "\n",
    "    query: str = Field(..., description='natural language question or instruction.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_finder(text):\n",
    "    \"\"\"Search in a string for a SQL query or code with format\"\"\"\n",
    "\n",
    "    # regex for finding sql_code_pattern with format:\n",
    "    # ```sql\n",
    "    #    <query>\n",
    "    # ```\n",
    "    sql_code_pattern = re.compile(r'```sql\\s+(.*?)\\s+```', re.DOTALL)\n",
    "    match = sql_code_pattern.search(text)\n",
    "    if match is not None:\n",
    "        query = match.group(1)\n",
    "\n",
    "        return query\n",
    "    else:\n",
    "        # regex for finding sql_code_pattern with format:\n",
    "        # ```\n",
    "        # <quey>\n",
    "        # ```\n",
    "        code_pattern = re.compile(r'```\\s+(.*?)\\s+```', re.DOTALL)\n",
    "        match = code_pattern.search(text)\n",
    "        if match is not None:\n",
    "            query = match.group(1)\n",
    "            return query\n",
    "        else:\n",
    "            print(text)\n",
    "            raise Exception('No SQL code found in LLM generation')\n",
    "\n",
    "\n",
    "@tool(args_schema=QueryDBSchema)\n",
    "def query_db(query: str) -> str:\n",
    "    \"\"\"A query generation tool. Use this to generate sql queries and retrieve the results from a database. \n",
    "    Do not pass sql queries directly. Input must be a natural language question or instruction.\n",
    "    \n",
    "    Args:\n",
    "        query (src): natural language question or instruction\n",
    "    \n",
    "    Returns:\n",
    "        str: result from the database\n",
    "    \"\"\"\n",
    "\n",
    "    # Using SambaNova model for generating the SQL Query\n",
    "    llm = ChatSambaNova(\n",
    "        max_tokens=512,\n",
    "        model='Meta-Llama-3.3-70B-Instruct',\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate(\n",
    "        [\n",
    "            (\n",
    "                'system',\n",
    "                \"\"\"\n",
    "            {table_info}\n",
    "            \n",
    "            Generate a query using valid SQLite to answer the following questions for the summarized tables schemas provided above.\n",
    "            Do not assume the values on the database tables before generating the SQL query, always generate a SQL that query what is asked.\n",
    "            Do not assume ids in tables when inserting new values let them null or use the max id + 1\n",
    "            The queries must be formatted including backticks code symbols as follows:\n",
    "            do not include comments in the query\n",
    "                \n",
    "            ```sql\n",
    "            query\n",
    "            ```\n",
    "            \n",
    "            Example format:\n",
    "            \n",
    "            ```sql\n",
    "            SELECT * FROM mainTable;\n",
    "            ```\"\"\",  # noqa: E501\n",
    "            ),\n",
    "            ('human', \"\"\"{input}\"\"\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Chain that receives the natural language input and the table schema, then pass the teh formmated prompt to the llm\n",
    "    # and finally execute the sql finder method, retrieving only the filtered SQL query\n",
    "    query_generation_chain = prompt | llm | StrOutputParser() |RunnableLambda(sql_finder)\n",
    "    table_info = db.get_table_info()\n",
    "    query = query_generation_chain.invoke({'input': query, 'table_info': table_info})\n",
    "    queries = query.split(';')\n",
    "    query_executor = QuerySQLDataBaseTool(db=db)\n",
    "    results = []\n",
    "    for query in queries:\n",
    "        if query.strip() != '':\n",
    "            print(f'query_db: executing query: \\n{query}\\n')\n",
    "            results.append(query_executor.invoke(query))\n",
    "            print(f'query_db: query result: \\n{results[-1]}\\n')\n",
    "\n",
    "    result = '\\n'.join([f'Query {query} executed with result {result}' for query, result in zip(queries, results)])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examples of query_db tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_db: executing query: \n",
      "SELECT COUNT(*) FROM genres\n",
      "\n",
      "query_db: query result: \n",
      "[(25,)]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Query SELECT COUNT(*) FROM genres executed with result [(25,)]'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'How many genres of music are in the chinook db'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_db: executing query: \n",
      "INSERT INTO genres (Name) \n",
      "VALUES ('Salsa')\n",
      "\n",
      "query_db: query result: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Query INSERT INTO genres (Name) \\nVALUES ('Salsa') executed with result \""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'add a new genre in the chinook db called Salsa'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_db: executing query: \n",
      "SELECT Name, MAX(Milliseconds) as Duration \n",
      "FROM tracks\n",
      "\n",
      "query_db: query result: \n",
      "[('Occupation / Precipice', 5286953)]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Query SELECT Name, MAX(Milliseconds) as Duration \\nFROM tracks executed with result [('Occupation / Precipice', 5286953)]\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'What is the longest track in the chinook db'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_db: executing query: \n",
      "SELECT i.InvoiceId, i.Total, c.FirstName, c.LastName \n",
      "FROM invoices i \n",
      "JOIN customers c ON i.CustomerId = c.CustomerId \n",
      "ORDER BY i.Total DESC \n",
      "LIMIT 5\n",
      "\n",
      "query_db: query result: \n",
      "[(404, 25.86, 'Helena', 'Holรฝ'), (299, 23.86, 'Richard', 'Cunningham'), (96, 21.86, 'Ladislav', 'Kovรกcs'), (194, 21.86, 'Hugh', \"O'Reilly\"), (89, 18.86, 'Astrid', 'Gruber')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Query SELECT i.InvoiceId, i.Total, c.FirstName, c.LastName \\nFROM invoices i \\nJOIN customers c ON i.CustomerId = c.CustomerId \\nORDER BY i.Total DESC \\nLIMIT 5 executed with result [(404, 25.86, \\'Helena\\', \\'Holรฝ\\'), (299, 23.86, \\'Richard\\', \\'Cunningham\\'), (96, 21.86, \\'Ladislav\\', \\'Kovรกcs\\'), (194, 21.86, \\'Hugh\\', \"O\\'Reilly\"), (89, 18.86, \\'Astrid\\', \\'Gruber\\')]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'list of the 5 highest value invoices registered in the database including customer names'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_db: executing query: \n",
      "INSERT INTO artists (\"Name\") \n",
      "VALUES ('Fruco y sus tesos')\n",
      "\n",
      "query_db: query result: \n",
      "\n",
      "\n",
      "query_db: executing query: \n",
      "\n",
      "\n",
      "INSERT INTO albums (\"Title\", \"ArtistId\") \n",
      "VALUES ('Fruco y sus tesos', (SELECT MAX(\"ArtistId\") FROM artists))\n",
      "\n",
      "query_db: query result: \n",
      "\n",
      "\n",
      "query_db: executing query: \n",
      "\n",
      "\n",
      "INSERT INTO tracks (\"Name\", \"AlbumId\", \"MediaTypeId\", \"Milliseconds\", \"UnitPrice\") \n",
      "VALUES ('El Preso', (SELECT MAX(\"AlbumId\") FROM albums), 1, 123000, 1.2)\n",
      "\n",
      "query_db: query result: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Query INSERT INTO artists (\"Name\") \\nVALUES (\\'Fruco y sus tesos\\') executed with result \\nQuery \\n\\nINSERT INTO albums (\"Title\", \"ArtistId\") \\nVALUES (\\'Fruco y sus tesos\\', (SELECT MAX(\"ArtistId\") FROM artists)) executed with result \\nQuery \\n\\nINSERT INTO tracks (\"Name\", \"AlbumId\", \"MediaTypeId\", \"Milliseconds\", \"UnitPrice\") \\nVALUES (\\'El Preso\\', (SELECT MAX(\"AlbumId\") FROM albums), 1, 123000, 1.2) executed with result '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke(\n",
    "    {\n",
    "        'query': 'add in the db a new song called \"El Preso\" from the artist \"Fruco y sus tesos\", with a duration 123000 seconds with a price of 1.2 usd'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_db: executing query: \n",
      "SELECT Composer FROM tracks WHERE Name = 'El Preso'\n",
      "\n",
      "query_db: query result: \n",
      "[(None,)]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Query SELECT Composer FROM tracks WHERE Name = 'El Preso' executed with result [(None,)]\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'who is the composer of the song with name \"El Preso\"'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_db: executing query: \n",
      "CREATE TABLE movies (\n",
      "    `MovieId` INTEGER PRIMARY KEY,\n",
      "    `MovieTitle` NVARCHAR(200) NOT NULL\n",
      ")\n",
      "\n",
      "query_db: query result: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Query CREATE TABLE movies (\\n    `MovieId` INTEGER PRIMARY KEY,\\n    `MovieTitle` NVARCHAR(200) NOT NULL\\n) executed with result '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke(\n",
    "    {'query': 'create a new table in the chinook db called movies, with a column for id and column for movieTitle'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_db: executing query: \n",
      "INSERT INTO playlists (Name) VALUES ('Movies') ON CONFLICT (Name) DO NOTHING\n",
      "\n",
      "query_db: query result: \n",
      "Error: (sqlite3.OperationalError) ON CONFLICT clause does not match any PRIMARY KEY or UNIQUE constraint\n",
      "[SQL: INSERT INTO playlists (Name) VALUES ('Movies') ON CONFLICT (Name) DO NOTHING]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "query_db: executing query: \n",
      "\n",
      "INSERT INTO playlists (Name) VALUES ('Movies') ON CONFLICT (Name) DO NOTHING\n",
      "\n",
      "query_db: query result: \n",
      "Error: (sqlite3.OperationalError) ON CONFLICT clause does not match any PRIMARY KEY or UNIQUE constraint\n",
      "[SQL: \n",
      "INSERT INTO playlists (Name) VALUES ('Movies') ON CONFLICT (Name) DO NOTHING]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "query_db: executing query: \n",
      "\n",
      "\n",
      "INSERT INTO playlists (Name) \n",
      "SELECT 'Movies'\n",
      "WHERE NOT EXISTS (\n",
      "  SELECT 1 \n",
      "  FROM playlists \n",
      "  WHERE Name = 'Movies'\n",
      ")\n",
      "\n",
      "query_db: query result: \n",
      "\n",
      "\n",
      "query_db: executing query: \n",
      "\n",
      "\n",
      "INSERT INTO playlist_track (PlaylistId, TrackId) \n",
      "SELECT p.PlaylistId, (SELECT MAX(t.TrackId) + 1 FROM tracks t) \n",
      "FROM playlists p \n",
      "WHERE p.Name = 'Movies'\n",
      "\n",
      "query_db: query result: \n",
      "\n",
      "\n",
      "query_db: executing query: \n",
      "\n",
      "\n",
      "INSERT INTO tracks (TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice) \n",
      "SELECT (SELECT MAX(t.TrackId) + 1 FROM tracks t), \n",
      "       'Star Wars', \n",
      "       NULL, \n",
      "       (SELECT MediaTypeId FROM media_types WHERE Name = 'Protected MPEG-4 video file'), \n",
      "       NULL, \n",
      "       'George Lucas', \n",
      "       7200000, \n",
      "       NULL, \n",
      "       9.99\n",
      "\n",
      "query_db: query result: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Query INSERT INTO playlists (Name) VALUES ('Movies') ON CONFLICT (Name) DO NOTHING executed with result Error: (sqlite3.OperationalError) ON CONFLICT clause does not match any PRIMARY KEY or UNIQUE constraint\\n[SQL: INSERT INTO playlists (Name) VALUES ('Movies') ON CONFLICT (Name) DO NOTHING]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\\nQuery \\nINSERT INTO playlists (Name) VALUES ('Movies') ON CONFLICT (Name) DO NOTHING executed with result Error: (sqlite3.OperationalError) ON CONFLICT clause does not match any PRIMARY KEY or UNIQUE constraint\\n[SQL: \\nINSERT INTO playlists (Name) VALUES ('Movies') ON CONFLICT (Name) DO NOTHING]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\\nQuery \\n\\nINSERT INTO playlists (Name) \\nSELECT 'Movies'\\nWHERE NOT EXISTS (\\n  SELECT 1 \\n  FROM playlists \\n  WHERE Name = 'Movies'\\n) executed with result \\nQuery \\n\\nINSERT INTO playlist_track (PlaylistId, TrackId) \\nSELECT p.PlaylistId, (SELECT MAX(t.TrackId) + 1 FROM tracks t) \\nFROM playlists p \\nWHERE p.Name = 'Movies' executed with result \\nQuery \\n\\nINSERT INTO tracks (TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice) \\nSELECT (SELECT MAX(t.TrackId) + 1 FROM tracks t), \\n       'Star Wars', \\n       NULL, \\n       (SELECT MediaTypeId FROM media_types WHERE Name = 'Protected MPEG-4 video file'), \\n       NULL, \\n       'George Lucas', \\n       7200000, \\n       NULL, \\n       9.99 executed with result \""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for exectuing this query it is needed to reinitialize the query db to get the new schema including movies table\n",
    "query_db.invoke({'query': 'add a new register in movies table for \"star wars\"'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default response tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a default tool to return conversational responses to the user, for this we will only define the schema of the tool and manually handle the behavior of the system when this tool is called by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query',\n",
       " 'properties': {'response': {'description': 'Conversational response to the user. must be in the same language as the user query',\n",
       "   'title': 'Response',\n",
       "   'type': 'string'}},\n",
       " 'required': ['response'],\n",
       " 'title': 'ConversationalResponse',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argument schema\n",
    "class ConversationalResponse(BaseModel):\n",
    "    \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\"\n",
    "\n",
    "    response: str = Field(\n",
    "        ..., description='Conversational response to the user. must be in the same language as the user query'\n",
    "    )\n",
    "\n",
    "\n",
    "ConversationalResponse.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tools_schemas(\n",
    "    tools: Optional[Union[StructuredTool, Tool, list]] = None,\n",
    "    default: Optional[Union[StructuredTool, Tool, Type[BaseModel]]] = None,\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Get the tools schemas.\n",
    "\n",
    "    Args:\n",
    "        tools (Optional[Union[StructuredTool, Tool, list]]): The tools to use.\n",
    "        default (Optional[Union[StructuredTool, Tool, Type[BaseModel]]]): The default tool to use.\n",
    "    \n",
    "    Returns:\n",
    "        list: list of tool schemas  \n",
    "    \"\"\"\n",
    "    if tools is None or isinstance(tools, list):\n",
    "        pass\n",
    "    elif isinstance(tools, Tool) or isinstance(tools, StructuredTool):\n",
    "        tools = [tools]\n",
    "    else:\n",
    "        raise TypeError('tools must be a Tool or a list of Tools')\n",
    "\n",
    "    tools_schemas = []\n",
    "\n",
    "    for tool in tools:\n",
    "        tool_schema = tool.get_input_schema().schema()\n",
    "        schema = {'name': tool.name, 'description': tool_schema['description'], 'properties': tool_schema['properties']}\n",
    "        if 'required' in schema:\n",
    "            schema['required'] = tool_schema['required']\n",
    "        tools_schemas.append(schema)\n",
    "\n",
    "    if default is not None:\n",
    "        if isinstance(default, Tool) or isinstance(default, StructuredTool):\n",
    "            tool_schema = default.get_input_schema().schema()\n",
    "        elif issubclass(default, BaseModel):\n",
    "            tool_schema = default.schema()\n",
    "        else:\n",
    "            raise TypeError('default must be a Tool or a BaseModel')\n",
    "        schema = {\n",
    "            'name': tool_schema['title'],\n",
    "            'description': tool_schema['description'],\n",
    "            'properties': tool_schema['properties'],\n",
    "        }\n",
    "        if 'required' in schema:\n",
    "            schema['required'] = tool_schema['required']\n",
    "        tools_schemas.append(schema)\n",
    "\n",
    "    return tools_schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_time, calculator, python_repl, query_db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\\n'\n",
      " '  \"name\": \"get_time\",\\n'\n",
      " '  \"description\": \"Returns current date, current time or both.\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"kind\": {\\n'\n",
      " '      \"anyOf\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"type\": \"string\"\\n'\n",
      " '        },\\n'\n",
      " '        {\\n'\n",
      " '          \"type\": \"null\"\\n'\n",
      " '        }\\n'\n",
      " '      ],\\n'\n",
      " '      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" '\n",
      " 'or \\\\\"both\\\\\"\",\\n'\n",
      " '      \"title\": \"Kind\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}\\n'\n",
      " '{\\n'\n",
      " '  \"name\": \"calculator\",\\n'\n",
      " '  \"description\": \"allow calculation of only basic operations: + - * and '\n",
      " '/\\\\nwith a string input expression\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"expression\": {\\n'\n",
      " '      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n'\n",
      " '      \"title\": \"Expression\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}\\n'\n",
      " '{\\n'\n",
      " '  \"name\": \"python_repl\",\\n'\n",
      " '  \"description\": \"A Python shell. Use this to evaluate python commands. '\n",
      " 'Input should be a valid python commands and expressions. If you want to see '\n",
      " 'the output of a value, you should print it out with `print(...)`, if you '\n",
      " 'need a specific module you should import it.\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"command\": {\\n'\n",
      " '      \"description\": \"python code to evaluate\",\\n'\n",
      " '      \"title\": \"Command\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}\\n'\n",
      " '{\\n'\n",
      " '  \"name\": \"query_db\",\\n'\n",
      " '  \"description\": \"A query generation tool. Use this to generate sql queries '\n",
      " 'and retrieve the results from a database. Do not pass sql queries directly. '\n",
      " 'Input must be a natural language question or instruction.\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"query\": {\\n'\n",
      " '      \"description\": \"natural language question or instruction.\",\\n'\n",
      " '      \"title\": \"Query\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}\\n'\n",
      " '{\\n'\n",
      " '  \"name\": \"ConversationalResponse\",\\n'\n",
      " '  \"description\": \"Respond conversationally only if no other tools should be '\n",
      " 'called for a given query, or if you have a final answer. response must be in '\n",
      " 'the same language as the user query\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"response\": {\\n'\n",
      " '      \"description\": \"Conversational response to the user. must be in the '\n",
      " 'same language as the user query\",\\n'\n",
      " '      \"title\": \"Response\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Get list of tools schemas\n",
    "tools_schemas = get_tools_schemas(tools, default=ConversationalResponse) \n",
    "\n",
    "# Convert list of tools schemas into JSON string\n",
    "tools_schemas = '\\n'.join([json.dumps(tool, indent=2) for tool in tools_schemas])\n",
    "pprint(tools_schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow for tool execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SambaNova model for tool calling\n",
    "llm = ChatSambaNova(\n",
    "    max_tokens=2048,\n",
    "    model=\"Meta-Llama-3.3-70B-Instruct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of some util methods to parse the llm output and invoke available tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map tool name to tool\n",
    "tools_map = {'get_time': get_time, 'calculator': calculator, 'python_repl': python_repl, 'query_db': query_db}\n",
    "\n",
    "\n",
    "def execute(invoked_tools: List[dict]) -> tuple[bool, List[str]]:\n",
    "    \"\"\"\n",
    "    Executes a list of tool invocations as generated by the LLM. Each tool is executed\n",
    "    according to its name, which is mapped in tools_map, along with the provided input arguments.\n",
    "    If there is only one tool invocation and it is the default conversational tool, the response is marked as the final response.\n",
    "    \n",
    "    Args:\n",
    "        invoked_tools (List[dict]): A list of tool invocations as generated by the LLM.\n",
    "    \n",
    "    Returns:\n",
    "        tuple[bool, List[str]]: A tuple containing:\n",
    "            - A boolean indicating whether the response is marked as the final response\n",
    "            - A list of strings representing the results from the executed tools\n",
    "    \"\"\"\n",
    "    tool_msg = \"Tool '{name}'response: {response}\"\n",
    "    tools_msgs = []\n",
    "    if len(invoked_tools) == 1 and invoked_tools[0]['tool'].lower() == 'conversationalresponse':\n",
    "        final_answer = True\n",
    "        return final_answer, [invoked_tools[0]['tool_input']['response']]\n",
    "    for tool in invoked_tools:\n",
    "        final_answer = False\n",
    "        if tool['tool'].lower() != 'conversationalresponse':\n",
    "            response = tools_map[tool['tool'].lower()].invoke(tool['tool_input'])\n",
    "            tools_msgs.append(tool_msg.format(name=tool['tool'], response=str(response)))\n",
    "    return final_answer, tools_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonFinder(input_message: AIMessage) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Searches for JSON structures within a LLM response. If the JSON is badly formatted, it attempts to correct it using an LLM.\n",
    "\n",
    "    Args:\n",
    "        input_message (AIMessage): The message to find the JSON structure in.\n",
    "    \n",
    "    Returns:\n",
    "        Optional[str]: JSON formatted response\n",
    "    \"\"\"\n",
    "    json_pattern = re.compile(r'(\\{.*\\}|\\[.*\\])', re.DOTALL)\n",
    "    # Find the first JSON structure in the string\n",
    "    json_match = json_pattern.search(input_message.content)\n",
    "    if json_match: # Case when a JSON structure is found\n",
    "        json_str = json_match.group(1)\n",
    "        try:\n",
    "            json.loads(json_str)\n",
    "        except:\n",
    "            json_correction_prompt = [\n",
    "                ('system', \"\"\"You are a json format corrector tool\"\"\"),\n",
    "                ('human', \"\"\"fix the following json file: {json}\n",
    "                 do not provide any explanation only return the fixed json\"\"\")\n",
    "            ]\n",
    "            json_correction_prompt_template = ChatPromptTemplate(json_correction_prompt)\n",
    "            json_correction_chain = json_correction_prompt_template | llm | StrOutputParser()\n",
    "            json_str = json_correction_chain.invoke(json_str)\n",
    "    else: # Case when no JSON structure is found\n",
    "        # will assume its a conversational response\n",
    "        print('response is not json formatted assuming conversational response')\n",
    "        dummy_json_response = [{'tool': 'ConversationalResponse', 'tool_input': {'response': input_message.content}}]\n",
    "        json_str = json.dumps(dummy_json_response)\n",
    "    return json_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agentic prompt template for function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_function_calling_prompt = [\n",
    "  ('system',\"\"\"You are an helpful assistant and you have access to the following tools:\n",
    "\n",
    "  {tools}\n",
    "\n",
    "  You must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\n",
    "\n",
    "  ```json\n",
    "  [{{\n",
    "    \"tool\": <name of the selected tool>,\n",
    "    \"tool_input\": <parameters for the selected tool, matching the tool's JSON schema>\n",
    "  }}]\n",
    "  ```\n",
    "\n",
    "  Think step by step\n",
    "  Do not call a tool if the input depends on another tool output you dont have yet.\n",
    "  Do not try to answer until you get tools output, if you dont have an answer yet you can continue calling tools until you do.\n",
    "  Your answer should be in the same language as the initial query.\"\"\"),\n",
    "  ('human',\"\"\"User: {usr_msg} \"\"\")\n",
    "]\n",
    "\n",
    "function_calling_prompt_template = ChatPromptTemplate(example_function_calling_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json parsing Chain for parsing tool calling output from llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_parsing_chain = RunnableLambda(jsonFinder) | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain for passing through the tools schemas to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = {\n",
    "    'tools': lambda x: tools_schemas,\n",
    "    'usr_msg': RunnablePassthrough(),\n",
    "} | function_calling_prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of chain to do one full pass of the query to the model. \n",
    "Here we will see the first tool execution call generated by the model and the result of this first execution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function calling chain\n",
    "default_fc_chain = prompt_template | llm | json_parsing_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'ConversationalResponse', 'tool_input': {'response': 'Hello! How can I help you today?'}}]\n",
      "['Hello! How can I help you today?']\n"
     ]
    }
   ],
   "source": [
    "query = 'hi'\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "print(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'get_time', 'tool_input': {'kind': 'time'}}]\n",
      "[\"Tool 'get_time'response: Current time: 12:50:39\"]\n"
     ]
    }
   ],
   "source": [
    "query = 'it is time to go to sleep?'\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "pprint(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'calculator', 'tool_input': {'expression': '347 / 60'}}]\n",
      "[\"Tool 'calculator'response: 5.783333333333333\"]\n"
     ]
    }
   ],
   "source": [
    "query = 'what is 347 min in hours and minutes?'\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "print(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'python_repl',\n",
      "  'tool_input': {'command': \"print('saippuakivikauppias' == \"\n",
      "                            \"'saippuakivikauppias'[::-1])\"}}]\n",
      "[\"Tool 'python_repl'response: True\\n\"]\n"
     ]
    }
   ],
   "source": [
    "query = \"is this word is a palindrome? 'saippuakivikauppias'\"\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "pprint(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'python_repl',\n",
      "  'tool_input': {'command': \"print(sorted(['screwdriver', 'pliers', \"\n",
      "                            \"'hammer']))\"}}]\n",
      "[\"Tool 'python_repl'response: ['hammer', 'pliers', 'screwdriver']\\n\"]\n"
     ]
    }
   ],
   "source": [
    "query = \"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\"\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "pprint(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are defining a iterative pipeline to give the model the ability of getting the tools execution as inputs and continue generating the answer until having a final response "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the system message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_calling_system_prompt = \"\"\"you are an helpful assistant and you have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "You must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\n",
    "\n",
    "```json\n",
    "[{{\n",
    "  \"tool\": <name of the selected tool>,\n",
    "  \"tool_input\": <parameters for the selected tool, matching the tool's JSON schema>\n",
    "}}]\n",
    "```\n",
    "\n",
    "Think step by step\n",
    "Do not call a tool if the input depends on another tool output that you do not have yet.\n",
    "Do not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\n",
    "Your answer should be in the same language as the initial query.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of chat prompt template, having as first interaction the system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['tools'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tools'], input_types={}, partial_variables={}, template='you are an helpful assistant and you have access to the following tools:\\n\\n{tools}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_calling_chat_template = ChatPromptTemplate.from_messages([('system', function_calling_system_prompt)])\n",
    "function_calling_chat_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting everything together to have an iterative/agentic pipeline for doing function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_call_llm(query: str, max_it: int = 5, debug: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Iterative/agentic pipeline for function calling workflow\n",
    "\n",
    "    Args:\n",
    "        query (str): The query to execute.\n",
    "        max_it (int, optional): The maximum number of iterations. Defaults to 5.\n",
    "        debug (bool, optional): Whether to print debug information. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        str: The final response from the LLM or an exception if no final response is reached.\n",
    "    \"\"\"\n",
    "    history = function_calling_chat_template.format_prompt(tools=tools_schemas).to_messages()\n",
    "    history.append(HumanMessage(query))\n",
    "    tool_call_id = 0  # Unique identifier for each tool calling required to create ToolMessages\n",
    "\n",
    "    for i in range(max_it):\n",
    "        llm_response = llm.invoke(history)\n",
    "        parsed_tools_llm_response = json_parsing_chain.invoke(llm_response)\n",
    "        history.append(llm_response)\n",
    "        final_answer, tools_msgs = execute(parsed_tools_llm_response)\n",
    "        if final_answer:\n",
    "            final_response = tools_msgs[0]\n",
    "            if debug:\n",
    "                pprint(history)\n",
    "            return final_response\n",
    "        else:\n",
    "            history.append(ToolMessage('\\n'.join(tools_msgs), tool_call_id=tool_call_id))\n",
    "            tool_call_id += 1\n",
    "\n",
    "    # If no final response is reached after the maximum number of iterations \n",
    "    raise Exception('not a final response yet', json.dumps(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='what time is it?', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='[{\\n  \"tool\": \"get_time\",\\n  \"tool_input\": {\\n    \"kind\": \"time\"\\n  }\\n}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 7.75, 'completion_tokens': 27, 'completion_tokens_after_first_per_sec': 127.34263620928435, 'completion_tokens_after_first_per_sec_first_ten': 192.0605029306107, 'completion_tokens_per_sec': 55.620019377945916, 'end_time': 1729619638.8245845, 'is_last_response': True, 'prompt_tokens': 660, 'start_time': 1729619638.275555, 'time_to_first_token': 0.34485602378845215, 'total_latency': 0.48543672407827065, 'total_tokens': 687, 'total_tokens_per_sec': 1415.2204930610683}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619638}, id='1ed27578-8628-4505-8fd2-f625c041ab4d'),\n",
      " ToolMessage(content=\"Tool 'get_time'response: Current time: 12:53:58\", tool_call_id='0'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"It\\'s 12:53:58\"\\n  }\\n}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 6.333333333333333, 'completion_tokens': 36, 'completion_tokens_after_first_per_sec': 122.01469655625826, 'completion_tokens_after_first_per_sec_first_ten': 155.83305174895187, 'completion_tokens_per_sec': 62.34588079859468, 'end_time': 1729619640.0851028, 'is_last_response': True, 'prompt_tokens': 716, 'start_time': 1729619639.4518447, 'time_to_first_token': 0.346407413482666, 'total_latency': 0.5774238737005937, 'total_tokens': 752, 'total_tokens_per_sec': 1302.3361766817554}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619639}, id='94c5fedf-c319-437f-98cd-10f0fa6f5990')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm('what time is it?', max_it=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's 12:53:58\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='how many hours last to 10pm?', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='[{\\n  \"tool\": \"get_time\",\\n  \"tool_input\": {\\n    \"kind\": \"time\"\\n  }\\n}, {\\n  \"tool\": \"python_repl\",\\n  \"tool_input\": {\\n    \"command\": \"import datetime; current_time = datetime.datetime.now().strftime(\\'%H\\'); hours_until_10pm = 22 - int(current_time); print(hours_until_10pm)\"\\n  }\\n}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 5.117647058823529, 'completion_tokens': 85, 'completion_tokens_after_first_per_sec': 91.72722931967706, 'completion_tokens_after_first_per_sec_first_ten': 100.98927545160252, 'completion_tokens_per_sec': 41.93023078227749, 'end_time': 1729619647.63238, 'is_last_response': True, 'prompt_tokens': 664, 'start_time': 1729619645.531118, 'time_to_first_token': 1.1855034828186035, 'total_latency': 2.027177013199905, 'total_tokens': 749, 'total_tokens_per_sec': 369.47932771677455}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619645}, id='e677f06f-6b68-4b41-9244-727e97958593'),\n",
      " ToolMessage(content=\"Tool 'get_time'response: Current time: 12:54:07\\nTool 'python_repl'response: 10\\n\", tool_call_id='0'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"there are 10 hours until 10pm\"\\n  }\\n}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 2.7142857142857144, 'completion_tokens': 37, 'completion_tokens_after_first_per_sec': 88.08293840521375, 'completion_tokens_after_first_per_sec_first_ten': 53.47634710804528, 'completion_tokens_per_sec': 23.33926299968207, 'end_time': 1729619649.8591666, 'is_last_response': True, 'prompt_tokens': 791, 'start_time': 1729619648.2738552, 'time_to_first_token': 1.1766057014465332, 'total_latency': 1.5853114128112793, 'total_tokens': 828, 'total_tokens_per_sec': 522.2948584793718}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619648}, id='aafc1877-45ef-42b1-bc38-cafaf0155d36')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm('how many hours last to 10pm?', max_it=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there are 10 hours until 10pm'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content=\"is this word is a palindrome? 'saippuakivikauppias'\", additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='[{\\n  \"tool\": \"python_repl\",\\n  \"tool_input\": {\\n    \"command\": \"print(\\'saippuakivikauppias\\' == \\'saippuakivikauppias\\'[::-1])\"\\n  }\\n}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 5.1, 'completion_tokens': 54, 'completion_tokens_after_first_per_sec': 94.09882026253074, 'completion_tokens_after_first_per_sec_first_ten': 100.02423917465354, 'completion_tokens_per_sec': 31.21952039664981, 'end_time': 1729619662.0070329, 'is_last_response': True, 'prompt_tokens': 673, 'start_time': 1729619660.2539773, 'time_to_first_token': 1.1898179054260254, 'total_latency': 1.7296870456022375, 'total_tokens': 727, 'total_tokens_per_sec': 420.3072468215631}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619660}, id='fd3f40fc-de4e-4b74-9a31-ed089f33844b'),\n",
      " ToolMessage(content=\"Tool 'python_repl'response: True\\n\", tool_call_id='0'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"Yes, the word \\'saippuakivikauppias\\' is a palindrome.\"\\n  }\\n}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 5.666666666666667, 'completion_tokens': 46, 'completion_tokens_after_first_per_sec': 87.87677936067328, 'completion_tokens_after_first_per_sec_first_ten': 111.4976106482524, 'completion_tokens_per_sec': 28.81495523733479, 'end_time': 1729619671.8622036, 'is_last_response': True, 'prompt_tokens': 750, 'start_time': 1729619670.1662946, 'time_to_first_token': 1.183828353881836, 'total_latency': 1.596393248614143, 'total_tokens': 796, 'total_tokens_per_sec': 498.6240080199672}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619670}, id='9e7bb659-4b53-442a-a96e-4a2440e4fdce')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm(\"is this word is a palindrome? 'saippuakivikauppias'\", max_it=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, the word 'saippuakivikauppias' is a palindrome.\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content=\"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\", additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='[{\\n  \"tool\": \"python_repl\",\\n  \"tool_input\": {\\n    \"command\": \"print(sorted([\\'screwdriver\\', \\'pliers\\', \\'hammer\\']))\"\\n  }\\n}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 5.571428571428571, 'completion_tokens': 40, 'completion_tokens_after_first_per_sec': 94.88087589919921, 'completion_tokens_after_first_per_sec_first_ten': 109.6888795109735, 'completion_tokens_per_sec': 25.865464691261355, 'end_time': 1729619685.721015, 'is_last_response': True, 'prompt_tokens': 673, 'start_time': 1729619684.1281774, 'time_to_first_token': 1.1817958354949951, 'total_latency': 1.5464636138361743, 'total_tokens': 713, 'total_tokens_per_sec': 461.0519081217337}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619684}, id='94ed6f00-d948-4d66-9008-18a47ec2a5e5'),\n",
      " ToolMessage(content=\"Tool 'python_repl'response: ['hammer', 'pliers', 'screwdriver']\\n\", tool_call_id='0'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"[\\'hammer\\', \\'pliers\\', \\'screwdriver\\']\"\\n  }\\n}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 5.857142857142857, 'completion_tokens': 39, 'completion_tokens_after_first_per_sec': 90.11364424052762, 'completion_tokens_after_first_per_sec_first_ten': 112.01054320292343, 'completion_tokens_per_sec': 25.016865509770085, 'end_time': 1729619688.8016582, 'is_last_response': True, 'prompt_tokens': 747, 'start_time': 1729619687.1692016, 'time_to_first_token': 1.2107667922973633, 'total_latency': 1.5589483016874732, 'total_tokens': 786, 'total_tokens_per_sec': 504.1860587353664}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619687}, id='db9dbdeb-95cd-4a17-a11a-c3182ccc9e55')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm(\n",
    "    \"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\", max_it=5, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['hammer', 'pliers', 'screwdriver']\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_db: executing query: \n",
      "SELECT UnitPrice FROM tracks WHERE Name = 'Snowballed'\n",
      "\n",
      "query_db: query result: \n",
      "[(0.99,)]\n",
      "\n",
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='whats the price in colombian pesos of the track \"Snowballed\" in the db if one usd is equal to 3800 cop?', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='[\\n  {\\n    \"tool\": \"query_db\",\\n    \"tool_input\": {\\n      \"query\": \"What is the price in USD of the track Snowballed?\"\\n    }\\n  }\\n]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 5, 'completion_tokens': 41, 'completion_tokens_after_first_per_sec': 98.59195783936129, 'completion_tokens_after_first_per_sec_first_ten': 123.8382955605683, 'completion_tokens_per_sec': 60.63494060425052, 'end_time': 1729619694.597988, 'is_last_response': True, 'prompt_tokens': 686, 'start_time': 1729619693.8471744, 'time_to_first_token': 0.34510087966918945, 'total_latency': 0.6761777877807618, 'total_tokens': 727, 'total_tokens_per_sec': 1075.161019982686}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619693}, id='dc8726a4-4aa5-47cc-b0f0-d1dd489013d7'),\n",
      " ToolMessage(content=\"Tool 'query_db'response: Query SELECT UnitPrice FROM tracks WHERE Name = 'Snowballed' executed with result [(0.99,)]\", tool_call_id='0'),\n",
      " AIMessage(content='[\\n  {\\n    \"tool\": \"calculator\",\\n    \"tool_input\": {\\n      \"expression\": \"0.99 * 3800\"\\n    }\\n  }\\n]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 7, 'completion_tokens': 35, 'completion_tokens_after_first_per_sec': 139.16981573993382, 'completion_tokens_after_first_per_sec_first_ten': 172.99869780158267, 'completion_tokens_per_sec': 63.99319268841728, 'end_time': 1729619697.738889, 'is_last_response': True, 'prompt_tokens': 770, 'start_time': 1729619697.1499636, 'time_to_first_token': 0.3446195125579834, 'total_latency': 0.5469331741333008, 'total_tokens': 805, 'total_tokens_per_sec': 1471.8434318335976}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619697}, id='26f5b7f4-eea9-4948-a9ba-95805f036534'),\n",
      " ToolMessage(content=\"Tool 'calculator'response: 3762.0\", tool_call_id='1'),\n",
      " AIMessage(content='[\\n  {\\n    \"tool\": \"ConversationalResponse\",\\n    \"tool_input\": {\\n      \"response\": \"The price of the track \\'Snowballed\\' in Colombian Pesos is 3762.0 COP.\"\\n    }\\n  }\\n]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 5.5, 'completion_tokens': 52, 'completion_tokens_after_first_per_sec': 109.41763351273822, 'completion_tokens_after_first_per_sec_first_ten': 130.57122965897835, 'completion_tokens_per_sec': 68.78248322992154, 'end_time': 1729619699.215603, 'is_last_response': True, 'prompt_tokens': 829, 'start_time': 1729619698.3917427, 'time_to_first_token': 0.3577563762664795, 'total_latency': 0.7560064359144731, 'total_tokens': 881, 'total_tokens_per_sec': 1165.3339947223244}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619698}, id='eb3fbb69-15d5-407a-a630-1dea09098374')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm(\n",
    "    'whats the price in colombian pesos of the track \"Snowballed\" in the db if one usd is equal to 3800 cop?',\n",
    "    max_it=5,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The price of the track 'Snowballed' in Colombian Pesos is 3762.0 COP.\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions in other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to evaluate python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='ยฟcuantos dรญas faltan para navidad?', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='[\\n  {\\n    \"tool\": \"get_time\",\\n    \"tool_input\": {\\n      \"kind\": \"date\"\\n    }\\n  }\\n]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 7.75, 'completion_tokens': 30, 'completion_tokens_after_first_per_sec': 141.30734146392467, 'completion_tokens_after_first_per_sec_first_ten': 192.05482916107837, 'completion_tokens_per_sec': 59.75833670115582, 'end_time': 1729619707.3751497, 'is_last_response': True, 'prompt_tokens': 667, 'start_time': 1729619706.8241067, 'time_to_first_token': 0.34581661224365234, 'total_latency': 0.5020220048965947, 'total_tokens': 697, 'total_tokens_per_sec': 1388.3853560235202}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619706}, id='c7c562ca-ed74-44cc-8f59-73791d2e2dd9'),\n",
      " ToolMessage(content=\"Tool 'get_time'response: Current date: 22/10/2024\", tool_call_id='0'),\n",
      " AIMessage(content='[\\n  {\\n    \"tool\": \"python_repl\",\\n    \"tool_input\": {\\n      \"command\": \"from datetime import datetime\\\\n\\\\ndatetime.now()\\\\nchristmas_date = datetime(2024, 12, 25)\\\\ndays_to_christmas = (christmas_date - datetime.now()).days\\\\nprint(f\\'There are {days_to_christmas} days until Christmas.\\')\"\\n    }\\n  }\\n]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 3.869565217391304, 'completion_tokens': 89, 'completion_tokens_after_first_per_sec': 90.14243627670183, 'completion_tokens_after_first_per_sec_first_ten': 95.68581862624598, 'completion_tokens_per_sec': 69.74084916901663, 'end_time': 1729619709.358038, 'is_last_response': True, 'prompt_tokens': 727, 'start_time': 1729619708.0357795, 'time_to_first_token': 0.3460257053375244, 'total_latency': 1.2761530876159668, 'total_tokens': 816, 'total_tokens_per_sec': 639.4217182237929}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619708}, id='aa6acf17-01c6-47e0-a5a0-a223b0bc0c1c'),\n",
      " ToolMessage(content=\"Tool 'python_repl'response: There are 63 days until Christmas.\\n\", tool_call_id='1'),\n",
      " AIMessage(content='[\\n  {\\n    \"tool\": \"ConversationalResponse\",\\n    \"tool_input\": {\\n      \"response\": \"Faltan 63 dรญas para Navidad.\"\\n    }\\n  }\\n]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 7.166666666666667, 'completion_tokens': 40, 'completion_tokens_after_first_per_sec': 136.4144625576671, 'completion_tokens_after_first_per_sec_first_ten': 176.9613080345141, 'completion_tokens_per_sec': 70.14852418909605, 'end_time': 1729619710.6455176, 'is_last_response': True, 'prompt_tokens': 846, 'start_time': 1729619710.0154436, 'time_to_first_token': 0.3441805839538574, 'total_latency': 0.5702186961506688, 'total_tokens': 886, 'total_tokens_per_sec': 1553.7898107884776}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1729619710}, id='6bdfb60b-e6a4-40d7-bb67-f74ef47e2bac')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm(\n",
    "    'ยฟcuantos dรญas faltan para navidad?',\n",
    "    max_it=5,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Faltan 63 dรญas para Navidad.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
