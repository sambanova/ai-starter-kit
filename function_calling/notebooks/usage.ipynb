{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "# load env variables from a .env file into Python environment \n",
    "load_dotenv(os.path.join(repo_dir, '.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorgep/Documents/ask_public_own/fcenv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in SambaStudioEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_API_KEY is not set. Weave initialization skipped.\n"
     ]
    }
   ],
   "source": [
    "from function_calling.src.function_calling import FunctionCallingLlm\n",
    "from function_calling.src.tools import get_time, calculator, python_repl, QueryDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_time, calculator, python_repl, QueryDb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FunctionCallingLlm(\n",
    "        tools,\n",
    "        sambanova_api_base=\"https://api.sambanova.ai/v1\",\n",
    "        sambanova_api_key=os.environ.get(\"SAMBANOVA_API_KEY\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "Calling function calling LLM with prompt: \n",
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "\n",
      "Function calling LLM response: \n",
      "content='[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"Hello! How can I help you today?\"\\n  }\\n}]' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 13.666666666666666, 'completion_tokens': 35, 'completion_tokens_after_first_per_sec': 177.03395151769453, 'completion_tokens_after_first_per_sec_first_ten': 0, 'completion_tokens_per_sec': 52.74036369854918, 'end_time': 1731700929.1474066, 'is_last_response': True, 'prompt_tokens': 656, 'start_time': 1731700928.4837782, 'time_to_first_token': 0.4715747833251953, 'total_latency': 0.663628339767456, 'total_tokens': 691, 'total_tokens_per_sec': 1041.2454661627853}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700928} id='a9dd48ed-fe2c-4323-8a6e-83699d251708'\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Final function calling LLM history: \n",
      "\n",
      "(\"[SystemMessage(content='you are an helpful assistant and you have access to \"\n",
      " 'the following tools:\\\\n\\\\n{\\\\n  \"name\": \"get_time\",\\\\n  \"description\": '\n",
      " '\"Returns current date, current time or both.\",\\\\n  \"properties\": {\\\\n    '\n",
      " '\"kind\": {\\\\n      \"anyOf\": [\\\\n        {\\\\n          \"type\": '\n",
      " '\"string\"\\\\n        },\\\\n        {\\\\n          \"type\": \"null\"\\\\n        '\n",
      " '}\\\\n      ],\\\\n      \"description\": \"kind of information to retrieve '\n",
      " '\\\\\\\\\"date\\\\\\\\\", \\\\\\\\\"time\\\\\\\\\" or \\\\\\\\\"both\\\\\\\\\"\",\\\\n      \"title\": '\n",
      " '\"Kind\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"calculator\",\\\\n  \"description\": '\n",
      " '\"allow calculation of only basic operations: + - * and /\\\\\\\\nwith a string '\n",
      " 'input expression\",\\\\n  \"properties\": {\\\\n    \"expression\": {\\\\n      '\n",
      " '\"description\": \"expression to calculate, example \\\\\\'12 * 3\\\\\\'\",\\\\n      '\n",
      " '\"title\": \"Expression\",\\\\n      \"type\": \"string\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  '\n",
      " '\"name\": \"python_repl\",\\\\n  \"description\": \"A Python shell. Use this to '\n",
      " 'execute python commands. Input should be a valid python commands and '\n",
      " 'expressions. If you want to see the output of a value, you should print it '\n",
      " 'out with `print(...)`, if you need a specific module you should import '\n",
      " 'it.\",\\\\n  \"properties\": {\\\\n    \"command\": {\\\\n      \"description\": \"python '\n",
      " 'code to evaluate\",\\\\n      \"title\": \"Command\",\\\\n      \"type\": '\n",
      " '\"string\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"query_db\",\\\\n  \"description\": \"A '\n",
      " 'query generation tool. Use this to generate sql queries and retrieve the '\n",
      " 'results from a database. Do not pass sql queries directly. Input must be a '\n",
      " 'natural language question or instruction.\",\\\\n  \"properties\": {\\\\n    '\n",
      " '\"query\": {\\\\n      \"description\": \"natural language question or '\n",
      " 'instruction.\",\\\\n      \"title\": \"Query\",\\\\n      \"type\": \"string\"\\\\n    '\n",
      " '}\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"ConversationalResponse\",\\\\n  \"description\": '\n",
      " '\"Respond conversationally only if no other tools should be called for a '\n",
      " 'given query, or if you have a final answer. response must be in the same '\n",
      " 'language as the user query\",\\\\n  \"properties\": {\\\\n    \"response\": {\\\\n      '\n",
      " '\"description\": \"Conversational response to the user. must be in the same '\n",
      " 'language as the user query\",\\\\n      \"title\": \"Response\",\\\\n      \"type\": '\n",
      " '\"string\"\\\\n    }\\\\n  }\\\\n}\\\\n\\\\nYou must always select one or more of the '\n",
      " 'above tools and answer with only a list of JSON objects matching the '\n",
      " 'following schema:\\\\n\\\\n```json\\\\n[{\\\\n  \"tool\": <name of the selected '\n",
      " 'tool>,\\\\n  \"tool_input\": <parameters for the selected tool, matching the '\n",
      " \"tool\\\\'s JSON schema>\\\\n}]\\\\n```\\\\n\\\\nThink step by step\\\\nDo not call a \"\n",
      " 'tool if the input depends on another tool output that you do not have '\n",
      " 'yet.\\\\nDo not try to answer until you get all the tools output, if you do '\n",
      " 'not have an answer yet, you can continue calling tools until you do.\\\\nYour '\n",
      " \"answer should be in the same language as the initial query.\\\\n\\\\n', \"\n",
      " \"additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', \"\n",
      " \"additional_kwargs={}, response_metadata={}), AIMessage(content='[{\\\\n  \"\n",
      " '\"tool\": \"ConversationalResponse\",\\\\n  \"tool_input\": {\\\\n    \"response\": '\n",
      " '\"Hello! How can I help you today?\"\\\\n  }\\\\n}]\\', additional_kwargs={}, '\n",
      " \"response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': \"\n",
      " \"13.666666666666666, 'completion_tokens': 35, \"\n",
      " \"'completion_tokens_after_first_per_sec': 177.03395151769453, \"\n",
      " \"'completion_tokens_after_first_per_sec_first_ten': 0, \"\n",
      " \"'completion_tokens_per_sec': 52.74036369854918, 'end_time': \"\n",
      " \"1731700929.1474066, 'is_last_response': True, 'prompt_tokens': 656, \"\n",
      " \"'start_time': 1731700928.4837782, 'time_to_first_token': 0.4715747833251953, \"\n",
      " \"'total_latency': 0.663628339767456, 'total_tokens': 691, \"\n",
      " \"'total_tokens_per_sec': 1041.2454661627853}, 'model_name': \"\n",
      " \"'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': \"\n",
      " \"1731700928}, id='a9dd48ed-fe2c-4323-8a6e-83699d251708')]\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.function_call_llm('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "Calling function calling LLM with prompt: \n",
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\", additional_kwargs={}, response_metadata={})]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 15:02:10,542 [WARNING] - Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Function calling LLM response: \n",
      "content='[{\\n  \"tool\": \"python_repl\",\\n  \"tool_input\": {\\n    \"command\": \"print(sorted([\\'screwdriver\\', \\'pliers\\', \\'hammer\\']))\"\\n  }\\n}]' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 11.25, 'completion_tokens': 39, 'completion_tokens_after_first_per_sec': 162.6049180311144, 'completion_tokens_after_first_per_sec_first_ten': 243.2765518663642, 'completion_tokens_per_sec': 60.67872030198056, 'end_time': 1731700930.5096252, 'is_last_response': True, 'prompt_tokens': 673, 'start_time': 1731700929.7935119, 'time_to_first_token': 0.4824180603027344, 'total_latency': 0.6427294413248698, 'total_tokens': 712, 'total_tokens_per_sec': 1107.7756116669273}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700929} id='7e46dd8c-e5e2-4899-a8ec-1c4191f1ea2f'\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Tool python_repl invoked with input {'command': \"print(sorted(['screwdriver', 'pliers', 'hammer']))\"}\n",
      "\n",
      "Tool response: ['hammer', 'pliers', 'screwdriver']\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Calling function calling LLM with prompt: \n",
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\", additional_kwargs={}, response_metadata={}), AIMessage(content='[{\\n  \"tool\": \"python_repl\",\\n  \"tool_input\": {\\n    \"command\": \"print(sorted([\\'screwdriver\\', \\'pliers\\', \\'hammer\\']))\"\\n  }\\n}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 11.25, 'completion_tokens': 39, 'completion_tokens_after_first_per_sec': 162.6049180311144, 'completion_tokens_after_first_per_sec_first_ten': 243.2765518663642, 'completion_tokens_per_sec': 60.67872030198056, 'end_time': 1731700930.5096252, 'is_last_response': True, 'prompt_tokens': 673, 'start_time': 1731700929.7935119, 'time_to_first_token': 0.4824180603027344, 'total_latency': 0.6427294413248698, 'total_tokens': 712, 'total_tokens_per_sec': 1107.7756116669273}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700929}, id='7e46dd8c-e5e2-4899-a8ec-1c4191f1ea2f'), ToolMessage(content=\"Tool 'python_repl'response: ['hammer', 'pliers', 'screwdriver']\\n\", tool_call_id='0')]\n",
      "\n",
      "\n",
      "Function calling LLM response: \n",
      "content='[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"[\\'hammer\\', \\'pliers\\', \\'screwdriver\\']\"\\n  }\\n}]' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 14.666666666666666, 'completion_tokens': 38, 'completion_tokens_after_first_per_sec': 191.22880164428733, 'completion_tokens_after_first_per_sec_first_ten': 0, 'completion_tokens_per_sec': 55.62011380616938, 'end_time': 1731700936.6588533, 'is_last_response': True, 'prompt_tokens': 747, 'start_time': 1731700935.9756472, 'time_to_first_token': 0.48972058296203613, 'total_latency': 0.6832060813903809, 'total_tokens': 785, 'total_tokens_per_sec': 1148.9944562590254}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700935} id='c82c46cd-036c-4a86-b112-66821a664c6d'\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Final function calling LLM history: \n",
      "\n",
      "(\"[SystemMessage(content='you are an helpful assistant and you have access to \"\n",
      " 'the following tools:\\\\n\\\\n{\\\\n  \"name\": \"get_time\",\\\\n  \"description\": '\n",
      " '\"Returns current date, current time or both.\",\\\\n  \"properties\": {\\\\n    '\n",
      " '\"kind\": {\\\\n      \"anyOf\": [\\\\n        {\\\\n          \"type\": '\n",
      " '\"string\"\\\\n        },\\\\n        {\\\\n          \"type\": \"null\"\\\\n        '\n",
      " '}\\\\n      ],\\\\n      \"description\": \"kind of information to retrieve '\n",
      " '\\\\\\\\\"date\\\\\\\\\", \\\\\\\\\"time\\\\\\\\\" or \\\\\\\\\"both\\\\\\\\\"\",\\\\n      \"title\": '\n",
      " '\"Kind\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"calculator\",\\\\n  \"description\": '\n",
      " '\"allow calculation of only basic operations: + - * and /\\\\\\\\nwith a string '\n",
      " 'input expression\",\\\\n  \"properties\": {\\\\n    \"expression\": {\\\\n      '\n",
      " '\"description\": \"expression to calculate, example \\\\\\'12 * 3\\\\\\'\",\\\\n      '\n",
      " '\"title\": \"Expression\",\\\\n      \"type\": \"string\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  '\n",
      " '\"name\": \"python_repl\",\\\\n  \"description\": \"A Python shell. Use this to '\n",
      " 'execute python commands. Input should be a valid python commands and '\n",
      " 'expressions. If you want to see the output of a value, you should print it '\n",
      " 'out with `print(...)`, if you need a specific module you should import '\n",
      " 'it.\",\\\\n  \"properties\": {\\\\n    \"command\": {\\\\n      \"description\": \"python '\n",
      " 'code to evaluate\",\\\\n      \"title\": \"Command\",\\\\n      \"type\": '\n",
      " '\"string\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"query_db\",\\\\n  \"description\": \"A '\n",
      " 'query generation tool. Use this to generate sql queries and retrieve the '\n",
      " 'results from a database. Do not pass sql queries directly. Input must be a '\n",
      " 'natural language question or instruction.\",\\\\n  \"properties\": {\\\\n    '\n",
      " '\"query\": {\\\\n      \"description\": \"natural language question or '\n",
      " 'instruction.\",\\\\n      \"title\": \"Query\",\\\\n      \"type\": \"string\"\\\\n    '\n",
      " '}\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"ConversationalResponse\",\\\\n  \"description\": '\n",
      " '\"Respond conversationally only if no other tools should be called for a '\n",
      " 'given query, or if you have a final answer. response must be in the same '\n",
      " 'language as the user query\",\\\\n  \"properties\": {\\\\n    \"response\": {\\\\n      '\n",
      " '\"description\": \"Conversational response to the user. must be in the same '\n",
      " 'language as the user query\",\\\\n      \"title\": \"Response\",\\\\n      \"type\": '\n",
      " '\"string\"\\\\n    }\\\\n  }\\\\n}\\\\n\\\\nYou must always select one or more of the '\n",
      " 'above tools and answer with only a list of JSON objects matching the '\n",
      " 'following schema:\\\\n\\\\n```json\\\\n[{\\\\n  \"tool\": <name of the selected '\n",
      " 'tool>,\\\\n  \"tool_input\": <parameters for the selected tool, matching the '\n",
      " \"tool\\\\'s JSON schema>\\\\n}]\\\\n```\\\\n\\\\nThink step by step\\\\nDo not call a \"\n",
      " 'tool if the input depends on another tool output that you do not have '\n",
      " 'yet.\\\\nDo not try to answer until you get all the tools output, if you do '\n",
      " 'not have an answer yet, you can continue calling tools until you do.\\\\nYour '\n",
      " \"answer should be in the same language as the initial query.\\\\n\\\\n', \"\n",
      " 'additional_kwargs={}, response_metadata={}), HumanMessage(content=\"sort this '\n",
      " 'list of elements alphabetically [\\'screwdriver\\', \\'pliers\\', \\'hammer\\']\", '\n",
      " \"additional_kwargs={}, response_metadata={}), AIMessage(content='[{\\\\n  \"\n",
      " '\"tool\": \"python_repl\",\\\\n  \"tool_input\": {\\\\n    \"command\": '\n",
      " '\"print(sorted([\\\\\\'screwdriver\\\\\\', \\\\\\'pliers\\\\\\', \\\\\\'hammer\\\\\\']))\"\\\\n  '\n",
      " \"}\\\\n}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', \"\n",
      " \"'usage': {'acceptance_rate': 11.25, 'completion_tokens': 39, \"\n",
      " \"'completion_tokens_after_first_per_sec': 162.6049180311144, \"\n",
      " \"'completion_tokens_after_first_per_sec_first_ten': 243.2765518663642, \"\n",
      " \"'completion_tokens_per_sec': 60.67872030198056, 'end_time': \"\n",
      " \"1731700930.5096252, 'is_last_response': True, 'prompt_tokens': 673, \"\n",
      " \"'start_time': 1731700929.7935119, 'time_to_first_token': 0.4824180603027344, \"\n",
      " \"'total_latency': 0.6427294413248698, 'total_tokens': 712, \"\n",
      " \"'total_tokens_per_sec': 1107.7756116669273}, 'model_name': \"\n",
      " \"'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': \"\n",
      " \"1731700929}, id='7e46dd8c-e5e2-4899-a8ec-1c4191f1ea2f'), \"\n",
      " 'ToolMessage(content=\"Tool \\'python_repl\\'response: [\\'hammer\\', \\'pliers\\', '\n",
      " '\\'screwdriver\\']\\\\n\", tool_call_id=\\'0\\'), AIMessage(content=\\'[{\\\\n  '\n",
      " '\"tool\": \"ConversationalResponse\",\\\\n  \"tool_input\": {\\\\n    \"response\": '\n",
      " '\"[\\\\\\'hammer\\\\\\', \\\\\\'pliers\\\\\\', \\\\\\'screwdriver\\\\\\']\"\\\\n  }\\\\n}]\\', '\n",
      " \"additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': \"\n",
      " \"{'acceptance_rate': 14.666666666666666, 'completion_tokens': 38, \"\n",
      " \"'completion_tokens_after_first_per_sec': 191.22880164428733, \"\n",
      " \"'completion_tokens_after_first_per_sec_first_ten': 0, \"\n",
      " \"'completion_tokens_per_sec': 55.62011380616938, 'end_time': \"\n",
      " \"1731700936.6588533, 'is_last_response': True, 'prompt_tokens': 747, \"\n",
      " \"'start_time': 1731700935.9756472, 'time_to_first_token': \"\n",
      " \"0.48972058296203613, 'total_latency': 0.6832060813903809, 'total_tokens': \"\n",
      " \"785, 'total_tokens_per_sec': 1148.9944562590254}, 'model_name': \"\n",
      " \"'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': \"\n",
      " \"1731700935}, id='c82c46cd-036c-4a86-b112-66821a664c6d')]\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"['hammer', 'pliers', 'screwdriver']\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.function_call_llm(\"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "Calling function calling LLM with prompt: \n",
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='cuantos dias faltan para navidad?', additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "\n",
      "Function calling LLM response: \n",
      "content='[\\n  {\\n    \"tool\": \"get_time\",\\n    \"tool_input\": {\\n      \"kind\": \"date\"\\n    }\\n  }\\n]' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 13.333333333333334, 'completion_tokens': 29, 'completion_tokens_after_first_per_sec': 150.26576862448053, 'completion_tokens_after_first_per_sec_first_ten': 0, 'completion_tokens_per_sec': 44.626181466504356, 'end_time': 1731700937.9487605, 'is_last_response': True, 'prompt_tokens': 666, 'start_time': 1731700937.2989178, 'time_to_first_token': 0.46350622177124023, 'total_latency': 0.6498427391052246, 'total_tokens': 695, 'total_tokens_per_sec': 1069.489521352432}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700937} id='ec84665a-cd0e-439d-be98-cf7c7e0b55ad'\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Tool get_time invoked with input {'kind': 'date'}\n",
      "\n",
      "Tool response: Current date: 15/11/2024\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Calling function calling LLM with prompt: \n",
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='cuantos dias faltan para navidad?', additional_kwargs={}, response_metadata={}), AIMessage(content='[\\n  {\\n    \"tool\": \"get_time\",\\n    \"tool_input\": {\\n      \"kind\": \"date\"\\n    }\\n  }\\n]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 13.333333333333334, 'completion_tokens': 29, 'completion_tokens_after_first_per_sec': 150.26576862448053, 'completion_tokens_after_first_per_sec_first_ten': 0, 'completion_tokens_per_sec': 44.626181466504356, 'end_time': 1731700937.9487605, 'is_last_response': True, 'prompt_tokens': 666, 'start_time': 1731700937.2989178, 'time_to_first_token': 0.46350622177124023, 'total_latency': 0.6498427391052246, 'total_tokens': 695, 'total_tokens_per_sec': 1069.489521352432}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700937}, id='ec84665a-cd0e-439d-be98-cf7c7e0b55ad'), ToolMessage(content=\"Tool 'get_time'response: Current date: 15/11/2024\", tool_call_id='0')]\n",
      "\n",
      "\n",
      "Function calling LLM response: \n",
      "content='[\\n  {\\n    \"tool\": \"python_repl\",\\n    \"tool_input\": {\\n      \"command\": \"from datetime import datetime; date_format = \\'%d/%m/%Y\\'; current_date = datetime.strptime(\\'15/11/2024\\', date_format); christmas_date = datetime.strptime(\\'25/12/2024\\', date_format); days_to_christmas = (christmas_date - current_date).days; print(days_to_christmas)\"\\n    }\\n  }\\n]' additional_kwargs={} response_metadata={'finish_reason': 'tool_calls', 'usage': {'acceptance_rate': 7.2, 'completion_tokens': 98, 'completion_tokens_after_first_per_sec': 129.2426994975117, 'completion_tokens_after_first_per_sec_first_ten': 154.35131330787985, 'completion_tokens_per_sec': 88.13984376817632, 'end_time': 1731700939.8270385, 'is_last_response': True, 'prompt_tokens': 726, 'start_time': 1731700938.5995584, 'time_to_first_token': 0.47695422172546387, 'total_latency': 1.11186945438385, 'total_tokens': 824, 'total_tokens_per_sec': 741.094196581401}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700938} id='fb7c05f0-6fa4-45ae-900b-4916f3695cb6'\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Tool python_repl invoked with input {'command': \"from datetime import datetime; date_format = '%d/%m/%Y'; current_date = datetime.strptime('15/11/2024', date_format); christmas_date = datetime.strptime('25/12/2024', date_format); days_to_christmas = (christmas_date - current_date).days; print(days_to_christmas)\"}\n",
      "\n",
      "Tool response: 40\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Calling function calling LLM with prompt: \n",
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='cuantos dias faltan para navidad?', additional_kwargs={}, response_metadata={}), AIMessage(content='[\\n  {\\n    \"tool\": \"get_time\",\\n    \"tool_input\": {\\n      \"kind\": \"date\"\\n    }\\n  }\\n]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 13.333333333333334, 'completion_tokens': 29, 'completion_tokens_after_first_per_sec': 150.26576862448053, 'completion_tokens_after_first_per_sec_first_ten': 0, 'completion_tokens_per_sec': 44.626181466504356, 'end_time': 1731700937.9487605, 'is_last_response': True, 'prompt_tokens': 666, 'start_time': 1731700937.2989178, 'time_to_first_token': 0.46350622177124023, 'total_latency': 0.6498427391052246, 'total_tokens': 695, 'total_tokens_per_sec': 1069.489521352432}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700937}, id='ec84665a-cd0e-439d-be98-cf7c7e0b55ad'), ToolMessage(content=\"Tool 'get_time'response: Current date: 15/11/2024\", tool_call_id='0'), AIMessage(content='[\\n  {\\n    \"tool\": \"python_repl\",\\n    \"tool_input\": {\\n      \"command\": \"from datetime import datetime; date_format = \\'%d/%m/%Y\\'; current_date = datetime.strptime(\\'15/11/2024\\', date_format); christmas_date = datetime.strptime(\\'25/12/2024\\', date_format); days_to_christmas = (christmas_date - current_date).days; print(days_to_christmas)\"\\n    }\\n  }\\n]', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'usage': {'acceptance_rate': 7.2, 'completion_tokens': 98, 'completion_tokens_after_first_per_sec': 129.2426994975117, 'completion_tokens_after_first_per_sec_first_ten': 154.35131330787985, 'completion_tokens_per_sec': 88.13984376817632, 'end_time': 1731700939.8270385, 'is_last_response': True, 'prompt_tokens': 726, 'start_time': 1731700938.5995584, 'time_to_first_token': 0.47695422172546387, 'total_latency': 1.11186945438385, 'total_tokens': 824, 'total_tokens_per_sec': 741.094196581401}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700938}, id='fb7c05f0-6fa4-45ae-900b-4916f3695cb6'), ToolMessage(content=\"Tool 'python_repl'response: 40\\n\", tool_call_id='1')]\n",
      "\n",
      "\n",
      "Function calling LLM response: \n",
      "content='[\\n  {\\n    \"tool\": \"ConversationalResponse\",\\n    \"tool_input\": {\\n      \"response\": \"Faltan 40 d√≠as para Navidad.\"\\n    }\\n  }\\n]' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 15, 'completion_tokens': 39, 'completion_tokens_after_first_per_sec': 203.03611332979193, 'completion_tokens_after_first_per_sec_first_ten': 0, 'completion_tokens_per_sec': 58.10354202527491, 'end_time': 1731700941.1916294, 'is_last_response': True, 'prompt_tokens': 849, 'start_time': 1731700940.5204139, 'time_to_first_token': 0.4840567111968994, 'total_latency': 0.6712155342102051, 'total_tokens': 888, 'total_tokens_per_sec': 1322.9729568831826}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700940} id='f9ed2ac3-4297-476d-ac01-b00fa92eacc3'\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Final function calling LLM history: \n",
      "\n",
      "(\"[SystemMessage(content='you are an helpful assistant and you have access to \"\n",
      " 'the following tools:\\\\n\\\\n{\\\\n  \"name\": \"get_time\",\\\\n  \"description\": '\n",
      " '\"Returns current date, current time or both.\",\\\\n  \"properties\": {\\\\n    '\n",
      " '\"kind\": {\\\\n      \"anyOf\": [\\\\n        {\\\\n          \"type\": '\n",
      " '\"string\"\\\\n        },\\\\n        {\\\\n          \"type\": \"null\"\\\\n        '\n",
      " '}\\\\n      ],\\\\n      \"description\": \"kind of information to retrieve '\n",
      " '\\\\\\\\\"date\\\\\\\\\", \\\\\\\\\"time\\\\\\\\\" or \\\\\\\\\"both\\\\\\\\\"\",\\\\n      \"title\": '\n",
      " '\"Kind\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"calculator\",\\\\n  \"description\": '\n",
      " '\"allow calculation of only basic operations: + - * and /\\\\\\\\nwith a string '\n",
      " 'input expression\",\\\\n  \"properties\": {\\\\n    \"expression\": {\\\\n      '\n",
      " '\"description\": \"expression to calculate, example \\\\\\'12 * 3\\\\\\'\",\\\\n      '\n",
      " '\"title\": \"Expression\",\\\\n      \"type\": \"string\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  '\n",
      " '\"name\": \"python_repl\",\\\\n  \"description\": \"A Python shell. Use this to '\n",
      " 'execute python commands. Input should be a valid python commands and '\n",
      " 'expressions. If you want to see the output of a value, you should print it '\n",
      " 'out with `print(...)`, if you need a specific module you should import '\n",
      " 'it.\",\\\\n  \"properties\": {\\\\n    \"command\": {\\\\n      \"description\": \"python '\n",
      " 'code to evaluate\",\\\\n      \"title\": \"Command\",\\\\n      \"type\": '\n",
      " '\"string\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"query_db\",\\\\n  \"description\": \"A '\n",
      " 'query generation tool. Use this to generate sql queries and retrieve the '\n",
      " 'results from a database. Do not pass sql queries directly. Input must be a '\n",
      " 'natural language question or instruction.\",\\\\n  \"properties\": {\\\\n    '\n",
      " '\"query\": {\\\\n      \"description\": \"natural language question or '\n",
      " 'instruction.\",\\\\n      \"title\": \"Query\",\\\\n      \"type\": \"string\"\\\\n    '\n",
      " '}\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"ConversationalResponse\",\\\\n  \"description\": '\n",
      " '\"Respond conversationally only if no other tools should be called for a '\n",
      " 'given query, or if you have a final answer. response must be in the same '\n",
      " 'language as the user query\",\\\\n  \"properties\": {\\\\n    \"response\": {\\\\n      '\n",
      " '\"description\": \"Conversational response to the user. must be in the same '\n",
      " 'language as the user query\",\\\\n      \"title\": \"Response\",\\\\n      \"type\": '\n",
      " '\"string\"\\\\n    }\\\\n  }\\\\n}\\\\n\\\\nYou must always select one or more of the '\n",
      " 'above tools and answer with only a list of JSON objects matching the '\n",
      " 'following schema:\\\\n\\\\n```json\\\\n[{\\\\n  \"tool\": <name of the selected '\n",
      " 'tool>,\\\\n  \"tool_input\": <parameters for the selected tool, matching the '\n",
      " \"tool\\\\'s JSON schema>\\\\n}]\\\\n```\\\\n\\\\nThink step by step\\\\nDo not call a \"\n",
      " 'tool if the input depends on another tool output that you do not have '\n",
      " 'yet.\\\\nDo not try to answer until you get all the tools output, if you do '\n",
      " 'not have an answer yet, you can continue calling tools until you do.\\\\nYour '\n",
      " \"answer should be in the same language as the initial query.\\\\n\\\\n', \"\n",
      " \"additional_kwargs={}, response_metadata={}), HumanMessage(content='cuantos \"\n",
      " \"dias faltan para navidad?', additional_kwargs={}, response_metadata={}), \"\n",
      " 'AIMessage(content=\\'[\\\\n  {\\\\n    \"tool\": \"get_time\",\\\\n    \"tool_input\": '\n",
      " '{\\\\n      \"kind\": \"date\"\\\\n    }\\\\n  }\\\\n]\\', additional_kwargs={}, '\n",
      " \"response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': \"\n",
      " \"13.333333333333334, 'completion_tokens': 29, \"\n",
      " \"'completion_tokens_after_first_per_sec': 150.26576862448053, \"\n",
      " \"'completion_tokens_after_first_per_sec_first_ten': 0, \"\n",
      " \"'completion_tokens_per_sec': 44.626181466504356, 'end_time': \"\n",
      " \"1731700937.9487605, 'is_last_response': True, 'prompt_tokens': 666, \"\n",
      " \"'start_time': 1731700937.2989178, 'time_to_first_token': \"\n",
      " \"0.46350622177124023, 'total_latency': 0.6498427391052246, 'total_tokens': \"\n",
      " \"695, 'total_tokens_per_sec': 1069.489521352432}, 'model_name': \"\n",
      " \"'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': \"\n",
      " \"1731700937}, id='ec84665a-cd0e-439d-be98-cf7c7e0b55ad'), \"\n",
      " 'ToolMessage(content=\"Tool \\'get_time\\'response: Current date: 15/11/2024\", '\n",
      " 'tool_call_id=\\'0\\'), AIMessage(content=\\'[\\\\n  {\\\\n    \"tool\": '\n",
      " '\"python_repl\",\\\\n    \"tool_input\": {\\\\n      \"command\": \"from datetime '\n",
      " \"import datetime; date_format = \\\\'%d/%m/%Y\\\\'; current_date = \"\n",
      " \"datetime.strptime(\\\\'15/11/2024\\\\', date_format); christmas_date = \"\n",
      " \"datetime.strptime(\\\\'25/12/2024\\\\', date_format); days_to_christmas = \"\n",
      " '(christmas_date - current_date).days; print(days_to_christmas)\"\\\\n    }\\\\n  '\n",
      " \"}\\\\n]', additional_kwargs={}, response_metadata={'finish_reason': \"\n",
      " \"'tool_calls', 'usage': {'acceptance_rate': 7.2, 'completion_tokens': 98, \"\n",
      " \"'completion_tokens_after_first_per_sec': 129.2426994975117, \"\n",
      " \"'completion_tokens_after_first_per_sec_first_ten': 154.35131330787985, \"\n",
      " \"'completion_tokens_per_sec': 88.13984376817632, 'end_time': \"\n",
      " \"1731700939.8270385, 'is_last_response': True, 'prompt_tokens': 726, \"\n",
      " \"'start_time': 1731700938.5995584, 'time_to_first_token': \"\n",
      " \"0.47695422172546387, 'total_latency': 1.11186945438385, 'total_tokens': 824, \"\n",
      " \"'total_tokens_per_sec': 741.094196581401}, 'model_name': \"\n",
      " \"'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': \"\n",
      " \"1731700938}, id='fb7c05f0-6fa4-45ae-900b-4916f3695cb6'), \"\n",
      " 'ToolMessage(content=\"Tool \\'python_repl\\'response: 40\\\\n\", '\n",
      " 'tool_call_id=\\'1\\'), AIMessage(content=\\'[\\\\n  {\\\\n    \"tool\": '\n",
      " '\"ConversationalResponse\",\\\\n    \"tool_input\": {\\\\n      \"response\": \"Faltan '\n",
      " '40 d√≠as para Navidad.\"\\\\n    }\\\\n  }\\\\n]\\', additional_kwargs={}, '\n",
      " \"response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 15, \"\n",
      " \"'completion_tokens': 39, 'completion_tokens_after_first_per_sec': \"\n",
      " \"203.03611332979193, 'completion_tokens_after_first_per_sec_first_ten': 0, \"\n",
      " \"'completion_tokens_per_sec': 58.10354202527491, 'end_time': \"\n",
      " \"1731700941.1916294, 'is_last_response': True, 'prompt_tokens': 849, \"\n",
      " \"'start_time': 1731700940.5204139, 'time_to_first_token': 0.4840567111968994, \"\n",
      " \"'total_latency': 0.6712155342102051, 'total_tokens': 888, \"\n",
      " \"'total_tokens_per_sec': 1322.9729568831826}, 'model_name': \"\n",
      " \"'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': \"\n",
      " \"1731700940}, id='f9ed2ac3-4297-476d-ac01-b00fa92eacc3')]\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Faltan 40 d√≠as para Navidad.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.function_call_llm('cuantos dias faltan para navidad?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "Calling function calling LLM with prompt: \n",
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the name of the customer who has bought the most items, and how many items?', additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "\n",
      "Function calling LLM response: \n",
      "content='[{\\n  \"tool\": \"query_db\",\\n  \"tool_input\": {\\n    \"query\": \"What is the name of the customer who has bought the most items, and how many items?\"\\n  }\\n}]' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 16.333333333333332, 'completion_tokens': 43, 'completion_tokens_after_first_per_sec': 225.24273711694133, 'completion_tokens_after_first_per_sec_first_ten': 0, 'completion_tokens_per_sec': 65.9143367965254, 'end_time': 1731700943.0208683, 'is_last_response': True, 'prompt_tokens': 674, 'start_time': 1731700942.3685064, 'time_to_first_token': 0.4658963680267334, 'total_latency': 0.6523618698120117, 'total_tokens': 717, 'total_tokens_per_sec': 1099.0832437932258}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700942} id='5a7f45ed-10a5-4a0f-b4bb-ef2305b24c9b'\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Tool query_db invoked with input {'query': 'What is the name of the customer who has bought the most items, and how many items?'}\n",
      "\n",
      "query_db: Calling query generation LLM with input: \n",
      "What is the name of the customer who has bought the most items, and how many items?\n",
      "\n",
      "query_db: query generation LLM raw response: \n",
      "```sql\n",
      "SELECT c.FirstName, c.LastName, SUM(ii.Quantity) as TotalItems\n",
      "FROM customers c\n",
      "JOIN invoices i ON c.CustomerId = i.CustomerId\n",
      "JOIN invoice_items ii ON i.InvoiceId = ii.InvoiceId\n",
      "GROUP BY c.CustomerId, c.FirstName, c.LastName\n",
      "ORDER BY TotalItems DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "query_db: query generation LLM filtered response: \n",
      "SELECT c.FirstName, c.LastName, SUM(ii.Quantity) as TotalItems\n",
      "FROM customers c\n",
      "JOIN invoices i ON c.CustomerId = i.CustomerId\n",
      "JOIN invoice_items ii ON i.InvoiceId = ii.InvoiceId\n",
      "GROUP BY c.CustomerId, c.FirstName, c.LastName\n",
      "ORDER BY TotalItems DESC\n",
      "LIMIT 1;\n",
      "\n",
      "query_db: executing query: \n",
      "SELECT c.FirstName, c.LastName, SUM(ii.Quantity) as TotalItems\n",
      "FROM customers c\n",
      "JOIN invoices i ON c.CustomerId = i.CustomerId\n",
      "JOIN invoice_items ii ON i.InvoiceId = ii.InvoiceId\n",
      "GROUP BY c.CustomerId, c.FirstName, c.LastName\n",
      "ORDER BY TotalItems DESC\n",
      "LIMIT 1\n",
      "\n",
      "query_db: query result: \n",
      "[('Lu√≠s', 'Gon√ßalves', 38)]\n",
      "\n",
      "Tool response: Query SELECT c.FirstName, c.LastName, SUM(ii.Quantity) as TotalItems\n",
      "FROM customers c\n",
      "JOIN invoices i ON c.CustomerId = i.CustomerId\n",
      "JOIN invoice_items ii ON i.InvoiceId = ii.InvoiceId\n",
      "GROUP BY c.CustomerId, c.FirstName, c.LastName\n",
      "ORDER BY TotalItems DESC\n",
      "LIMIT 1 executed with result [('Lu√≠s', 'Gon√ßalves', 38)]\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Calling function calling LLM with prompt: \n",
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"anyOf\": [\\n        {\\n          \"type\": \"string\"\\n        },\\n        {\\n          \"type\": \"null\"\\n        }\\n      ],\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"title\": \"Kind\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression\",\\n  \"properties\": {\\n    \"expression\": {\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"title\": \"Expression\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...)`, if you need a specific module you should import it.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"description\": \"python code to evaluate\",\\n      \"title\": \"Command\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"query_db\",\\n  \"description\": \"A query generation tool. Use this to generate sql queries and retrieve the results from a database. Do not pass sql queries directly. Input must be a natural language question or instruction.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"natural language question or instruction.\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer. response must be in the same language as the user query\",\\n  \"properties\": {\\n    \"response\": {\\n      \"description\": \"Conversational response to the user. must be in the same language as the user query\",\\n      \"title\": \"Response\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output that you do not have yet.\\nDo not try to answer until you get all the tools output, if you do not have an answer yet, you can continue calling tools until you do.\\nYour answer should be in the same language as the initial query.\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the name of the customer who has bought the most items, and how many items?', additional_kwargs={}, response_metadata={}), AIMessage(content='[{\\n  \"tool\": \"query_db\",\\n  \"tool_input\": {\\n    \"query\": \"What is the name of the customer who has bought the most items, and how many items?\"\\n  }\\n}]', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 16.333333333333332, 'completion_tokens': 43, 'completion_tokens_after_first_per_sec': 225.24273711694133, 'completion_tokens_after_first_per_sec_first_ten': 0, 'completion_tokens_per_sec': 65.9143367965254, 'end_time': 1731700943.0208683, 'is_last_response': True, 'prompt_tokens': 674, 'start_time': 1731700942.3685064, 'time_to_first_token': 0.4658963680267334, 'total_latency': 0.6523618698120117, 'total_tokens': 717, 'total_tokens_per_sec': 1099.0832437932258}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700942}, id='5a7f45ed-10a5-4a0f-b4bb-ef2305b24c9b'), ToolMessage(content=\"Tool 'query_db'response: Query SELECT c.FirstName, c.LastName, SUM(ii.Quantity) as TotalItems\\nFROM customers c\\nJOIN invoices i ON c.CustomerId = i.CustomerId\\nJOIN invoice_items ii ON i.InvoiceId = ii.InvoiceId\\nGROUP BY c.CustomerId, c.FirstName, c.LastName\\nORDER BY TotalItems DESC\\nLIMIT 1 executed with result [('Lu√≠s', 'Gon√ßalves', 38)]\", tool_call_id='0')]\n",
      "\n",
      "\n",
      "Function calling LLM response: \n",
      "content='[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"The customer who has bought the most items is Lu√≠s Gon√ßalves with 38 items.\"\\n  }\\n}]' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': 12.75, 'completion_tokens': 46, 'completion_tokens_after_first_per_sec': 191.55357945705555, 'completion_tokens_after_first_per_sec_first_ten': 0, 'completion_tokens_per_sec': 65.65122414237216, 'end_time': 1731700946.9349337, 'is_last_response': True, 'prompt_tokens': 823, 'start_time': 1731700946.2342613, 'time_to_first_token': 0.46575117111206055, 'total_latency': 0.7006723880767822, 'total_tokens': 869, 'total_tokens_per_sec': 1240.2372560809001}, 'model_name': 'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': 1731700946} id='c2a6a2c4-0f06-4c43-a8bc-3c1393ea6b6c'\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "Final function calling LLM history: \n",
      "\n",
      "(\"[SystemMessage(content='you are an helpful assistant and you have access to \"\n",
      " 'the following tools:\\\\n\\\\n{\\\\n  \"name\": \"get_time\",\\\\n  \"description\": '\n",
      " '\"Returns current date, current time or both.\",\\\\n  \"properties\": {\\\\n    '\n",
      " '\"kind\": {\\\\n      \"anyOf\": [\\\\n        {\\\\n          \"type\": '\n",
      " '\"string\"\\\\n        },\\\\n        {\\\\n          \"type\": \"null\"\\\\n        '\n",
      " '}\\\\n      ],\\\\n      \"description\": \"kind of information to retrieve '\n",
      " '\\\\\\\\\"date\\\\\\\\\", \\\\\\\\\"time\\\\\\\\\" or \\\\\\\\\"both\\\\\\\\\"\",\\\\n      \"title\": '\n",
      " '\"Kind\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"calculator\",\\\\n  \"description\": '\n",
      " '\"allow calculation of only basic operations: + - * and /\\\\\\\\nwith a string '\n",
      " 'input expression\",\\\\n  \"properties\": {\\\\n    \"expression\": {\\\\n      '\n",
      " '\"description\": \"expression to calculate, example \\\\\\'12 * 3\\\\\\'\",\\\\n      '\n",
      " '\"title\": \"Expression\",\\\\n      \"type\": \"string\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  '\n",
      " '\"name\": \"python_repl\",\\\\n  \"description\": \"A Python shell. Use this to '\n",
      " 'execute python commands. Input should be a valid python commands and '\n",
      " 'expressions. If you want to see the output of a value, you should print it '\n",
      " 'out with `print(...)`, if you need a specific module you should import '\n",
      " 'it.\",\\\\n  \"properties\": {\\\\n    \"command\": {\\\\n      \"description\": \"python '\n",
      " 'code to evaluate\",\\\\n      \"title\": \"Command\",\\\\n      \"type\": '\n",
      " '\"string\"\\\\n    }\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"query_db\",\\\\n  \"description\": \"A '\n",
      " 'query generation tool. Use this to generate sql queries and retrieve the '\n",
      " 'results from a database. Do not pass sql queries directly. Input must be a '\n",
      " 'natural language question or instruction.\",\\\\n  \"properties\": {\\\\n    '\n",
      " '\"query\": {\\\\n      \"description\": \"natural language question or '\n",
      " 'instruction.\",\\\\n      \"title\": \"Query\",\\\\n      \"type\": \"string\"\\\\n    '\n",
      " '}\\\\n  }\\\\n}\\\\n{\\\\n  \"name\": \"ConversationalResponse\",\\\\n  \"description\": '\n",
      " '\"Respond conversationally only if no other tools should be called for a '\n",
      " 'given query, or if you have a final answer. response must be in the same '\n",
      " 'language as the user query\",\\\\n  \"properties\": {\\\\n    \"response\": {\\\\n      '\n",
      " '\"description\": \"Conversational response to the user. must be in the same '\n",
      " 'language as the user query\",\\\\n      \"title\": \"Response\",\\\\n      \"type\": '\n",
      " '\"string\"\\\\n    }\\\\n  }\\\\n}\\\\n\\\\nYou must always select one or more of the '\n",
      " 'above tools and answer with only a list of JSON objects matching the '\n",
      " 'following schema:\\\\n\\\\n```json\\\\n[{\\\\n  \"tool\": <name of the selected '\n",
      " 'tool>,\\\\n  \"tool_input\": <parameters for the selected tool, matching the '\n",
      " \"tool\\\\'s JSON schema>\\\\n}]\\\\n```\\\\n\\\\nThink step by step\\\\nDo not call a \"\n",
      " 'tool if the input depends on another tool output that you do not have '\n",
      " 'yet.\\\\nDo not try to answer until you get all the tools output, if you do '\n",
      " 'not have an answer yet, you can continue calling tools until you do.\\\\nYour '\n",
      " \"answer should be in the same language as the initial query.\\\\n\\\\n', \"\n",
      " \"additional_kwargs={}, response_metadata={}), HumanMessage(content='What is \"\n",
      " 'the name of the customer who has bought the most items, and how many '\n",
      " \"items?', additional_kwargs={}, response_metadata={}), \"\n",
      " 'AIMessage(content=\\'[{\\\\n  \"tool\": \"query_db\",\\\\n  \"tool_input\": {\\\\n    '\n",
      " '\"query\": \"What is the name of the customer who has bought the most items, '\n",
      " 'and how many items?\"\\\\n  }\\\\n}]\\', additional_kwargs={}, '\n",
      " \"response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': \"\n",
      " \"16.333333333333332, 'completion_tokens': 43, \"\n",
      " \"'completion_tokens_after_first_per_sec': 225.24273711694133, \"\n",
      " \"'completion_tokens_after_first_per_sec_first_ten': 0, \"\n",
      " \"'completion_tokens_per_sec': 65.9143367965254, 'end_time': \"\n",
      " \"1731700943.0208683, 'is_last_response': True, 'prompt_tokens': 674, \"\n",
      " \"'start_time': 1731700942.3685064, 'time_to_first_token': 0.4658963680267334, \"\n",
      " \"'total_latency': 0.6523618698120117, 'total_tokens': 717, \"\n",
      " \"'total_tokens_per_sec': 1099.0832437932258}, 'model_name': \"\n",
      " \"'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': \"\n",
      " \"1731700942}, id='5a7f45ed-10a5-4a0f-b4bb-ef2305b24c9b'), \"\n",
      " 'ToolMessage(content=\"Tool \\'query_db\\'response: Query SELECT c.FirstName, '\n",
      " 'c.LastName, SUM(ii.Quantity) as TotalItems\\\\nFROM customers c\\\\nJOIN '\n",
      " 'invoices i ON c.CustomerId = i.CustomerId\\\\nJOIN invoice_items ii ON '\n",
      " 'i.InvoiceId = ii.InvoiceId\\\\nGROUP BY c.CustomerId, c.FirstName, '\n",
      " 'c.LastName\\\\nORDER BY TotalItems DESC\\\\nLIMIT 1 executed with result '\n",
      " '[(\\'Lu√≠s\\', \\'Gon√ßalves\\', 38)]\", tool_call_id=\\'0\\'), '\n",
      " 'AIMessage(content=\\'[{\\\\n  \"tool\": \"ConversationalResponse\",\\\\n  '\n",
      " '\"tool_input\": {\\\\n    \"response\": \"The customer who has bought the most '\n",
      " 'items is Lu√≠s Gon√ßalves with 38 items.\"\\\\n  }\\\\n}]\\', additional_kwargs={}, '\n",
      " \"response_metadata={'finish_reason': 'stop', 'usage': {'acceptance_rate': \"\n",
      " \"12.75, 'completion_tokens': 46, 'completion_tokens_after_first_per_sec': \"\n",
      " \"191.55357945705555, 'completion_tokens_after_first_per_sec_first_ten': 0, \"\n",
      " \"'completion_tokens_per_sec': 65.65122414237216, 'end_time': \"\n",
      " \"1731700946.9349337, 'is_last_response': True, 'prompt_tokens': 823, \"\n",
      " \"'start_time': 1731700946.2342613, 'time_to_first_token': \"\n",
      " \"0.46575117111206055, 'total_latency': 0.7006723880767822, 'total_tokens': \"\n",
      " \"869, 'total_tokens_per_sec': 1240.2372560809001}, 'model_name': \"\n",
      " \"'Meta-Llama-3.1-405B-Instruct', 'system_fingerprint': 'fastcoe', 'created': \"\n",
      " \"1731700946}, id='c2a6a2c4-0f06-4c43-a8bc-3c1393ea6b6c')]\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The customer who has bought the most items is Lu√≠s Gon√ßalves with 38 items.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.function_call_llm('What is the name of the customer who has bought the most items, and how many items?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
