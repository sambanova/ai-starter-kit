api: "fastapi" # set either sambastudio, sambaverse or fastapi

embedding_model: 
    "type": "sambastudio" # set either sambastudio or cpu
    "batch_size": 1 #set depending of your endpoint configuration (1 if CoE embedding expert)
    "coe": True #set true if using Sambastudio embeddings in a CoE endpoint 
    "select_expert": "e5-mistral-7b-instruct" #set if using SambaStudio CoE embedding expert

llm:
    "temperature": 0.01
    "max_tokens_to_generate": 500
    "top_p": 1
    "do_sample": false
    "sambaverse_model_name": "Meta/Meta-Llama-3-8B-Instruct"
    "coe": True #set as true if using Sambastudio CoE endpoint
    "select_expert": "llama3-405b" #set if using Sambaverse or SambaStudio CoE llm expert
    #fastApi CoE expert name -> "llama3-8b"

retrieval:
    "chunk_size": 1200
    "chunk_overlap": 240
    "db_type": "faiss"
    "k_retrieved_documents": 3
    "score_treshold": 0.3

web_crawling:
    "max_scraped_websites": 20
    "excluded_links":
        - 'facebook.com'
        - 'twitter.com'
        - 'instagram.com'
        - 'linkedin.com'
        - 'telegram.me'
        - 'reddit.com'
        - 'whatsapp.com'
        - 'wa.me' 

extra_loaders:
    - "pdf"