{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Assitant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "from langchain_classic.prompts import PromptTemplate, load_prompt\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "from langchain_classic.document_loaders import AsyncHtmlLoader\n",
    "from langchain_classic.document_transformers import Html2TextTransformer\n",
    "from langchain_classic.prompts import ChatPromptTemplate\n",
    "from urllib.parse import urljoin, urlparse, urldefrag\n",
    "from langchain_classic.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from langchain_sambanova import ChatSambaNova\n",
    "\n",
    "load_dotenv(os.path.join(repo_dir, '.env'), override=True)\n",
    "\n",
    "from langchain_classic.globals import set_debug\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatSambaNova(\n",
    "    api_key=os.environ.get(\"SAMBANOVA_API_KEY\"),\n",
    "    base_url=\"https://api.sambanova.ai/v1\",\n",
    "    model=\"gpt-oss-120b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chat_prompt(path: str) -> ChatPromptTemplate:\n",
    "    \"\"\"Load chat prompt from yaml file\"\"\"\n",
    "\n",
    "    with open(path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    config.pop('_type')\n",
    "\n",
    "    template = config.pop('template')\n",
    "\n",
    "    if not template:\n",
    "        msg = \"Can't load chat prompt without template\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    messages = []\n",
    "    if isinstance(template, str):\n",
    "        messages.append(('human', template))\n",
    "\n",
    "    elif isinstance(template, list):\n",
    "        for item in template:\n",
    "            messages.append((item['role'], item['content']))\n",
    "\n",
    "    return ChatPromptTemplate(messages=messages, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only admits Google Search\n",
    "def querySerper(query: str, limit: int = 5, do_analysis: bool = True, include_site_links: bool = False):\n",
    "    \"\"\"A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\"\"\"\n",
    "    url = 'https://google.serper.dev/search'\n",
    "    payload = json.dumps({'q': query, 'num': limit})\n",
    "    headers = {'X-API-KEY': os.environ.get('SERPER_API_KEY'), 'Content-Type': 'application/json'}\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=payload).json()\n",
    "    results = response['organic']\n",
    "    links = [r['link'] for r in results]\n",
    "    if include_site_links:\n",
    "        sitelinks = []\n",
    "        for r in [r.get('sitelinks', []) for r in results]:\n",
    "            sitelinks.extend([site.get('link', None) for site in r])\n",
    "        links.extend(sitelinks)\n",
    "    links = list(filter(lambda x: x is not None, links))\n",
    "\n",
    "    if do_analysis:\n",
    "        prompt = load_chat_prompt(os.path.join(kit_dir, 'prompts/serp_analysis.yaml'))\n",
    "        formatted_prompt = prompt.format(question=query, context=json.dumps(results))\n",
    "        return llm.invoke(formatted_prompt), links\n",
    "    else:\n",
    "        return response, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AIMessage(content='Donald Trump is the current President of the United States (America)【reference:1】.', additional_kwargs={'reasoning_content': 'We need to answer using the provided contexts. The question: \"who is the president of America\". The contexts include Wikipedia snippet: \"Donald Trump is the 47th and current president since January 20, 2025.\" Also other sources mention Donald J. Trump as president. So answer: Donald Trump is the current President of the United States (America). Cite reference. Use [reference:1] for Wikipedia snippet. Also could cite [reference:2] etc. Provide concise answer.\\n\\n'}, response_metadata={'token_usage': {'acceptance_rate': None, 'completion_tokens': 128, 'completion_tokens_after_first_per_sec': 530.3008601465435, 'completion_tokens_after_first_per_sec_first_ten': 532.2428300934738, 'completion_tokens_after_first_per_sec_graph': 532.2428300934738, 'completion_tokens_per_sec': 433.99254517396616, 'end_time': 1765325895.6541054, 'is_last_response': True, 'prompt_tokens': 922, 'prompt_tokens_details': {'cached_tokens': 0}, 'start_time': 1765325895.3591695, 'time_to_first_token': 0.05544924736022949, 'total_latency': 0.294935941696167, 'total_tokens': 1050, 'total_tokens_per_sec': 3560.095097130191, 'stop_reason': 'stop', 'time_to_first_token_graph': 0.05018210411071777}, 'model_name': 'gpt-oss-120b', 'system_fingerprint': 'fastcoe', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b059f-74f9-72f0-8ab4-a98a3dd549d5-0', usage_metadata={'input_tokens': 922, 'output_tokens': 128, 'total_tokens': 1050}),\n",
       " ['https://en.wikipedia.org/wiki/President_of_the_United_States',\n",
       "  'https://www.whitehouse.gov/administration/donald-j-trump/',\n",
       "  'https://www.facebook.com/POTUS/',\n",
       "  'https://www.instagram.com/potus/?hl=en',\n",
       "  'https://trumpwhitehouse.archives.gov/people/donald-j-trump/'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "querySerper('who is the president of America', do_analysis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryOpenSerp(query: str, limit: int = 5, do_analysis: bool = True, engine='google') -> str:\n",
    "    \"\"\"A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\"\"\"\n",
    "    if engine not in ['google', 'yandex', 'baidu']:\n",
    "        raise ValueError('engine must be either google, yandex or baidu')\n",
    "    url = f'http://127.0.0.1:7000/{engine}/search'\n",
    "    params = {'lang': 'EN', 'limit': limit, 'text': query}\n",
    "\n",
    "    results = requests.get(url, params=params).json()\n",
    "\n",
    "    links = [r['url'] for r in results]\n",
    "    if do_analysis:\n",
    "        prompt = load_chat_prompt(os.path.join(kit_dir, 'prompts/serp_analysis.yaml'))\n",
    "        formatted_prompt = prompt.format(question=query, context=json.dumps(results))\n",
    "        return llm.invoke(formatted_prompt), links\n",
    "    else:\n",
    "        return results, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryOpenSerp('who is the president of America', do_analysis=True, engine='google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(text):\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    return re.sub(url_pattern, '', text)\n",
    "\n",
    "\n",
    "def querySerpapi(query: str, limit: int = 5, do_analysis: bool = True, engine='google') -> str:\n",
    "    if engine not in ['google', 'bing']:\n",
    "        raise ValueError('engine must be either google or bing')\n",
    "    params = {'q': query, 'num': limit, 'engine': engine, 'api_key': os.environ.get('SERPAPI_API_KEY')}\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    response = search.get_dict()\n",
    "\n",
    "    knowledge_graph = response.get('knowledge_graph', None)\n",
    "    results = response.get('organic_results', None)\n",
    "\n",
    "    links = []\n",
    "    links = [r['link'] for r in results]\n",
    "\n",
    "    if do_analysis:\n",
    "        prompt = load_chat_prompt(os.path.join(kit_dir, 'prompts/serp_analysis.yaml'))\n",
    "        if knowledge_graph:\n",
    "            knowledge_graph_str = json.dumps(knowledge_graph)\n",
    "            knowledge_graph = remove_links(knowledge_graph_str)\n",
    "            print(knowledge_graph)\n",
    "            formatted_prompt = prompt.format(question=query, context=json.dumps(knowledge_graph))\n",
    "        else:\n",
    "            results_str = json.dumps(results)\n",
    "            results_str = remove_links(results_str)\n",
    "            formatted_prompt = prompt.format(question=query, context=json.dumps(results))\n",
    "        return llm.invoke(formatted_prompt), links\n",
    "    else:\n",
    "        return response, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AIMessage(content='Donald\\u202fJ.\\u202fTrump is the current President of the United States\\u202f[reference:4][reference:7]', additional_kwargs={'reasoning_content': 'We need to answer based on provided contexts. Several snippets indicate as of 2025, the President is Donald J. Trump. Cite reference 4 (All About America) says \"As of 2025, the President of the United States is Donald J. Trump\". Also reference 7,8,9 indicate Trump sworn in as 47th president in Jan 2025. So answer: Donald J. Trump. Cite multiple.'}, response_metadata={'token_usage': {'acceptance_rate': None, 'completion_tokens': 122, 'completion_tokens_after_first_per_sec': 501.7938467044957, 'completion_tokens_after_first_per_sec_first_ten': 503.16893922344093, 'completion_tokens_after_first_per_sec_graph': 503.16893922344093, 'completion_tokens_per_sec': 233.37002577214975, 'end_time': 1765325952.3212404, 'is_last_response': True, 'prompt_tokens': 4218, 'prompt_tokens_details': {'cached_tokens': 0}, 'start_time': 1765325951.7984655, 'time_to_first_token': 0.28164005279541016, 'total_latency': 0.5227749347686768, 'total_tokens': 4340, 'total_tokens_per_sec': 8301.851736484672, 'stop_reason': 'stop', 'time_to_first_token_graph': 0.2689692974090576}, 'model_name': 'gpt-oss-120b', 'system_fingerprint': 'fastcoe', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b05a0-4947-7102-88a9-e1f121735838-0', usage_metadata={'input_tokens': 4218, 'output_tokens': 122, 'total_tokens': 4340}),\n",
      " ['https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States',\n",
      "  'https://www.britannica.com/topic/Presidents-of-the-United-States-1846696',\n",
      "  'https://www.whitehouse.gov/administration/donald-j-trump/',\n",
      "  'https://allaboutamerica.com/united-states/who-is-the-president-of-the-usa.html',\n",
      "  'https://www.usa.gov/presidents',\n",
      "  'https://planetrulers.com/united-states-america-president/',\n",
      "  'https://www.pbs.org/newshour/politics/donald-trump-sworn-in-as-47th-president-of-the-united-states',\n",
      "  'https://www.usatoday.com/story/news/politics/elections/2025/01/20/donald-trump-sworn-in-as-47-president-inauguration/77755765007/',\n",
      "  'https://www.firstpost.com/world/united-states/donald-trump-becomes-president-of-the-united-states-for-a-historic-second-term-13854671.html',\n",
      "  'https://bidenwhitehouse.archives.gov/about-the-white-house/presidents/'])\n"
     ]
    }
   ],
   "source": [
    "pprint(querySerpapi('Who is the president of USA', engine='bing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\": \"Donald Trump\", \"type\": \"45th and 47th U.S. President\", \"kgmid\": \"/m/0cqt90\", \"knowledge_graph_search_link\": \" \"serpapi_knowledge_graph_search_link\": \" \"header_images\": [{\"image\": \" \"source\": \" {\"image\": \" \"source\": \" {\"image\": \" \"source\": \" \"description\": \"Donald John Trump is an American politician, media personality, and businessman who is the 47th president of the United States. A member of the Republican Party, he served as the 45th president from 2017 to 2021.\", \"source\": {\"name\": \"\\u00a0Wikipedia\", \"link\": \" \"previous_campaigns\": \"2024 United States presidential election, United States Presidential election, 2020\", \"previous_campaigns_links\": [{\"text\": \"2024 United States presidential election\", \"link\": \" {\"text\": \"United States Presidential election, 2020\", \"link\": \" \"children\": \"Barron Trump, Ivanka Trump, Tiffany Trump, Donald Trump Jr., Eric Trump\", \"children_links\": [{\"text\": \"Barron Trump\", \"link\": \" {\"text\": \"Ivanka Trump\", \"link\": \" {\"text\": \"Tiffany Trump\", \"link\": \" {\"text\": \"Donald Trump Jr.\", \"link\": \" {\"text\": \"Eric Trump\", \"link\": \" \"parents\": \"Fred Trump, Mary Anne MacLeod Trump\", \"parents_links\": [{\"text\": \"Fred Trump\", \"link\": \" {\"text\": \"Mary Anne MacLeod Trump\", \"link\": \" \"siblings\": \"Robert Trump, Elizabeth Trump Grau, Maryanne Trump Barry, Fred Trump, Jr.\", \"siblings_links\": [{\"text\": \"Robert Trump\", \"link\": \" {\"text\": \"Elizabeth Trump Grau\", \"link\": \" {\"text\": \"Maryanne Trump Barry\", \"link\": \" {\"text\": \"Fred Trump, Jr.\", \"link\": \" \"spouse\": \"Melania Trump (m. 2005), Marla Maples (m. 1993\\u20131999), Ivana Trump (m. 1977\\u20131990)\", \"spouse_links\": [{\"text\": \"Melania Trump\", \"link\": \" {\"text\": \"Marla Maples\", \"link\": \" {\"text\": \"Ivana Trump\", \"link\": \" \"web_results\": [{\"title\": \"Age\", \"snippet\": \"79 years Jun 14, 1946\", \"link\": \" {\"title\": \"Grandchildren\", \"snippet\": \"Kai Trump, Donald Trump III\", \"items\": [{\"title\": \"Kai Trump\", \"thumbnail\": \" \"link\": \" \"extensions\": [\"via Donald Trump Jr.\"]}, {\"title\": \"Donald Trump III\", \"thumbnail\": \" \"link\": \" \"extensions\": [\"via Donald Trump Jr.\"]}]}]}\n",
      "(AIMessage(content='Donald\\u202fTrump is the current president of the United States, serving as the 47th president\\u202f[reference:1]', additional_kwargs={'reasoning_content': 'We need answer based on provided context. The context contains info about Donald Trump being the 47th president. It says \"Donald John Trump is an American politician... who is the 47th president of the United States. A member of the Republican Party, he served as the 45th president from 2017 to 2021.\" So current president according to this context is Donald Trump as 47th president. So answer: Donald Trump. Cite reference. There\\'s only one context reference? It\\'s given as <context> but no explicit reference number. The instruction says each context starts reference number with [reference:n]. But here context doesn\\'t have explicit reference number. Might be reference:0? Usually they give reference numbers like [reference:1]. Since none, maybe treat as reference:0? But guidelines: cite the contexts using reference number. If none, maybe we cannot cite. But we need to cite if applicable. Could say answer not found? But the context clearly says Donald Trump is the 47th president. So answer: Donald Trump. Cite maybe [reference:0] or just omit? Probably we should use [reference:0] as placeholder. However there is no reference number, but we can treat as [reference:1]? The context starts with <context>. No reference tag. Might be considered reference:1 implicitly. I\\'ll use [reference:1].'}, response_metadata={'token_usage': {'acceptance_rate': None, 'completion_tokens': 313, 'completion_tokens_after_first_per_sec': 534.3212951859251, 'completion_tokens_after_first_per_sec_first_ten': 568.4558340203973, 'completion_tokens_after_first_per_sec_graph': 568.4558340203973, 'completion_tokens_per_sec': 482.54887158626315, 'end_time': 1765325957.6164362, 'is_last_response': True, 'prompt_tokens': 969, 'prompt_tokens_details': {'cached_tokens': 0}, 'start_time': 1765325956.9677973, 'time_to_first_token': 0.06472063064575195, 'total_latency': 0.6486389636993408, 'total_tokens': 1282, 'total_tokens_per_sec': 1976.446176912426, 'stop_reason': 'stop', 'time_to_first_token_graph': 0.05968594551086426}, 'model_name': 'gpt-oss-120b', 'system_fingerprint': 'fastcoe', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b05a0-5f68-7e12-ad1d-f5123c530f03-0', usage_metadata={'input_tokens': 969, 'output_tokens': 313, 'total_tokens': 1282}),\n",
      " ['https://en.wikipedia.org/wiki/President_of_the_United_States',\n",
      "  'https://www.whitehouse.gov/',\n",
      "  'https://www.facebook.com/POTUS/',\n",
      "  'https://trumpwhitehouse.archives.gov/people/donald-j-trump/'])\n"
     ]
    }
   ],
   "source": [
    "pprint(querySerpapi('Who is the president of USA', engine='google'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scrapping methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = os.path.join(kit_dir, 'config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_info():\n",
    "    \"\"\"\n",
    "    Loads json config file\n",
    "    \"\"\"\n",
    "    # Read config file\n",
    "    with open(CONFIG_PATH, 'r') as yaml_file:\n",
    "        config = yaml.safe_load(yaml_file)\n",
    "    llm_info = config['llm']\n",
    "    retrieval_info = config['retrieval']\n",
    "    web_crawling_params = config['web_crawling']\n",
    "    extra_loaders = config['extra_loaders']\n",
    "\n",
    "    return llm_info, retrieval_info, web_crawling_params, extra_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_remote_pdf(url):\n",
    "    \"\"\"\n",
    "    Load PDF files from the given URL.\n",
    "    Args:\n",
    "        url (str): URL to load pdf document from.\n",
    "    Returns:\n",
    "        list: A list of loaded pdf documents.\n",
    "    \"\"\"\n",
    "    loader = UnstructuredURLLoader(urls=[url])\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_htmls(urls, extra_loaders=None):\n",
    "    \"\"\"\n",
    "    Load HTML documents from the given URLs.\n",
    "    Args:\n",
    "        urls (list): A list of URLs to load HTML documents from.\n",
    "    Returns:\n",
    "        list: A list of loaded HTML documents.\n",
    "    \"\"\"\n",
    "    if extra_loaders is None:\n",
    "        extra_loaders = []\n",
    "    docs = []\n",
    "    for url in urls:\n",
    "        if url.endswith('.pdf'):\n",
    "            if 'pdf' in extra_loaders:\n",
    "                docs.extend(load_remote_pdf(url))\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            loader = AsyncHtmlLoader(url, verify_ssl=False)\n",
    "            docs.extend(loader.load())\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_filter(all_links, excluded_links):\n",
    "    \"\"\"\n",
    "    Filters a list of links based on a list of excluded links.\n",
    "    Args:\n",
    "        all_links (List[str]): A list of links to filter.\n",
    "        excluded_links (List[str]): A list of excluded links.\n",
    "    Returns:\n",
    "        Set[str]: A list of filtered links.\n",
    "    \"\"\"\n",
    "    clean_excluded_links = set()\n",
    "    for excluded_link in excluded_links:\n",
    "        parsed_link = urlparse(excluded_link)\n",
    "        clean_excluded_links.add(parsed_link.netloc + parsed_link.path)\n",
    "    filtered_links = set()\n",
    "    for link in all_links:\n",
    "        # Check if the link contains any of the excluded links\n",
    "        if not any(excluded_link in link for excluded_link in clean_excluded_links):\n",
    "            filtered_links.add(link)\n",
    "    return filtered_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_docs(docs):\n",
    "    \"\"\"\n",
    "    Clean the given HTML documents by transforming them into plain text.\n",
    "    Args:\n",
    "        docs (list): A list of langchain documents with html content to clean.\n",
    "    Returns:\n",
    "        list: A list of cleaned plain text documents.\n",
    "    \"\"\"\n",
    "    html2text_transformer = Html2TextTransformer()\n",
    "    docs = html2text_transformer.transform_documents(documents=docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_crawl(urls, excluded_links=None):\n",
    "    \"\"\"\n",
    "    Perform web crawling, retrieve and clean HTML documents from the given URLs, with specified depth of exploration.\n",
    "    Args:\n",
    "        urls (list): A list of URLs to crawl.\n",
    "        excluded_links (list, optional): A list of links to exclude from crawling. Defaults to None.\n",
    "        depth (int, optional): The depth of crawling, determining how many layers of internal links to explore. Defaults to 1\n",
    "    Returns:\n",
    "        tuple: A tuple containing the langchain documents (list) and the scrapped URLs (list).\n",
    "    \"\"\"\n",
    "    *_, web_crawling_params, extra_loaders = get_config_info()\n",
    "    if excluded_links is None:\n",
    "        excluded_links = []\n",
    "    excluded_links.extend(\n",
    "        [\n",
    "            'facebook.com',\n",
    "            'twitter.com',\n",
    "            'instagram.com',\n",
    "            'linkedin.com',\n",
    "            'telagram.me',\n",
    "            'reddit.com',\n",
    "            'whatsapp.com',\n",
    "            'wa.me',\n",
    "        ]\n",
    "    )\n",
    "    excluded_link_suffixes = {'.ico', '.svg', '.jpg', '.png', '.jpeg', '.', '.docx', '.xls', '.xlsx'}\n",
    "    scrapped_urls = []\n",
    "\n",
    "    urls = [url for url in urls if not url.endswith(tuple(excluded_link_suffixes))]\n",
    "    urls = link_filter(urls, set(excluded_links))\n",
    "    urls = list(urls)[: web_crawling_params['max_scraped_websites']]\n",
    "\n",
    "    scraped_docs = load_htmls(urls, extra_loaders)\n",
    "    scrapped_urls.append(urls)\n",
    "\n",
    "    docs = clean_docs(scraped_docs)\n",
    "    return docs, scrapped_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  1.38it/s]\n",
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  1.73it/s]\n",
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "_, links = querySerpapi('Who is the president of USA', engine='google', do_analysis=False)\n",
    "docs, links = web_crawl(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieval and vdb creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 19:22:03,587 [INFO] - Splitter: splitting documents\n",
      "2025-12-09 19:22:03,590 [INFO] - Total 184 chunks created\n",
      "2025-12-09 19:22:03,601 [INFO] - This is the collection name: collection_909d57c4-0e60-4c1d-9cb4-def11797d319\n",
      "2025-12-09 19:22:03,618 [INFO] - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-12-09 19:22:05,718 [INFO] - HTTP Request: POST https://api.sambanova.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-09 19:22:08,909 [INFO] - HTTP Request: POST https://api.sambanova.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-09 19:22:14,137 [INFO] - HTTP Request: POST https://api.sambanova.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-09 19:22:17,517 [INFO] - HTTP Request: POST https://api.sambanova.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-09 19:22:21,098 [INFO] - HTTP Request: POST https://api.sambanova.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-09 19:22:23,780 [INFO] - HTTP Request: POST https://api.sambanova.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-09 19:22:25,457 [INFO] - Vector store saved to None\n"
     ]
    }
   ],
   "source": [
    "from utils.vectordb.vector_db import VectorDb\n",
    "from langchain_sambanova import SambaNovaEmbeddings\n",
    "\n",
    "vectordb = VectorDb()\n",
    "config = {'persist_directory': 'NoneDirectory'}\n",
    "documents = docs\n",
    "\n",
    "def create_and_save_local(input_directory=None, persist_directory=None, update=False):\n",
    "    *_, retrieval_info, _, _ = get_config_info()\n",
    "    persist_directory = config.get('persist_directory', 'NoneDirectory')\n",
    "\n",
    "    chunks = vectordb.get_text_chunks(documents, retrieval_info['chunk_size'], retrieval_info['chunk_overlap'])\n",
    "    encode_kwargs = {\"normalize_embeddings\": True}\n",
    "    embeddings = SambaNovaEmbeddings(\n",
    "        api_key=os.environ.get(\"SAMBANOVA_API_KEY\"),\n",
    "        base_url=\"https://api.sambanova.ai/v1\",\n",
    "        model=\"E5-Mistral-7B-Instruct\"\n",
    "    )\n",
    "    if update and os.path.exists(persist_directory):\n",
    "        config['update'] = True\n",
    "        vector_store = vectordb.update_vdb(\n",
    "            chunks, embeddings, retrieval_info['db_type'], input_directory, persist_directory\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        if os.path.exists(persist_directory):\n",
    "            vector_store = vectordb.create_vector_store(\n",
    "                chunks, embeddings, retrieval_info['db_type'], persist_directory\n",
    "            )\n",
    "        else:\n",
    "            vector_store = vectordb.create_vector_store(chunks, embeddings, retrieval_info['db_type'], None)\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "\n",
    "vector_store = create_and_save_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "\n",
    "def retrieval_qa_chain():\n",
    "    *_, retrieval_info, _, _ = get_config_info()\n",
    "    prompt = load_chat_prompt(os.path.join(kit_dir, 'prompts/web_scraped_data_retriever.yaml'))\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type='similarity_score_threshold',\n",
    "        search_kwargs={\n",
    "            'score_threshold': retrieval_info['score_treshold'],\n",
    "            'k': retrieval_info['k_retrieved_documents'],\n",
    "        },\n",
    "    )\n",
    "    qa_chain = RetrievalQA.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        verbose=True,\n",
    "        input_key='question',\n",
    "        output_key='answer',\n",
    "        prompt=prompt,\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = retrieval_qa_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 19:22:30,345 [INFO] - HTTP Request: POST https://api.sambanova.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-09 19:22:32,002 [INFO] - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'who is joe biden',\n",
       " 'answer': 'Joe\\u202fBiden is listed as one of the Presidents of the United States【reference:1】.',\n",
       " 'source_documents': [Document(id='b17c3106-b1d5-482b-9033-494d3a30d9e7', metadata={'title': 'President of the United States - Wikipedia', 'language': 'en', 'source': 'https://en.wikipedia.org/wiki/President_of_the_United_States'}, page_content='* House elections\\n  * Senate elections\\n  * Gubernatorial elections\\n\\n  \\n  \\n  * v\\n  * t\\n  * e\\n\\nMemorials to, and namesakes of, presidents of the United States  \\n---  \\nBy president|\\n\\n  * Washington\\n  * J. Adams\\n  * Jefferson\\n  * Madison\\n  * Monroe\\n  * J. Q. Adams\\n  * Jackson\\n  * Van Buren\\n  * W. H. Harrison\\n  * Tyler\\n  * Polk\\n  * Taylor\\n  * Fillmore\\n  * Pierce\\n  * Buchanan\\n  * Lincoln\\n  * Grant\\n  * Hayes\\n  * Garfield\\n  * Arthur\\n  * Cleveland\\n  * B. Harrison\\n  * McKinley\\n  * T. Roosevelt\\n  * Wilson\\n  * Harding\\n  * Coolidge\\n  * Hoover\\n  * F. D. Roosevelt\\n  * Truman\\n  * Eisenhower\\n  * Kennedy\\n  * L. B. Johnson\\n  * Nixon\\n  * Ford\\n  * Carter\\n  * Reagan\\n  * G. H. W. Bush\\n  * Clinton\\n  * G. W. Bush\\n  * Obama\\n  * Trump\\n  * Biden\\n\\n  \\nBy topic|\\n\\n  * Counties\\n  * Currency\\n  * Educational institutions\\n  * Military vessels\\n  * Outside the United States\\n  * Postage stamps\\n  * Presidential library system\\n  * Residences\\n  * Sculptures\\n\\n  \\n  \\n  * v\\n  * t\\n  * e\\n\\nUnited States Armed Forces  \\n---  \\n  \\nLegend\\n\\n    A = Army\\n    MC = Marine Corps\\n    N = Navy\\n    AF = Air Force\\n    SF = Space Force\\n    CG = Coast Guard  \\nLeadership|'),\n",
       "  Document(id='689d0206-7306-44a8-bf5c-d2e00c8400ff', metadata={'source': 'https://www.whitehouse.gov/', 'language': 'en-US', 'description': 'President Donald J. Trump and Vice President JD Vance are committed to lowering costs for all Americans, securing our borders, unleashing American energy dominance, restoring peace through strength, and making all Americans safe and secure once again.', 'title': 'The White House'}, page_content=\"Menu\\n\\nPresident Donald J. Trump\\n\\nThe White House\\n\\nSearch\\n\\n  * News\\n    * Articles\\n    * Briefings & Statements\\n    * Fact Sheets\\n    * Presidential Actions\\n      * Executive Orders\\n      * Nominations & Appointments\\n      * Presidential Memoranda\\n      * Proclamations\\n    * Remarks\\n  * Administration\\n    * Donald J. Trump\\n    * JD Vance\\n    * Melania Trump\\n    * Usha Vance\\n    * The Cabinet\\n  * Media\\n    * Gallery\\n    * Live News\\n    * Video Library\\n    * Media Offenders\\n    * White House Wire\\n  * Priorities\\n    * Issues\\n    * Investments\\n    * DOGE Savings\\n    * Wins and Achievements\\n  * History\\n    * America 250\\n    * The Founders Museum\\n    * America's Founding Fathers\\n    * Moments That Made Us\\n      * Road to Liberty\\n      * The Story of America\\n      * Signers of the Declaration of Independence\\n      * Road to Liberty: A Timeline\\n    * Our Government\\n    * About The White House\\n      * Major Events Timeline\\n      * Christmas at The White House\\n  * Get in Touch\\n    * Contact\\n    * Visit\\n    * Internships\\n\\n  * X\\n  * Instagram\\n  * Facebook\\n  * YouTube\\n\\nSearch for: Press Enter to Search\\n\\n## America is Back\"),\n",
       "  Document(id='c5363c07-d52d-430c-a60b-d28766a4bac6', metadata={'source': 'https://en.wikipedia.org/wiki/President_of_the_United_States', 'language': 'en', 'title': 'President of the United States - Wikipedia'}, page_content='Presidency  \\ntimelines|\\n\\n  * Washington\\n  * J. Adams\\n  * McKinley\\n  * T. Roosevelt\\n  * Taft\\n  * Wilson\\n  * Harding\\n  * Coolidge\\n  * Hoover\\n  * F. D. Roosevelt\\n  * Truman\\n  * Eisenhower\\n  * Kennedy\\n  * L. B. Johnson\\n  * Nixon\\n  * Ford\\n  * Carter\\n  * Reagan\\n  * G. H. W. Bush\\n  * Clinton\\n  * G. W. Bush\\n  * Obama\\n  * Trump\\n  * Biden\\n\\n  \\n  \\n  * Category\\n  * List\\n\\n  \\n  \\nLinks to related articles  \\n---  \\n|\\n\\n  * v\\n  * t\\n  * e\\n\\nLists related to presidents and vice presidents of the United States  \\n---  \\n  \\n  * List of presidents\\n  * List of vice presidents\\n\\n  \\nPresidents| | Professional  \\ncareer|\\n\\n  * Approval rating\\n  * Assassination attempts and plots\\n  * Control of Congress\\n  * Desks\\n  * Did not seek reelection\\n  * Doctrines\\n  * Executive orders\\n  * Historical rankings\\n  * Impeachment efforts\\n  * International trips\\n  * Judicial appointments\\n  * Lost reelection\\n  * Military service\\n    * rank\\n  * Official vehicles\\n  * Other offices held\\n  * Pardons\\n  * Post-presidency campaigns\\n  * Previous experience\\n  * Time in office\\n  * Vetoes\\n  * Concurrent Canadian prime ministers\\n\\n  \\n---|---  \\nPersonal life|')]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('who is joe biden')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
