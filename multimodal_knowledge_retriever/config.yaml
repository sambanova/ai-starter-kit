llm: 
    "type": "sncloud" # set either sncloud or sambastudio
    "temperature": 0.0
    "do_sample": False
    "max_tokens_to_generate": 1200
    "bundle": True #set as true if using Sambastudio bundle endpoint
    "select_expert": "Meta-Llama-3.3-70B-Instruct"  #set if using SambaNovaCloud or SambaStudio bundle llm expert

lvlm:
    "model": "Llama-4-Maverick-17B-128E-Instruct"
    "do_sample": false
    "max_tokens_to_generate": 512 
    "temperature": 1
    "top_k": 50
    "top_p": 1

embedding_model: 
    "type": "sncloud" # set either sncloud, sambastudio or cpu
    "model": "E5-Mistral-7B-Instruct" #set if using Cloud or SambaStudio bundle embedding expert

retrieval:
    "max_characters": 800
    "new_after_n_chars": 500
    "combine_text_under_n_chars": 300
    "k_retrieved_documents": 4

prod_mode: False
