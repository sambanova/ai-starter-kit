api: "sambaverse" # set either sambastudio or sambaverse

embedding_model: 
    "type": "sambastudio" # set either sambastudio or cpu
    "batch_size": 1 #set depending of your endpoint configuration (1 if CoE embedding expert)
    "coe": True #set true if using Sambastudio embeddings in a CoE endpoint 
    "select_expert": "e5-mistral-7b-instruct" #set if using SambaStudio CoE embedding expert

llm: 
    "temperature": 0.1
    "max_tokens_to_generate": 500
    "sambaverse_model_name": "Meta/llama-2-70b-chat-hf"
    "coe": True #set as true if using Sambastudio CoE endpoint
    "select_expert": "llama-2-70b-chat-hf" #set if using Sambaverse or SambaStudio CoE llm expert

retrieval:
    "chunk_size": 1200
    "chunk_overlap": 240
    "db_type": "faiss"
    "k_retrieved_documents": 4
    "score_treshold": 0.5

web_crawling:
    "max_depth": 2
    "max_scraped_websites": 20
    "excluded_links":
        - 'facebook.com'
        - 'twitter.com'
        - 'instagram.com'
        - 'linkedin.com'
        - 'telegram.me'
        - 'reddit.com'
        - 'whatsapp.com'
        - 'wa.me' 

extra_loaders:
    - "pdf"