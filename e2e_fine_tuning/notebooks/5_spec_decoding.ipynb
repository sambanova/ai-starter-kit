{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speculative Decoding Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir =  os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from utils.fine_tuning.src.snsdk_wrapper import SnsdkWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by Step / Manual setting\n",
    "\n",
    "First instantiate the SambaStudio client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 09:13:24,299 [INFO] Using variables from .snapi config to set up Snsdk.\n"
     ]
    }
   ],
   "source": [
    "sambastudio_client = SnsdkWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Speculative Decoding Model Using Target and Draft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 09:13:25,447 [INFO] Model with name 'Meta-Llama-3.3-70B-Instruct' found with id 9d8a3abd-9635-4adc-9067-1403b8adcdb2\n",
      "2025-04-01 09:13:25,679 [INFO] Model with name 'Meta-Llama-3-8B-Instruct' found with id b16efa3a-90a9-4708-b963-ffd5306780e5\n",
      "2025-04-01 09:13:30,951 [INFO] Speculative decoding validation: 'Provided target model: Meta-Llama-3.3-70B-Instruct and draft model: Meta-Llama-3-8B-Instruct are compatible\n",
      "'\n",
      "2025-04-01 09:13:38,997 [INFO] Speculative decoding creation message: 'Successfully created Composite Model Meta-Llama-3.3-70B-Instruct-SD.\n",
      "'\n",
      "2025-04-01 09:13:39,215 [INFO] Model with name 'Meta-Llama-3.3-70B-Instruct-SD' found with id e695a4e7-c232-4522-b64e-5c1a9914cec1\n"
     ]
    }
   ],
   "source": [
    "model_id = sambastudio_client.create_spec_decoding_model(\n",
    "    model_name=\"Meta-Llama-3.3-70B-Instruct-SD\",\n",
    "    target_model=\"Meta-Llama-3.3-70B-Instruct\", target_model_version=\"1\",\n",
    "    draft_model=\"Meta-Llama-3-8B-Instruct\", draft_model_version=\"1\",\n",
    "    rdu_arch=\"SN40L-8\", job_type=\"deploy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlined Execution\n",
    "\n",
    "The speculative decoding model creation can be done in a streamlined way setting all the parameters in a config file like in the [spec_decoding_config.yaml](../spec_decoding_config.yaml) example, and executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.path.join(kit_dir, 'spec_decoding_config.yaml')\n",
    "sambastudio_client = SnsdkWrapper(config_file)\n",
    "sambastudio_client.create_spec_decoding_model()\n",
    "sambastudio_client.search_model(\"Meta-Llama-3.3-70B-Instruct-SD\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byoc_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
