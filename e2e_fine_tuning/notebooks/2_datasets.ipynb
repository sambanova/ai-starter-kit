{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datasets import load_dataset\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir =  os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from utils.fine_tuning.src import sambastudio_utils\n",
    "from utils.fine_tuning.src.snsdk_wrapper import SnsdkWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by Step / Manual setting\n",
    "\n",
    "First instantiate the SambaStudio client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 10:16:32,411 [INFO] Using variables from Snapi config to set up Snsdk.\n"
     ]
    }
   ],
   "source": [
    "sambastudio_client = SnsdkWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download datasets from HuggingFace (Optional)\n",
    "You can use your own dataset (see [synthetic data generation util](../synthetic_data_gen/notebooks/quickstart_synthetic_data_gen.ipynb)) or alternatively you can download and use an existing dataset like the ones in [Huggingface datasets](https://huggingface.co/datasets?modality=modality:text&sort=trending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset='xhluca/publichealth-qa'\n",
    "data_dir = \"data\"\n",
    "target_dir = os.path.join(kit_dir, \"data\",\"datasets\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 647 examples [00:00, 8264.90 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'url', 'source', 'section'],\n",
       "    num_rows: 647\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create target dir if not exist\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "# Load dataset     \n",
    "dataset = load_dataset(hf_dataset, data_dir=data_dir, data_files = ['english.csv','spanish.csv', 'french.csv', 'russian.csv', 'chinese.csv'] ,split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 103.23ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1041854"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save dataset in jsonl file with  appropriate column names\n",
    "dataset=dataset.rename_columns({'question': 'prompt', 'answer': 'completion'}).select_columns(['prompt', 'completion'])\n",
    "dataset.to_json(os.path.join(target_dir,f'{hf_dataset.split(\"/\")[-1]}.jsonl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset\n",
    "\n",
    "To upload a dataset to SambaStudio we need first to convert it to a suitable format (hdf5), for this we will use the generative data prep utility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_dataset_path = sambastudio_utils.gen_data_prep_pipeline(\n",
    "    input_files = os.path.join(target_dir, \"publichealth-qa.jsonl\"),\n",
    "    output_path = os.path.join(target_dir, \"fine_tuning-publichealth-qa\"),\n",
    "    tokenizer = \"lightblue/suzume-llama-3-8B-multilingual\", # use the tokenizer of the model to train with\n",
    "    max_seq_length = 8192,\n",
    "    shuffle = 'on_RAM',\n",
    "    input_packing_config = 'single::truncate_right', \n",
    "    prompt_keyword = 'prompt',\n",
    "    completion_keyword = 'completion',\n",
    "    num_training_splits = 8,\n",
    "    apply_chat_template = False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find more details about the gen data prep parameters [here](https://github.com/sambanova/generative_data_prep?tab=readme-ov-file#flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataset configs\n",
    "\n",
    "Some parameter should be provided to upload a previously created checkpoint, for this we will keep these parameters in a dataset dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'dataset_path': hdf5_dataset_path,\n",
    "    'dataset_name': \"publichealth\",\n",
    "    'dataset_description': 'This dataset contains question and answer pairs sourced from Q&A pages and FAQs from CDC and WHO pertaining to COVID-19',\n",
    "    'dataset_job_types': [\"evaluation\", \"train\"],\n",
    "    'dataset_source_type': 'localMachine',\n",
    "    'dataset_language': 'english',\n",
    "    'dataset_filetype': 'hdf5',\n",
    "    'dataset_url': \"https://huggingface.co/datasets/xhluca/publichealth-qa\",\n",
    "    'dataset_metadata':{}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should indicate for which apps the uploaded dataset will be available, if not sure you can list all the aps in SambaStudio ans select those you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '89fbfbe6-ee77-4f5c-9ff6-56e2ab69f6ee', 'name': 'Text Embedding'},\n",
       " {'id': 'a0547cc1-bf29-4774-abd0-5f1b2ac87eb2', 'name': 'Symphony CoE App'},\n",
       " {'id': 'ecf84906-0924-4ce1-a1a2-c008f5334820', 'name': 'Speech Recognition'},\n",
       " {'id': 'e580a1b7-0f23-4644-8959-98eba2dae86e', 'name': 'Spec Decoding'},\n",
       " {'id': 'cbba6d31-104a-4295-ac21-7e91da09ab9b', 'name': 'Speaker Diarization'},\n",
       " {'id': '44b2a732-c15a-441b-84f2-6efeea287d91',\n",
       "  'name': 'Simple Text Classifier Generative'},\n",
       " {'id': '3aaf5b6b-6d17-45ce-bb1e-543bed912f7b',\n",
       "  'name': 'Simple Text Classifier'},\n",
       " {'id': 'f67c5390-da52-4105-ae17-12434fa7d03b', 'name': 'Sentence Detection'},\n",
       " {'id': 'c3178605-2f2a-409d-9dbd-e4efebd2ade5',\n",
       "  'name': 'Samba 1 Turbo Spec Decoding'},\n",
       " {'id': '6c24ed43-f150-4fa6-a76c-38ff5e1372bc', 'name': 'Samba 1 Turbo App'},\n",
       " {'id': '99f31849-8911-4118-bd2c-587ac843e85c',\n",
       "  'name': 'Samba1 Solar Experts'},\n",
       " {'id': 'd2afdaf6-bbf0-484f-abb1-3e93db210246',\n",
       "  'name': 'Samba1 Qwen2 Experts'},\n",
       " {'id': '34c9f9ae-4b60-472f-914b-ca33705cd819',\n",
       "  'name': 'Samba1 Mistral Routers'},\n",
       " {'id': 'da89eace-e9f2-4174-8b65-a036804d275c',\n",
       "  'name': 'Samba1 Mistral Experts'},\n",
       " {'id': '61fa0993-04a2-42ca-9db1-1eff693ea978',\n",
       "  'name': 'Samba1 Llama3 Experts'},\n",
       " {'id': '49683c7f-3e42-4217-96dd-6f975d17c393',\n",
       "  'name': 'Samba1 Llama3.2 Experts'},\n",
       " {'id': 'eb0aaad1-694f-41b6-958a-b974737635c4',\n",
       "  'name': 'Samba1 Llama3.1 Experts'},\n",
       " {'id': 'fefdb08e-28c6-49c7-87cf-ead1bb0603fa',\n",
       "  'name': 'Samba1 Llama2 Experts'},\n",
       " {'id': '6af83648-a054-4680-964d-3fcda56feffd',\n",
       "  'name': 'Samba1 Gemma Experts'},\n",
       " {'id': 'c911704f-92a0-4faa-84de-2d3f6db284db',\n",
       "  'name': 'Samba1 Falcon Experts'},\n",
       " {'id': '2764e168-46ac-4478-b81c-6e1823d52f61',\n",
       "  'name': 'Samba1 Embedding Experts'},\n",
       " {'id': 'fa2ca67a-446e-4a68-8536-5615a2f77f03', 'name': 'Samba1 EEVE Experts'},\n",
       " {'id': '825cf1f8-849b-4c62-80d7-a2ed487a834a',\n",
       "  'name': 'Samba1 Bloom Experts'},\n",
       " {'id': 'f25c8247-f73a-4dd9-9871-d5c10675239c', 'name': 'Reranking'},\n",
       " {'id': 'c27a105f-d0be-4bef-b2a4-4d6bf747ebdc',\n",
       "  'name': 'Named Entity Recognition'},\n",
       " {'id': '8bb4e0be-53ca-4923-86c1-d93fc7b1888e',\n",
       "  'name': 'Molle 20experts tp8 inference'},\n",
       " {'id': '4e5abe67-4380-4d5a-adc3-d4e60045e783',\n",
       "  'name': 'Molle 150experts tp8 inference'},\n",
       " {'id': 'ab46c162-ff57-4700-beae-3ded6065ee7a', 'name': 'Mistral'},\n",
       " {'id': 'f7b8323f-764a-48fc-916f-bf87d08de0c2', 'name': 'Llava v1.5'},\n",
       " {'id': '19eb25e5-3ef7-4f9d-8d28-173ef4619623', 'name': 'Llava 7b'},\n",
       " {'id': 'ad39e323-9878-4914-8e29-82c9f2939475', 'name': 'Llama 3'},\n",
       " {'id': '2a633d60-ed93-47e8-b2d4-3a5aa345e320',\n",
       "  'name': 'Llama 2 with dynamic batching'},\n",
       " {'id': '4176768d-d4dc-4204-ac3b-d1154b6e8fb1',\n",
       "  'name': 'Llama 2 7B single socket'},\n",
       " {'id': '21d706a3-d9fb-4998-aa9b-ad9ff2c3a920', 'name': 'Llama 2 7B 8-socket'},\n",
       " {'id': 'ec012370-6ffa-4a3a-b230-2c62613f1d89', 'name': 'Llama 2 7B'},\n",
       " {'id': '0b5871de-f335-43c6-a718-1300c1ef02b8',\n",
       "  'name': 'Llama 2 70B with dynamic batching'},\n",
       " {'id': '82254d3b-7239-458b-9da8-da1aca9b7fba', 'name': 'Llama 2 70B'},\n",
       " {'id': '858ef69e-1aad-42c5-a6ea-eaf72153c086',\n",
       "  'name': 'Llama 2 13b 8-socket'},\n",
       " {'id': '1bf617cb-8afb-4bbd-b92f-c15ebfdca10b', 'name': 'Llama 2 13B'},\n",
       " {'id': 'e681c226-86be-40b2-9380-d2de11b19842',\n",
       "  'name': 'Generative Tuning 1.5B'},\n",
       " {'id': '57f6a3c8-1f04-488a-bb39-3cfc5b4a5d7a',\n",
       "  'name': 'Generative Tuning 13B'},\n",
       " {'id': 'a56e0c49-49ea-41a9-ba5a-7b0ed83ec1de', 'name': 'Falcon 40B'},\n",
       " {'id': '3bcf5b6b-6d17-45ce-bb1e-543bed912f7b',\n",
       "  'name': 'Fake Box for Testing'},\n",
       " {'id': '0519e6f3-d8d8-4975-9486-fd83eb2d2970',\n",
       "  'name': 'E5 Mistral Embedding'},\n",
       " {'id': '0498c73a-5c03-456a-a645-3820728cfcae',\n",
       "  'name': 'Dialog Act Classification'},\n",
       " {'id': '40f16b58-72a9-404f-a7c3-afc0d27a2343', 'name': 'DePlot'},\n",
       " {'id': '8c8525f6-2cbf-4e7f-b751-0afce9631445', 'name': 'DeepSeek Coder'},\n",
       " {'id': '2eeb4b7f-bc56-48c4-8814-ef9d1e8806b8',\n",
       "  'name': 'Deepseek 6.7B single socket'},\n",
       " {'id': '199e9684-785c-4df0-8dc3-49e808d8eba5', 'name': 'Databox'},\n",
       " {'id': '6c14325a-1be7-4e48-b38f-19b33745fc3b', 'name': 'CLIP'},\n",
       " {'id': 'a36cc322-dd36-40e3-9641-d87ac48fe2c4',\n",
       "  'name': 'ASR Without Diarization'},\n",
       " {'id': 'b6aefdf7-02a4-4384-9c3c-8a81d735a54e',\n",
       "  'name': 'ASR With Diarization'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avaliable_apps = sambastudio_client.list_apps()\n",
    "avaliable_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case we will train a llama3 model so wi will include all the llama3 apps\n",
    "llama3_apps=[app['name'] for app in avaliable_apps if 'llama3' in app['name'].replace(' ','').lower()]\n",
    "dataset['dataset_apps_availability']=llama3_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_path': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit-snova/e2e_fine_tuning/data/datasets/fine_tuning-publichealth-qa',\n",
       " 'dataset_name': 'publichealth',\n",
       " 'dataset_description': 'This dataset contains question and answer pairs sourced from Q&A pages and FAQs from CDC and WHO pertaining to COVID-19',\n",
       " 'dataset_job_types': ['evaluation', 'train'],\n",
       " 'dataset_source_type': 'localMachine',\n",
       " 'dataset_language': 'english',\n",
       " 'dataset_filetype': 'hdf5',\n",
       " 'dataset_url': 'https://huggingface.co/datasets/xhluca/publichealth-qa',\n",
       " 'dataset_metadata': {},\n",
       " 'dataset_apps_availability': ['Samba1 Llama3 Experts',\n",
       "  'Samba1 Llama3.2 Experts',\n",
       "  'Samba1 Llama3.1 Experts',\n",
       "  'Llama 3']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see here all the parameters required to upload the dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Dataset to SambaStudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 10:16:36,555 [INFO] App with name 'Samba1 Llama3 Experts' found with id 61fa0993-04a2-42ca-9db1-1eff693ea978\n",
      "2024-11-25 10:16:36,751 [INFO] App with name 'Samba1 Llama3.2 Experts' found with id 49683c7f-3e42-4217-96dd-6f975d17c393\n",
      "2024-11-25 10:16:36,964 [INFO] App with name 'Samba1 Llama3.1 Experts' found with id eb0aaad1-694f-41b6-958a-b974737635c4\n",
      "2024-11-25 10:16:37,160 [INFO] App with name 'Llama 3' found with id ad39e323-9878-4914-8e29-82c9f2939475\n",
      "2024-11-25 10:16:37,446 [INFO] Dataset with name 'publichealth' not found\n",
      "2024-11-25 10:17:38,095 [INFO] Dataset with name 'publichealth' found with id 6ac585ad-107c-45f5-a2de-129dd1a69279\n",
      "2024-11-25 10:17:38,096 [INFO] Dataset with name 'publichealth' created: 'Uploading files\n",
      "Completed Folder upload: /Users/jorgep/Documents/ask_public_own/ai-starter-kit-snova/e2e_fine_tuning/data/datasets/fine_tuning-publichealth-qa\n",
      "Dataset added successfully.\n",
      "Time taken to upload the dataset: 58.665268898010254 seconds\n",
      "'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6ac585ad-107c-45f5-a2de-129dd1a69279'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the create dataset method from client with dataset parameters (this can take a while)\n",
    "sambastudio_client.create_dataset(\n",
    "    dataset_path = dataset['dataset_path'],\n",
    "    dataset_name = dataset['dataset_name'],\n",
    "    dataset_description = dataset['dataset_description'],\n",
    "    dataset_job_types = dataset['dataset_job_types'],\n",
    "    dataset_source_type = dataset['dataset_source_type'],\n",
    "    dataset_language = dataset['dataset_language'],\n",
    "    dataset_url = dataset['dataset_url'],\n",
    "    dataset_apps_availability = dataset['dataset_apps_availability'],\n",
    "    dataset_filetype = dataset['dataset_filetype'],\n",
    "    dataset_metadata = dataset['dataset_metadata']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '6ac585ad-107c-45f5-a2de-129dd1a69279', 'dataset_name': 'publichealth'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dataset is now in SambaStudio environment\n",
    "sambastudio_client.list_datasets()[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlined Execution\n",
    "\n",
    "The dataset upload can be done in a streamlined way setting all the dataset parameters in a config file like in the [dataset_config.yaml](../dataset_config.yaml) example, and executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.path.join(kit_dir, 'dataset_config.yaml')\n",
    "sambastudio_client = SnsdkWrapper(config_file)\n",
    "sambastudio_client.create_dataset()\n",
    "sambastudio_client.list_datasets()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snapienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
