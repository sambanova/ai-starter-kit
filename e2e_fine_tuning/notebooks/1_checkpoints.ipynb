{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and Upload your on checkpoint to SambaStudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorgep/Documents/ask_public_own/snapienv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from huggingface_hub import hf_hub_download, HfApi\n",
    "\n",
    "# Get absolute paths for kit_dir and repo_dir\n",
    "current_dir = os.getcwd()\n",
    "kit_dir =  os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "\n",
    "# Adding directories to the Python module search path\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from utils.byoc.src.snsdk_byoc_wrapper import BYOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by Step / Manual setting\n",
    "\n",
    "First instantiate the SambaStudio client for BYOC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 12:20:51,796 [INFO] Using variables from Snapi config to set up Snsdk.\n"
     ]
    }
   ],
   "source": [
    "byoc = BYOC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a base chekpoint from HuggingFace (Optional)\n",
    "\n",
    "You can use your own fine-tuned models or alternatively you can download and use [Huggingface model checkpoints](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending). In this case we will use an available model in HuggingFace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model = 'lightblue/suzume-llama-3-8B-multilingual'\n",
    "target_dir = os.path.join(kit_dir, 'data', 'models') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target dir if not exist\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "# Download checkpoint to target dir\n",
    "repo_files = HfApi().list_repo_files(hf_model)\n",
    "for file_name in repo_files:\n",
    "    hf_hub_download(repo_id=hf_model, filename=file_name, cache_dir=target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jorgep/Documents/ask_public_own/ai-starter-kit-snova/e2e_fine_tuning/data/models/models--lightblue--suzume-llama-3-8B-multilingual/snapshots/0cb15aa9ec685eef494f9a15f65aefcfe3c04c66'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the snapshot folder inside the target dir\n",
    "for root, dirs, files in os.walk(target_dir):\n",
    "    if \"snapshots\" in root and hf_model.replace(\"/\", \"--\") in root:\n",
    "        checkpoint_folder = os.path.join(root,dirs[0])\n",
    "        break\n",
    "\n",
    "checkpoint_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set checkpoint configs\n",
    "\n",
    "Some parameter should be provided to upload a previously created checkpoint, for this we will keep these parameters in a checkpoint dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'model_name':'Suzume-Llama-3-8B-Multilingual',\n",
    "    'publisher': \"lightblue\",\n",
    "    'description': \" Suzume 8B, a multilingual finetune of Llama 3\",\n",
    "    'param_count':8,  # number in billions of parameters\n",
    "    'checkpoint_path': checkpoint_folder\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set and check chat template (Optional) \n",
    "\n",
    "If you want to use chat templates (roles structures), you could need to include or update the existing chat template. This should be formatted as a Jinja2 String template as the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jinja_chat_template = \"\"\" \n",
    "{% for message in messages %}\n",
    "    {% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>' + '\\n' + message['content'] | trim + '<|eot_id|>'+'\\n' %}\n",
    "    {% if loop.index0 == 0 %}{% set content = bos_token + content %}\n",
    "    {% endif %}\n",
    "    {{content}}\n",
    "{% endfor %}\n",
    "{{'<|start_header_id|>assistant<|end_header_id|>'+'\\n'}}\n",
    "\"\"\"\n",
    "#delete scape characters\n",
    "jinja_chat_template = re.sub(r\"(?<!')\\n(?!')\", \"\", jinja_chat_template).strip().replace('  ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and update current tokenizer config from the checkpoint path\n",
    "with open(os.path.join(checkpoint['checkpoint_path'], 'tokenizer_config.json'), 'r+') as file:\n",
    "    data = json.load(file)\n",
    "    data['chat_template'] = jinja_chat_template\n",
    "    file.seek(0)\n",
    "    file.truncate()\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 15:17:29,527 [INFO] Raw chat template for checkpoint in /Users/jorgep/Documents/ask_public_own/ai-starter-kit-snova/e2e_fine_tuning/data/models/models--lightblue--suzume-llama-3-8B-multilingual/snapshots/0cb15aa9ec685eef494f9a15f65aefcfe3c04c66:\n",
      "{% for message in messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>' + '\n",
      "' + message['content'] | trim + '<|eot_id|>'+'\n",
      "' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{content}}{% endfor %}{{'<|start_header_id|>assistant<|end_header_id|>'+'\n",
      "'}}\n",
      "\n",
      "2024-11-25 15:17:29,532 [INFO] Rendered template with input test messages:\n",
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "This is a system prompt.<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "This is a user prompt.<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "This is a response from the assistant.<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "This is an user follow up<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Render template when using a roles / chat structure\n",
    "test_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"This is a system prompt.\"},\n",
    "    {\"role\": \"user\", \"content\": \"This is a user prompt.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"This is a response from the assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"This is an user follow up\"}\n",
    "    ]\n",
    "byoc.check_chat_templates(test_messages, checkpoint_paths=checkpoint['checkpoint_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set padding token (required for training)\n",
    "\n",
    "if not set in your checkpoint and you want to do a further fine-tuning over your checkpoint you need to ensure the 'pad_token_id' is set in your checkpoint `config.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding pad_token_id to checkpoint config\n",
    "with open(os.path.join(checkpoint['checkpoint_path'], 'config.json'), 'r+') as file:\n",
    "    data = json.load(file)\n",
    "    data['pad_token_id']=None\n",
    "    file.seek(0)\n",
    "    file.truncate()\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model params and Sambastudio suitable Apps\n",
    "\n",
    "Extra parameters are required to upload your checkpoint including model architecture, sequence length, and vocabulary size, those parameters can be extracted from your checkpoint config, and included in checkpoint dict parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 12:21:33,276 [INFO] Params for checkpoint in /Users/jorgep/Documents/ask_public_own/ai-starter-kit-snova/e2e_fine_tuning/data/models/models--lightblue--suzume-llama-3-8B-multilingual/snapshots/0cb15aa9ec685eef494f9a15f65aefcfe3c04c66:\n",
      "[{'model_arch': 'llama', 'seq_length': 8192, 'vocab_size': 128256}]\n"
     ]
    }
   ],
   "source": [
    "checkpoint_config_params = byoc.find_config_params(checkpoint_paths=checkpoint['checkpoint_path'])[0]\n",
    "checkpoint.update(checkpoint_config_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To upload a model checkpoint you will need to set a SambaStudio App, if not sure, you can search for suitable apps using the checkpoint parameters, and select the one from the suitable apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 12:21:35,336 [INFO] Checkpoint Suzume-Llama-3-8B-Multilingual suitable apps:\n",
      "[{'id': '61fa0993-04a2-42ca-9db1-1eff693ea978', 'name': 'Samba1 Llama3 Experts'}, {'id': 'ad39e323-9878-4914-8e29-82c9f2939475', 'name': 'Llama 3'}]\n"
     ]
    }
   ],
   "source": [
    "suitable_apps = byoc.get_suitable_apps(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the two suitable apps found we will use the first one give we want to use this checkpoint in a bundle\n",
    "checkpoint[\"app_id\"]=suitable_apps[0][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'Suzume-Llama-3-8B-Multilingual',\n",
       " 'publisher': 'lightblue',\n",
       " 'description': ' Suzume 8B, a multilingual finetune of Llama 3',\n",
       " 'param_count': 8,\n",
       " 'checkpoint_path': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit-snova/e2e_fine_tuning/data/models/models--lightblue--suzume-llama-3-8B-multilingual/snapshots/0cb15aa9ec685eef494f9a15f65aefcfe3c04c66',\n",
       " 'model_arch': 'llama',\n",
       " 'seq_length': 8192,\n",
       " 'vocab_size': 128256,\n",
       " 'app_id': '61fa0993-04a2-42ca-9db1-1eff693ea978'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see here all the parameters required to upload the checkpoint\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If uploading only one checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 12:21:42,947 [INFO] Model with name 'Suzume-Llama-3-8B-Multilingual' not found\n",
      "2024-11-25 12:21:43,138 [INFO] App with name '61fa0993-04a2-42ca-9db1-1eff693ea978' found with id 61fa0993-04a2-42ca-9db1-1eff693ea978\n",
      "2024-11-25 15:17:27,207 [INFO] Model with name 'Suzume-Llama-3-8B-Multilingual' found with id b2bb7c02-3b18-4ef4-bd58-1b19669bce15\n",
      "2024-11-25 15:17:27,208 [INFO] Model checkpoint with name 'Suzume-Llama-3-8B-Multilingual' created it with id b2bb7c02-3b18-4ef4-bd58-1b19669bce15\n"
     ]
    }
   ],
   "source": [
    "# Execute the upload_checkpoint method from client with checkpoint parameters (this can take a while)\n",
    "model_id=byoc.upload_checkpoint(\n",
    "    model_name=checkpoint['model_name'],\n",
    "    checkpoint_path=checkpoint['checkpoint_path'],\n",
    "    description=checkpoint['description'],\n",
    "    publisher=checkpoint['publisher'],\n",
    "    param_count=checkpoint['param_count'],\n",
    "    model_arch=checkpoint['model_arch'],\n",
    "    seq_length=checkpoint['seq_length'],\n",
    "    vocab_size=checkpoint['vocab_size'],\n",
    "    app_id=checkpoint['app_id'],\n",
    "    retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 15:36:10,969 [INFO] model b2bb7c02-3b18-4ef4-bd58-1b19669bce15 status: \n",
      " {'model_id': 'b2bb7c02-3b18-4ef4-bd58-1b19669bce15', 'status': 'Available', 'progress': 100, 'stage': 'convert', 'status_code': 200, 'headers': {'access-control-allow-headers': 'Accept, Content-Type, Content-Length, Accept-Encoding, Authorization, ResponseType', 'access-control-allow-methods': 'GET, POST, PATCH, DELETE', 'access-control-allow-origin': '', 'content-type': 'application/json', 'x-correlation-id': 'cd512837-7f7d-48f6-a9df-62b6ef3e0d69', 'date': 'Mon, 25 Nov 2024 20:36:11 GMT', 'x-envoy-upstream-service-time': '52', 'server': 'istio-envoy', 'content-encoding': 'gzip', 'vary': 'Accept-Encoding', 'transfer-encoding': 'chunked'}}\n"
     ]
    }
   ],
   "source": [
    "# check the status of the uploaded checkpoint \n",
    "byoc.get_checkpoints_status(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively if uploading multiple checkpoints in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=byoc.upload_checkpoints([checkpoint], max_parallel_jobs=4, retries=3) # add multiple checkpoints parameters to the checkpoints list\n",
    "byoc.get_checkpoints_status([model['id'] for model in models])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlined Execution\n",
    "The checkpoint upload can be done in a streamlined way setting all the checkpoints parameters to upload in a config file like in the [checkpoints_config.yaml](../checkpoints_config.yaml) example, and executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.path.join(kit_dir, 'checkpoints_config.yaml')\n",
    "byoc = BYOC(config_file)\n",
    "byoc.find_config_params()\n",
    "byoc.upload_checkpoints()\n",
    "# wait until all checkpoints are in available status\n",
    "while True:\n",
    "    statuses = [model['status'] for model in byoc.get_checkpoints_status()]\n",
    "    if all(x == \"Available\" for x in statuses):\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snapienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
