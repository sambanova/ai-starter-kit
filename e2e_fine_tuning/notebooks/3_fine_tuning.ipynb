{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Executing Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir =  os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from utils.fine_tuning.src.snsdk_wrapper import SnsdkWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by Step / Manual setting\n",
    "\n",
    "First instantiate the SambaStudio client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 12:16:27,150 [INFO] Using variables from Snapi config to set up Snsdk.\n"
     ]
    }
   ],
   "source": [
    "sambastudio_client = SnsdkWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List trainable models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta-llama-3-8b-instruct-128384-vocab',\n",
       " 'E5 Large V2',\n",
       " 'GPT13B 2k SS ITv3',\n",
       " 'GPT_1.5B_GT_Finetuned',\n",
       " 'Multilingual E5 Large',\n",
       " 'GPT_1.5B_Base_Model',\n",
       " 'CLIP-ViT-B-32-laion2B-s34B-b79k',\n",
       " 'CLIP ViT-B-32 Backbone (Deprecated)',\n",
       " 'llava-v1.5-7b',\n",
       " 'Multilingual E5 Large Instruct',\n",
       " 'Hubert_ASR',\n",
       " 'GPT_1.5B_GT_Pretrained',\n",
       " 'Suzume-Llama-3-8B-Multilingual',\n",
       " 'TR_Sarashina2-70B_Superglue_Sarashina_8k_SN40L-8_4RDU-ckpt10',\n",
       " 'FakeBox',\n",
       " 'Deepseek-coder-6.7b-instruct',\n",
       " 'RC4_VIEW_TEST',\n",
       " 'SimpleTextClassGenerativeTrained',\n",
       " 'RC4_Colab_Test',\n",
       " 'Deepseek-coder-6.7b-base',\n",
       " 'GPT_1.5B_Dialog_Act_Classification_Finetuned',\n",
       " 'HermesProInstructV10',\n",
       " 'GPT_13B_Human_Aligned_Instruction_Tuned_V2',\n",
       " 'Llama-2-7b-16k-hf',\n",
       " 'YANZHEC_TEST_SNAPI_GPT1.5B_GT_Finetuned',\n",
       " 'meta-llama-3-8b-instruct-128256-vocab',\n",
       " 'LlamaGuard_7b',\n",
       " 'meta-llama-3-70b-instruct-128256-vocab',\n",
       " 'Thai_LLaMA_70B',\n",
       " 'GPT_13B_Generative_Inference',\n",
       " 'Llama-2-13b-hf',\n",
       " 'meta-llama-3-8b-nan-generator',\n",
       " 'meta-llama-guard-2-8b-128384-vocab',\n",
       " 'Zephyr-7B-Beta',\n",
       " 'Llama-2-7b-chat-hf',\n",
       " 'GPT_13B_Base_Model',\n",
       " 'Llama-2-7b-sambalingo-thai-base-hf',\n",
       " 'GPT_13B_GT_Base_Model_300k_MaxVocabSize',\n",
       " 'meta-llama-guard-2-8b-128256-vocab',\n",
       " 'Llama-2-70b-hf',\n",
       " 'Llama 2 7B base 8-socket',\n",
       " 'mistral-7b-instruct-v0.2',\n",
       " 'Llama-2-7b-sambalingo-thai-chat-hf',\n",
       " 'Llama 2 7B chat 8-socket',\n",
       " 'Llama-2-7b-hf',\n",
       " 'Llama-2-13b-chat-hf',\n",
       " 'llava-v1.5-7b (deprecated)',\n",
       " 'GPT 13B 8k SS SN Pretrained',\n",
       " 'GPT_13B_Dialog_Summarization_Finetuned',\n",
       " 'Llama-2-70-16k-hf',\n",
       " 'GPT13B 8k SS HAv3',\n",
       " 'GPT_13B_Instruction_Tuned_V2',\n",
       " 'GPT13B 8k SS ITv3',\n",
       " 'llama-2-70b-chat-hf',\n",
       " 'Meta-Llama-3-8B-Instruct',\n",
       " 'law-chat',\n",
       " 'meta-llama-3-70b-128256-vocab',\n",
       " 'Llama-2-7b-chat-hf',\n",
       " 'NSQL-Llama-2-7B',\n",
       " 'Test Upload',\n",
       " 'Llama-2-70b-chat-hf',\n",
       " 'GPT13B 2k SS HAv3',\n",
       " 'Llama-2-70b-chat-16k-hf',\n",
       " 'law-chat',\n",
       " 'mistral-7b-v0.1',\n",
       " 'meta-llama-3-70b-instruct-128384-vocab',\n",
       " 'Sarashina2-7b',\n",
       " 'llama-2-7B-chat-hf',\n",
       " 'meta-llama-3-70b-128384-vocab',\n",
       " 'Meta-Llama-3-70B-Instruct',\n",
       " 'Sarashina2-70b',\n",
       " 'Llama-2-13B-chat-hf',\n",
       " 'Llama-2-7b-chat-16k-hf',\n",
       " 'meta-llama-3-8b-128256-vocab',\n",
       " 'meta-llama-3-8b-128384-vocab',\n",
       " 'Sarashina2-7B',\n",
       " 'Sarashina2-70B',\n",
       " 'GPT_1.5B_NER_Finetuned']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model[\"model_checkpoint_name\"]for model in sambastudio_client.list_models(filter_job_types=[\"train\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'Suzume-Llama-3-8B-Multilingual'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openthaigpt_50k_IT0913',\n",
       " 'Generative_Inference_Dataset',\n",
       " 'GPT_13B_Inference_Dataset',\n",
       " 'FiQA',\n",
       " 'Super_Glue_4k_SS',\n",
       " 'E5_Large_V2_Inference_Example',\n",
       " 'ASR_With_Diarization_Dataset',\n",
       " 'Restore_Punctuation_Data',\n",
       " 'ASR_Without_Diarization_Dataset',\n",
       " 'GPT_13B_8k_SS_Toy_Training_Dataset',\n",
       " 'Librispeech',\n",
       " 'GPT_1.5B_Training_Dataset',\n",
       " 'GPT_13B_Training_Dataset',\n",
       " 'Speaker_Diarization',\n",
       " 'test',\n",
       " 'Coding_Generative_Train_4k_SS_Dataset',\n",
       " 'Mistral_Tokenized_Copa',\n",
       " 'thai-dpo-sft-ss4k',\n",
       " 'RBAC_Test_Curl',\n",
       " 'test_upload',\n",
       " 'Coding_Generative_Inference_Dataset',\n",
       " 'E5_Large_V2_Training_MSMarco_Distillation',\n",
       " 'console_upload',\n",
       " 'Super_Glue_8k_SS_128k_vocab',\n",
       " 'yc_snapi_add_localmachine_test_13B_2451_rc3',\n",
       " '0606qa03orgadmin',\n",
       " 'LLaVA-example',\n",
       " 'openwebtext_ss4096_32k_vocab',\n",
       " 'aniket-e5-dataset-upload-trial5',\n",
       " 'GPT_1.5B_Inference_Dataset',\n",
       " 'test_dataset',\n",
       " 'Super_Glue_16k_SS',\n",
       " 'Caltech_256_Clip',\n",
       " 'Superglue_Sarashina_4k',\n",
       " 'Superglue_Sarashina_8k',\n",
       " '1029test',\n",
       " '1113AWS',\n",
       " 'smol_sql_dataset',\n",
       " 'publichealth']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dataset[\"dataset_name\"] for dataset in sambastudio_client.list_datasets()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'publichealth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Project configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = {\n",
    "    'project_name': 'byoc fine-tuning project',\n",
    "    'project_description': 'this project will be used to test the BYOC and Fine-tuning e2e pipeline implementation'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 15:37:10,033 [INFO] Project with name 'byoc fine-tuning project' not found\n",
      "2024-11-25 15:37:10,258 [INFO] Project with name byoc fine-tuning project created with id b11867e6-7ca8-45bd-b09b-41cbc7ba73ce\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'b11867e6-7ca8-45bd-b09b-41cbc7ba73ce'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the create project method from client with project parameters\n",
    "sambastudio_client.create_project(\n",
    "    project_name = project['project_name'],\n",
    "    project_description = project['project_description']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set train job config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = {\n",
    "    'job_name': 'e2e_fc_taining_job',\n",
    "    'job_description': 'e2e finetuning training job public health for suzume multilingual',\n",
    "    'job_type': 'train',\n",
    "    'model': model,\n",
    "    'model_version': '1',\n",
    "    'parallel_instances': '1',\n",
    "    'dataset_name': dataset_name,\n",
    "    'load_state': False,\n",
    "    'sub_path': '',\n",
    "    'hyperparams': {\n",
    "        \"batch_size\": 8,\n",
    "        \"do_eval\": False,\n",
    "        \"eval_steps\":50,\n",
    "        \"evaluation_strategy\": \"no\",\n",
    "        \"learning_rate\": 0.00001,\n",
    "        \"logging_steps\": 1,\n",
    "        \"lr_schedule\": \"fixed_lr\",\n",
    "        \"max_sequence_length\": 8192,\n",
    "        \"num_iterations\": 100,\n",
    "        \"prompt_loss_weight\": 0.0,\n",
    "        \"save_optimizer_state\": True,\n",
    "        \"save_steps\": 50,\n",
    "        \"skip_checkpoint\": False,\n",
    "        \"subsample_eval\": 0.01,\n",
    "        \"subsample_eval_seed\": 123,\n",
    "        \"use_token_type_ids\": True,\n",
    "        \"vocab_size\": 128256,\n",
    "        \"warmup_steps\": 0,\n",
    "        \"weight_decay\": 0.1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 15:37:31,065 [INFO] Project with name 'byoc fine-tuning project' found with id b11867e6-7ca8-45bd-b09b-41cbc7ba73ce\n",
      "2024-11-25 15:37:32,546 [INFO] Model 'Suzume-Llama-3-8B-Multilingual' with id 'b2bb7c02-3b18-4ef4-bd58-1b19669bce15' available for training and deployment found\n",
      "2024-11-25 15:37:32,837 [INFO] Dataset with name 'publichealth' found with id 6ac585ad-107c-45f5-a2de-129dd1a69279\n",
      "2024-11-25 15:37:33,130 [INFO] Job with name 'e2e_fc_taining_job' created: '{'job_id': '1819ba81-9f93-4197-a7c3-51df6a3f8f0e', 'job_name': 'e2e_fc_taining_job', 'job_type': 'train', 'user_id': 'jorge.piedrahita', 'project_id': 'b11867e6-7ca8-45bd-b09b-41cbc7ba73ce', 'tenant_id': 'f254d0b5-fb45-4501-9740-93183e7c6f4c', 'rdu_arch': 'SN40L-8', 'result_path': '', 'parallel_instances': 1, 'app_id': '61fa0993-04a2-42ca-9db1-1eff693ea978', 'model_checkpoint': 'Suzume-Llama-3-8B-Multilingual', 'checkpoint_id': '', 'dataset_id': '6ac585ad-107c-45f5-a2de-129dd1a69279', 'description': 'e2e finetuning training job public health for suzume multilingual', 'status': 'CREATED', 'image_version': '1.1.6-20241025', 'variant_set_version': '3bd6d55fcf31c2b5c9c06293fa557c2e', 'variant_name': 'sn40.b=8.d=off.m=8192.m=1.m=8b.r=balanced.v=128256', 'project_name': 'byoc fine-tuning project', 'dataset_name': '', 'input_data_path': '', 'hyperparams': [], 'time_created': '2024-11-25T20:37:33.143538000Z', 'time_updated': '2024-11-25T20:37:33.143538000Z', 'load_state': False, 'app_name': 'Samba1 Llama3 Experts', 'environment_variables': '', 'model_id': 'b2bb7c02-3b18-4ef4-bd58-1b19669bce15', 'model_status': 'Available', 'model_version': 1, 'dataset': 'publichealth', 'dataset_path': 'default/default/datasets/local-dataset-6ac585ad-107c-45f5-a2de-129dd1a69279', 'tracking_id': '45db970d-a83f-4deb-9b11-b2dcff71264a', 'status_code': 200, 'headers': {'access-control-allow-headers': 'Accept, Content-Type, Content-Length, Accept-Encoding, Authorization, ResponseType', 'access-control-allow-methods': 'GET, POST, PATCH, DELETE', 'access-control-allow-origin': '', 'content-type': 'application/json', 'x-correlation-id': '45db970d-a83f-4deb-9b11-b2dcff71264a', 'date': 'Mon, 25 Nov 2024 20:37:33 GMT', 'x-envoy-upstream-service-time': '150', 'server': 'istio-envoy', 'content-encoding': 'gzip', 'vary': 'Accept-Encoding', 'transfer-encoding': 'chunked'}}'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1819ba81-9f93-4197-a7c3-51df6a3f8f0e'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sambastudio_client.run_training_job(\n",
    "    project_name = project[\"project_name\"],\n",
    "    job_name = job['job_name'],\n",
    "    job_description = job['job_description'],\n",
    "    job_type = job['job_type'],\n",
    "    model = job['model'],\n",
    "    model_version = job['model_version'],\n",
    "    dataset_name = job['dataset_name'],\n",
    "    parallel_instances = job['parallel_instances'],\n",
    "    load_state = job['load_state'],\n",
    "    sub_path = job['sub_path'],\n",
    "    rdu_arch = 'SN40L-8',\n",
    "    hyperparams = job['hyperparams']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 15:37:35,358 [INFO] Project with name 'byoc fine-tuning project' found with id b11867e6-7ca8-45bd-b09b-41cbc7ba73ce\n",
      "2024-11-25 15:37:35,616 [INFO] Project with name 'byoc fine-tuning project' found with id b11867e6-7ca8-45bd-b09b-41cbc7ba73ce\n",
      "2024-11-25 15:37:35,881 [INFO] Job with name 'e2e_fc_taining_job' in project 'byoc fine-tuning project' found with id '1819ba81-9f93-4197-a7c3-51df6a3f8f0e'\n",
      "2024-11-25 15:37:36,104 [INFO] Job `e2e_fc_taining_job` with progress status: PENDING_RDU\n",
      "2024-11-25 15:38:36,340 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:39:36,597 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:40:36,859 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:41:37,169 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:42:37,509 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:43:37,829 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:44:38,081 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:45:38,331 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:46:38,597 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:47:38,860 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:48:39,099 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:49:39,341 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:50:39,632 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:51:39,876 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:52:40,164 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:53:40,429 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:54:40,720 [INFO] Job `e2e_fc_taining_job` with progress status: TRAINING\n",
      "2024-11-25 15:55:40,959 [INFO] Job `e2e_fc_taining_job` with progress status: EXIT_WITH_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': '1819ba81-9f93-4197-a7c3-51df6a3f8f0e',\n",
       " 'job_name': 'e2e_fc_taining_job',\n",
       " 'job_type': 'train',\n",
       " 'status': 'EXIT_WITH_0',\n",
       " 'time_created': '2024-11-25T20:37:33.143538000Z'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sambastudio_client.check_job_progress(\n",
    "    project_name=project['project_name'],\n",
    "    job_name=job['job_name'],\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promote Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:03:15,340 [INFO] Project with name 'byoc fine-tuning project' found with id b11867e6-7ca8-45bd-b09b-41cbc7ba73ce\n",
      "2024-11-25 16:03:15,664 [INFO] Project with name 'byoc fine-tuning project' found with id b11867e6-7ca8-45bd-b09b-41cbc7ba73ce\n",
      "2024-11-25 16:03:15,905 [INFO] Job with name 'e2e_fc_taining_job' in project 'byoc fine-tuning project' found with id '1819ba81-9f93-4197-a7c3-51df6a3f8f0e'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'checkpoint_name': '1819ba81-9f93-4197-a7c3-51df6a3f8f0e-10',\n",
       "  'checkpoint_id': '6925d395-3251-4465-8ec6-225761536680',\n",
       "  'steps': 10,\n",
       "  'time_created': '2024-11-25T20:55:13.923615Z',\n",
       "  'metrics': {'single_value': {'train_learning_rate': 0.0,\n",
       "    'train_loss': 1.6116},\n",
       "   'multi_value': {},\n",
       "   'last_batch_omitted': []},\n",
       "  'labels': None,\n",
       "  'job_id': '1819ba81-9f93-4197-a7c3-51df6a3f8f0e',\n",
       "  'app_id': '61fa0993-04a2-42ca-9db1-1eff693ea978',\n",
       "  'app_name': 'Samba1 Llama3 Experts',\n",
       "  'path': 'default/default/b11867e6-7ca8-45bd-b09b-41cbc7ba73ce/jobs/1819ba81-9f93-4197-a7c3-51df6a3f8f0e/checkpoints/1819ba81-9f93-4197-a7c3-51df6a3f8f0e-10',\n",
       "  'transformers_version': '',\n",
       "  'torch_version': '',\n",
       "  'user_id': 'jorge.piedrahita',\n",
       "  'tenant_id': 'f254d0b5-fb45-4501-9740-93183e7c6f4c',\n",
       "  'image_version': '1.1.6-20241025',\n",
       "  'dependent_jobs': []},\n",
       " {'checkpoint_name': '1819ba81-9f93-4197-a7c3-51df6a3f8f0e-5',\n",
       "  'checkpoint_id': '19a5cf40-1663-406c-816a-fceb759624f5',\n",
       "  'steps': 5,\n",
       "  'time_created': '2024-11-25T20:48:35.023844Z',\n",
       "  'metrics': {'single_value': {'train_learning_rate': 0.0,\n",
       "    'train_loss': 2.1781},\n",
       "   'multi_value': {},\n",
       "   'last_batch_omitted': []},\n",
       "  'labels': None,\n",
       "  'job_id': '1819ba81-9f93-4197-a7c3-51df6a3f8f0e',\n",
       "  'app_id': '61fa0993-04a2-42ca-9db1-1eff693ea978',\n",
       "  'app_name': 'Samba1 Llama3 Experts',\n",
       "  'path': 'default/default/b11867e6-7ca8-45bd-b09b-41cbc7ba73ce/jobs/1819ba81-9f93-4197-a7c3-51df6a3f8f0e/checkpoints/1819ba81-9f93-4197-a7c3-51df6a3f8f0e-5',\n",
       "  'transformers_version': '',\n",
       "  'torch_version': '',\n",
       "  'user_id': 'jorge.piedrahita',\n",
       "  'tenant_id': 'f254d0b5-fb45-4501-9740-93183e7c6f4c',\n",
       "  'image_version': '1.1.6-20241025',\n",
       "  'dependent_jobs': []}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will promote the checkpoint with less training loss so we list it sorted \n",
    "checkpoints = sambastudio_client.list_checkpoints(\n",
    "    project_name=project['project_name'],\n",
    "    job_name=job['job_name'],\n",
    "    sort=True\n",
    ")\n",
    "checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Promoted checkpoint config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint to promote config\n",
    "model_checkpoint = {\n",
    "    'checkpoint_name': checkpoints[0]['checkpoint_name'],\n",
    "    'model_name': 'Suzume-Llama-3-8B-Multilingual-Publichealth',\n",
    "    'model_description': 'finetuned suzume multilingual in public health qa dataset',\n",
    "    'model_type': 'finetuned'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:03:51,838 [INFO] Project with name 'byoc fine-tuning project' found with id b11867e6-7ca8-45bd-b09b-41cbc7ba73ce\n",
      "2024-11-25 16:03:52,088 [INFO] Project with name 'byoc fine-tuning project' found with id b11867e6-7ca8-45bd-b09b-41cbc7ba73ce\n",
      "2024-11-25 16:03:52,329 [INFO] Job with name 'e2e_fc_taining_job' in project 'byoc fine-tuning project' found with id '1819ba81-9f93-4197-a7c3-51df6a3f8f0e'\n",
      "2024-11-25 16:03:53,245 [INFO] Model checkpoint '1819ba81-9f93-4197-a7c3-51df6a3f8f0e-10' promoted to model 'Suzume-Llama-3-8B-Multilingual-Publichealth'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c867b392-2d02-453d-9fd8-e14016e39153'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the promote_checkpoint method from client with checkpoint parameters\n",
    "sambastudio_client.promote_checkpoint(\n",
    "    checkpoint_name = model_checkpoint['checkpoint_name'],\n",
    "    project_name=project['project_name'],\n",
    "    job_name=job['job_name'],\n",
    "    model_name=model_checkpoint['model_name'],\n",
    "    model_description=model_checkpoint['model_description'],\n",
    "    model_type=model_checkpoint['model_type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_id': 'c867b392-2d02-453d-9fd8-e14016e39153',\n",
       "  'model_checkpoint_name': 'Suzume-Llama-3-8B-Multilingual-Publichealth',\n",
       "  'version': 1}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the promoted model is now in SambaStudio models\n",
    "[model for model in sambastudio_client.list_models() if model['model_checkpoint_name']==model_checkpoint['model_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all saved training checkpoints, after promotion (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:06:20,296 [INFO] Model checkpoint '1819ba81-9f93-4197-a7c3-51df6a3f8f0e-10' deleted\n",
      "2024-11-25 16:06:20,586 [INFO] Model checkpoint '1819ba81-9f93-4197-a7c3-51df6a3f8f0e-5' deleted\n"
     ]
    }
   ],
   "source": [
    "# We can delete all intermediate checkpoints saved during the training job \n",
    "for checkpoint in checkpoints:\n",
    "    sambastudio_client.delete_checkpoint(checkpoint[\"checkpoint_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlined Execution\n",
    "\n",
    "The training job and checkpoint promotion can be done in a streamlined way setting all the job and checkpoint parameters in a config file like in the [finetune_config.yaml](../finetune_config.yaml) example, and executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.path.join(kit_dir, 'finetune_config.yaml')\n",
    "sambastudio_client = SnsdkWrapper(config_file)\n",
    "sambastudio_client.create_project()\n",
    "sambastudio_client.run_training_job()\n",
    "sambastudio_client.check_job_progress(wait=True)\n",
    "checkpoints = sambastudio_client.list_checkpoints(sort=True)\n",
    "sambastudio_client.promote_checkpoint(checkpoints[0]['checkpoint_name'])\n",
    "for checkpoint in checkpoints:\n",
    "    sambastudio_client.delete_checkpoint(checkpoint[\"checkpoint_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
