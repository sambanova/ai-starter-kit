llm:
    "model": "Meta-Llama-3.3-70B-Instruct"
    "temperature": 0.0
    "max_tokens": 4000
    "top_p": 0.1    
    "top_k":

system_message: "You are a document analysis assistant" 

max_retries: 2 # Maximum number of attemps to get a response from the LLM for each request

pdf_only_mode: True  # Set to true for PDF-only lite parsing mode (use PyMuPdf instead of Sambaparse)

templates: "document_comparison/templates/document_comparison_templates.json"

prod_mode: False