{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from sambanova_endpoint import SambaNovaEndpoint, SambaverseEndpoint, SambaStudioFastCoE, SambaNovaEmbeddingModel\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "load_dotenv(\"../.env\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SambaStudio endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = SambaNovaEndpoint(\n",
    "        streaming=False,\n",
    "        #base_uri=\"api/predict/generic\",\n",
    "        model_kwargs={\n",
    "            \"do_sample\": True, \n",
    "            \"temperature\": 0.01,\n",
    "            \"max_tokens_to_generate\": 256,\n",
    "            \"process_prompt\": False,\n",
    "            \"select_expert\": \"llama-2-7b-chat-hf\",\n",
    "            # \"repetition_penalty\": 1.0,\n",
    "            # \"top_k\": 50\",\n",
    "            # \"top_logprobs\": 0,\n",
    "            # \"top_p\": 1.0\n",
    "        }\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of a character who is a master of disguise\\n\\nSure! Here is a 50-word tale of a character who is a master of disguise:\\n\\n\"Araxys, the skilled disguise artist, transformed into a stunning mermaid to infiltrate a pirate\\'s lair, her shimmering scales and flowing locks fooling even the most skeptical of eyes.\"'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"tell me a 50 word tale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=SambaNovaEndpoint(\n",
    "        streaming=True,\n",
    "        model_kwargs={\n",
    "            \"do_sample\": True,\n",
    "            \"max_tokens_to_generate\": 256,\n",
    "            \"temperature\": 0.01,\n",
    "            \"process_prompt\": False,\n",
    "            \"select_expert\": \"llama-2-7b-chat-hf\",\n",
    "            # \"repetition_penalty\": 1.0,\n",
    "            # \"top_k\": 50\",\n",
    "            # \"top_logprobs\": 0,\n",
    "            # \"top_p\": 1.0\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of a character who is a master of disguise\n",
      "\n",
      "Sure! Here is a 50-word tale of a character who is a master of disguise:\n",
      "\n",
      "\"Araxys, the skilled disguise artist, transformed into a stunning mermaid to infiltrate a pirate's lair, then morphed into a loyal servant to gain the trust of the pirate's crew.\""
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"tell me a 50 word tale\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sambaverse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SambaverseEndpoint(\n",
    "    sambaverse_model_name = \"Meta/llama-2-7b-chat-hf\",\n",
    "    model_kwargs={\n",
    "        \"do_sample\": True, \n",
    "        \"max_tokens_to_generate\": 256,\n",
    "        \"temperature\": 0.01,\n",
    "        \"process_prompt\": True,\n",
    "        \"select_expert\": \"llama-2-7b-chat-hf\",\n",
    "        #\"stop_sequences\": '\\\"sequence1\\\",\\\"sequence2\\\"',\n",
    "        #\"repetition_penalty\":  1.0,\n",
    "        #\"top_k\": 50,\n",
    "        #\"top_p\": 1.0\n",
    "        }\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sure! Here is a 50-word tale:\\n\\nThe cat purred contentedly on my lap, pawing at my hand with a gentle mew.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"tell me a 50 word tale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SambaverseEndpoint(\n",
    "    streaming=True,\n",
    "    sambaverse_model_name=\"Meta/llama-2-7b-chat-hf\",\n",
    "    model_kwargs={\n",
    "        \"do_sample\": True, \n",
    "        \"max_tokens_to_generate\": 256,\n",
    "        \"temperature\": 0.01,\n",
    "        \"process_prompt\": True,\n",
    "        \"select_expert\": \"llama-2-7b-chat-hf\",\n",
    "        #\"stop_sequences\": '\\\"sequence1\\\",\\\"sequence2\\\"',\n",
    "        #\"repetition_penalty\":  1.0,\n",
    "        #\"top_k\": 50,\n",
    "        #\"top_p\": 1.0\n",
    "        }\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure! Here is a 50-word tale:\n",
      "\n",
      "The cat purred contentedly on my lap, pawing at my hand with a gentle mew."
     ]
    }
   ],
   "source": [
    "\n",
    "for chunk in llm.stream(\"tell me a 50 word tale\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastCoe endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SambaStudioFastCoE(model='llama3-8b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's great to meet you! I'm here to assist you with any questions or topics you'd like to discuss. I'm a helpful assistant developed by SambaNova Systems, and I'm committed to providing you with accurate and respectful information. What's on your mind today?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "llm.invoke(json.dumps([{'role': 'user', 'content': 'hello'}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's great to meet you! I'm here to assist you with any questions or topics you'd like to discuss. I'm a helpful assistant developed by SambaNova Systems, and I'm committed to providing you with accurate and respectful information. What's on your mind today?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'd be delighted to spin a yarn for you! Here's a tale that'll take us on \n",
      "a journey across the globe, through time, and into the hearts of those who lived through \n",
      "it.\n",
      "\n",
      "Once upon a time, in the early 19th century, there was a small village nestled in \n",
      "the rolling hills of rural France. The villagers lived simple lives, working the land, tending to \n",
      "their animals, and trading goods with neighboring towns. Among them was a young girl named Sophie, with \n",
      "hair as golden as the sun and eyes as blue as the sky.\n",
      "\n",
      "Sophie was a curious and \n",
      "adventurous soul, always eager to explore the world beyond her village. She spent her days helping her mother \n",
      "with the household chores, learning the secrets of traditional French cooking, and listening to the stories of the \n",
      "village elder, Monsieur LeFleur.\n",
      "\n",
      "One day, a group of travelers passed through the \n",
      "village, seeking refuge from the turmoil of the Napoleonic Wars. Among them was a young man named \n",
      "Alexandre, a skilled musician with a voice as smooth as honey and a heart full of kindness. Sophie \n",
      "was immediately smitten, and the two began to spend hours together, exploring the countryside and sharing stories \n",
      "of their dreams and aspirations.\n",
      "\n",
      "As the years passed, Sophie and Alexandre's love blossomed, and \n",
      "they decided to leave the village to make a new life in the city. They settled in Paris, \n",
      "where Sophie's culinary skills earned her a reputation as one of the city's top chefs, and \n",
      "Alexandre's music brought joy to the hearts of all who heard him.\n",
      "\n",
      "But fate had other plans. \n",
      "Napoleon's armies returned, and the city was plunged into chaos. Sophie and Alexandre found themselves caught in the \n",
      "midst of the conflict, struggling to survive as the city burned around them.\n",
      "\n",
      "In the midst of the \n",
      "chaos, Sophie discovered a hidden talent â€“ she could heal the wounded with her cooking. Her dishes, \n",
      "infused with love and kindness, brought solace to the suffering, and soon, people from all walks \n",
      "of life were flocking to her kitchen, seeking comfort and hope.\n",
      "\n",
      "As the war finally came to \n",
      "an end, Sophie and Alexandre decided to leave Paris and start anew in the United States. They settled \n",
      "in New Orleans, where Sophie's culinary skills earned her a reputation as one of the city's top \n",
      "chefs, and Alexandre's music brought joy to the hearts of all who heard him.\n",
      "\n",
      "Years passed, \n",
      "and Sophie and Alexandre built a life filled with love, laughter, and music. They had children, \n",
      "grandchildren, and great-grandchildren, each one carrying on the traditions and stories of their ancestors.\n",
      "\n",
      "But \n",
      "Sophie's greatest legacy was yet to come. As she grew older, she began to share her \n",
      "stories, her recipes, and her love with the world. She wrote cookbooks, taught cooking classes, \n",
      "and even opened a small restaurant in the heart of the city.\n",
      "\n",
      "And so, Sophie's story became \n",
      "a part of the fabric of the city, a reminder of the power of love, kindness, and \n",
      "resilience. Her legacy lived on, inspiring generations to come, and reminding us all that even in the \n",
      "darkest of times, there is always hope, always love, and always a chance to start \n",
      "anew.\n",
      "\n",
      "I hope you enjoyed this long story! It's a tale of love, adventure, and the power \n",
      "of the human \n",
      "spirit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in llm.stream('hello tell me a long story'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = SambaNovaEmbeddingModel()\n",
    "embedding.embed_documents([\"tell me a 50 word tale\",\"tell me a joke\"])\n",
    "embedding.embed_query(\"tell me a 50 word tale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Response.json of <Response [200]>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='give me 3 party activities'),\n",
       " Document(page_content='tell me a 50 word tale'),\n",
       " Document(page_content='tell me a joke'),\n",
       " Document(page_content='give me three healty dishes')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "docs=[\"tell me a 50 word tale\",\"tell me a joke\",\"when was America discoverd?\", \"how to build an engine?\", \"give me 3 party activities\", \"give me three healty dishes\"]\n",
    "docs=[Document(doc) for doc in docs]\n",
    "\n",
    "query = \"prompt for generating something fun\"\n",
    "\n",
    "vectordb = Chroma.from_documents(docs, embedding)\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "retriever.get_relevant_documents(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = SambaNovaEmbeddingModel(\n",
    "    batch_size=1,\n",
    "    model_kwargs = {\n",
    "        \"select_expert\":\"e5-mistral-7b-instruct\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.embed_documents([\"tell me a 50 word tale\",\"tell me a joke\"])\n",
    "embedding.embed_query(\"tell me a 50 word tale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
