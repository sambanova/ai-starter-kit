{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from sambanova_endpoint import SambaNovaEndpoint, SambaverseEndpoint, SambaNovaEmbeddingModel\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "load_dotenv(\"../.env\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SambaStudio endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = SambaNovaEndpoint(\n",
    "        streaming=False,\n",
    "        #base_uri=\"api/predict/generic\",\n",
    "        model_kwargs={\n",
    "            \"do_sample\": True, \n",
    "            \"temperature\": 0.01,\n",
    "            \"max_tokens_to_generate\": 256,\n",
    "            #\"process_prompt\": False,\n",
    "            #\"select_expert\": \"llama-2-7b-chat-hf\",\n",
    "            # \"repetition_penalty\": 1.0,\n",
    "            # \"top_k\": 50\",\n",
    "            # \"top_logprobs\": 0,\n",
    "            # \"top_p\": 1.0\n",
    "        }\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of a character who is a master of disguise\\n\\nSure! Here is a 50-word tale of a character who is a master of disguise:\\n\\n\"Araxys, the skilled disguise artist, transformed into a stunning mermaid to infiltrate a pirate\\'s lair. With a flick of her tail, she charmed the pirates and stole their treasure.\"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"tell me a 50 word tale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=SambaNovaEndpoint(\n",
    "        streaming=True,\n",
    "        model_kwargs={\n",
    "            \"do_sample\": True,\n",
    "            \"max_tokens_to_generate\": 256,\n",
    "            \"temperature\": 0.01,\n",
    "            # \"repetition_penalty\": 1.0,\n",
    "            # \"top_k\": 50\",\n",
    "            # \"top_logprobs\": 0,\n",
    "            # \"top_p\": 1.0\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of a man who was once a great warrior, but is now a humble farmer.\n",
      "\n",
      "The sun sets on the fields, a weary farmer bends to his toil. Once a great warrior, he fought for his people's freedom. Now, he fights for his family's survival. His calloused hands, a testament to his past, still hold the strength of a warrior. But his heart, once filled with anger and vengeance, now holds only love and hope."
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"tell me a 50 word tale\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sambaverse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SambaverseEndpoint(\n",
    "    sambaverse_model_name = \"Meta/llama-2-7b-chat-hf\",\n",
    "    model_kwargs={\n",
    "        \"do_sample\": True, \n",
    "        \"max_tokens_to_generate\": 256,\n",
    "        \"temperature\": 0.01,\n",
    "        \"process_prompt\": True,\n",
    "        \"select_expert\": \"llama-2-7b-chat-hf\",\n",
    "        #\"stop_sequences\": '\\\"sequence1\\\",\\\"sequence2\\\"',\n",
    "        #\"repetition_penalty\":  1.0,\n",
    "        #\"top_k\": 50,\n",
    "        #\"top_p\": 1.0\n",
    "        }\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sure! Here is a 50-word tale:\\n\\nThe cat purred contentedly on my lap, pawing at my hand with a gentle mew.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"tell me a 50 word tale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SambaverseEndpoint(\n",
    "    streaming=True,\n",
    "    sambaverse_model_name=\"Meta/llama-2-7b-chat-hf\",\n",
    "    model_kwargs={\n",
    "        \"do_sample\": True, \n",
    "        \"max_tokens_to_generate\": 256,\n",
    "        \"temperature\": 0.01,\n",
    "        \"process_prompt\": True,\n",
    "        \"select_expert\": \"llama-2-7b-chat-hf\",\n",
    "        #\"stop_sequences\": '\\\"sequence1\\\",\\\"sequence2\\\"',\n",
    "        #\"repetition_penalty\":  1.0,\n",
    "        #\"top_k\": 50,\n",
    "        #\"top_p\": 1.0\n",
    "        }\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure! Here is a 50-word tale:\n",
      "\n",
      "The cat purred contentedly on my lap, pawing at my hand with a gentle mew."
     ]
    }
   ],
   "source": [
    "\n",
    "for chunk in llm.stream(\"tell me a 50 word tale\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = SambaNovaEmbeddingModel()\n",
    "embedding.embed_documents([\"tell me a 50 word tale\",\"tell me a joke\"])\n",
    "embedding.embed_query(\"tell me a 50 word tale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Response.json of <Response [200]>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='give me 3 party activities'),\n",
       " Document(page_content='tell me a 50 word tale'),\n",
       " Document(page_content='tell me a joke'),\n",
       " Document(page_content='give me three healty dishes')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "docs=[\"tell me a 50 word tale\",\"tell me a joke\",\"when was America discoverd?\", \"how to build an engine?\", \"give me 3 party activities\", \"give me three healty dishes\"]\n",
    "docs=[Document(doc) for doc in docs]\n",
    "\n",
    "query = \"prompt for generating something fun\"\n",
    "\n",
    "vectordb = Chroma.from_documents(docs, embedding)\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "retriever.get_relevant_documents(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
