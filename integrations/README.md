# SambaNova Cloud Integrations

Welcome to the SambaNova Cloud API ecosystem, where everyday our fast inference models are expanding alongside the best tools in the developer community. Explore the partners available below and get started building\! 

### Need Assistance? 

If you have any suggestions of integrations or questions, please post on our [Community Page](https://community.sambanova.ai/) so we can follow up. 

## Integrations

| Company | Type | Description | Access |
| :---- | :---- | :---- | :---- |
| **AutoGen** | Agentic-first library | AutoGen is an open-source tool that defines agents, integrates LLMs, and handles task termination.  | [Demo code](https://github.com/sambanova/ai-starter-kit/tree/main/integrations/autogen) |
| **Camel** | Agentic-first library | Camel AI is an open-source framework for intelligent agents, and supports building, customizing, and deploying multi-agent systems.   | [Demo code](https://github.com/sambanova/ai-starter-kit/tree/main/integrations/camel) |
| **Continue** | Assistant tool | Continue is an open-source coding assistant platform to modify and optimize coding within IDE. | [Usage](./continue/README.md)   [Documentation](https://sambanova.ai/blog/accelerating-coding-with-sambanova-cloud?ref=blog.continue.dev) |
| **CrewAI** | Agentic-first library | CrewAI is an open-source framework for making automated workflows with agents. | [Demo code](https://github.com/sambanova/ai-starter-kit/tree/main/integrations/crewai) |
| **Gradio** | Assistant tool | Gradio is an open-source Python package that allows users to create interactive web apps for machine learning models, APIs, and Python functions.  | [Demo code](https://github.com/gradio-app/sambanova-gradio) |
| **Haystack** | LLM framework | Haystack is an open-source end-to-end framework that enables modular development of production-ready LLM applications.  | [Demo code](https://haystack.deepset.ai/integrations/sambanova) |
| **Hugging Face**  | LLM framework | Hugging Face is a platform for building, training, and deploying open-source models.  | [Documentation](https://huggingface.co/docs/huggingface_hub/main/en/package_reference/inference_client) |
| **LangChain** | LLM framework | Langchain implements a standard interface for LLMs to simplify development, productization, and deployment. | [Documentation](https://python.langchain.com/docs/integrations/providers/sambanova/) |
| **Langflow** | Low code framework | Langflow is a visual framework for building multi-agent and RAG applications. | [Documentation](https://docs.langflow.org/components-models#sambanova) |
| **LlamaIndex** | LLM framework | LlamaIndex is an orchestration framework to rapidly deploy LLM applications. | [Demo code](https://github.com/sambanova/ai-starter-kit/tree/main/integrations/llamaindex) |
| **LiteLLM** | LLM framework | LiteLLM is an open-source Python library that provides a unified interface for accessing LLMs, translating inputs and mapping exceptions. | [Documentation](https://docs.litellm.ai/docs/providers/sambanova) |
| **Lama Stack** | AI application framework | Llama Stack standardizes the core building blocks that simplify AI application development. It codifies best practices across the Llama ecosystem. | [Demo code](./llama_stack/README.md) |
| **Milvus** | Vector DB | Milvus is an open-source vector database from Milvus and can easily enable RAG applications. | [Demo code](https://github.com/sambanova/ai-starter-kit/tree/main/integrations/milvus) |
| **Oumi** | LLM framework | Oumi is open-source platform that streamlines the entire lifecycle of foundation models from data preparation and training to evaluation and deployment. | [Documentation](https://oumi.ai/docs/en/latest/api/oumi.inference.html#oumi.inference.SambanovaInferenceEngine) |
| **Semantic Kernel** | Agentic-first library | Semantic Kernel is an open-source development tool to build agents and integrate them with the latest AI models into your codebase.  | [Demo code](https://github.com/sambanova/ai-starter-kit/blob/main/integrations/semantic_kernel) |