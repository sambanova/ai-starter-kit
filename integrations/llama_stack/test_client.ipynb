{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_http_client():\n",
    "    from llama_stack_client import LlamaStackClient\n",
    "\n",
    "    return LlamaStackClient(base_url=f\"http://localhost:{os.environ['LLAMA_STACK_PORT']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = create_http_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionResponse(completion_message=CompletionMessage(content='Lines of code unfold\\nLogic flows like morning dew\\nBeauty in the byte', role='assistant', stop_reason='end_of_turn', tool_calls=[]), logprobs=None, metrics=[Metric(metric='prompt_tokens', value=27.0, unit=None), Metric(metric='completion_tokens', value=25.0, unit=None), Metric(metric='total_tokens', value=52.0, unit=None)])\n",
      "Lines of code unfold\n",
      "Logic flows like morning dew\n",
      "Beauty in the byte\n"
     ]
    }
   ],
   "source": [
    "response = client.inference.chat_completion(\n",
    "    model_id=\"sambanova/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a haiku about coding\"},\n",
    "    ],\n",
    ")\n",
    "print(response)\n",
    "print(response.completion_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data:image/png;base64,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'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_url_from_image(file_path):\n",
    "    mime_type, _ = mimetypes.guess_type(file_path)\n",
    "    if mime_type is None:\n",
    "        raise ValueError(\"Could not determine MIME type of the file\")\n",
    "\n",
    "    with open(file_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    data_url = f\"data:{mime_type};base64,{encoded_string}\"\n",
    "    return data_url\n",
    "\n",
    "\n",
    "data_url_from_image(\"../../images/SambaNova-dark-logo-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Llama-3.2-11B-Vision-Instruct',\n",
       " 'Llama-3.2-90B-Vision-Instruct',\n",
       " 'Meta-Llama-3.1-405B-Instruct',\n",
       " 'Meta-Llama-3.1-70B-Instruct',\n",
       " 'Meta-Llama-3.1-8B-Instruct',\n",
       " 'Meta-Llama-3.2-1B-Instruct',\n",
       " 'Meta-Llama-3.2-3B-Instruct',\n",
       " 'Meta-Llama-3.3-70B-Instruct',\n",
       " 'Meta-Llama-Guard-3-8B',\n",
       " 'all-MiniLM-L6-v2',\n",
       " 'meta-llama/Llama-3.1-405B-Instruct-FP8',\n",
       " 'meta-llama/Llama-3.1-70B-Instruct',\n",
       " 'meta-llama/Llama-3.1-8B-Instruct',\n",
       " 'meta-llama/Llama-3.2-11B-Vision-Instruct',\n",
       " 'meta-llama/Llama-3.2-1B-Instruct',\n",
       " 'meta-llama/Llama-3.2-3B-Instruct',\n",
       " 'meta-llama/Llama-3.2-90B-Vision-Instruct',\n",
       " 'meta-llama/Llama-3.3-70B-Instruct',\n",
       " 'meta-llama/Llama-Guard-3-8B',\n",
       " 'sambanova/Llama-3.2-11B-Vision-Instruct',\n",
       " 'sambanova/Llama-3.2-90B-Vision-Instruct',\n",
       " 'sambanova/Meta-Llama-3.1-405B-Instruct',\n",
       " 'sambanova/Meta-Llama-3.1-70B-Instruct',\n",
       " 'sambanova/Meta-Llama-3.1-8B-Instruct',\n",
       " 'sambanova/Meta-Llama-3.2-1B-Instruct',\n",
       " 'sambanova/Meta-Llama-3.2-3B-Instruct',\n",
       " 'sambanova/Meta-Llama-3.3-70B-Instruct',\n",
       " 'sambanova/Meta-Llama-Guard-3-8B']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_models():\n",
    "    models = []\n",
    "    for model in client.models.list():\n",
    "        models.append(model.identifier)\n",
    "    return models\n",
    "\n",
    "\n",
    "list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference_llm_text_only(stream: bool):\n",
    "    model_ids = list_models()\n",
    "    print(\"========== Inference: Text Only ==========\")\n",
    "    assert len(model_ids) > 0\n",
    "    for model_id in model_ids:\n",
    "        if \"guard\" not in model_id.lower() and \"sambanova\" in model_id:\n",
    "            print(f\">>>>> Sending request to {model_id}\")\n",
    "            iterator = client.inference.chat_completion(\n",
    "                model_id=model_id,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": \"Write a haiku on llamas\"},\n",
    "                ],\n",
    "                stream=stream,\n",
    "            )\n",
    "            if stream:\n",
    "                print(\"<<<<< Streaming Response\")\n",
    "                text = \"\"\n",
    "                for chunk in iterator:\n",
    "                    print(f\"{chunk.event.delta.text}\", end=\"\", flush=True)\n",
    "                    text += chunk.event.delta.text\n",
    "                assert text != \"\"\n",
    "                print()\n",
    "            else:\n",
    "                print(\"<<<<< Non-streaming Response\")\n",
    "                print(f\"Type: {type(iterator.completion_message.content)}, Value:{iterator.completion_message.content}\")\n",
    "                assert iterator.completion_message.content != \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Inference: Text Only ==========\n",
      ">>>>> Sending request to sambanova/Llama-3.2-11B-Vision-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "Type: <class 'str'>, Value:Fuzzy llama eyes\n",
      "Softly gaze with gentle soul\n",
      "Mountain's gentle friend\n",
      ">>>>> Sending request to sambanova/Llama-3.2-90B-Vision-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "Type: <class 'str'>, Value:Fuzzy gentle eyes\n",
      "Llama's soft and quiet pace\n",
      "Misty mountain friend\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.1-405B-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "Type: <class 'str'>, Value:Softly gentle eyes\n",
      "Llama's gentle, fuzzy form\n",
      "Misty Andes home\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.1-70B-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "Type: <class 'str'>, Value:Fuzzy gentle eyes\n",
      "Llama's soft and quiet pace\n",
      "Misty mountain friend\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.1-8B-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "Type: <class 'str'>, Value:Fuzzy llama eyes\n",
      "Softly gaze with gentle soul\n",
      "Mountain's gentle friend\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.2-1B-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "Type: <class 'str'>, Value:Softly padded feet\n",
      "Gentle eyes in the Andes\n",
      "Llama's gentle soul\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.2-3B-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "Type: <class 'str'>, Value:Softly humming llama\n",
      "Gentle eyes in misty dawn\n",
      "Peaceful Andean soul\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.3-70B-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "Type: <class 'str'>, Value:Fuzzy gentle eyes\n",
      "Llama's soft and quiet pace\n",
      "Misty mountain friend\n"
     ]
    }
   ],
   "source": [
    "test_inference_llm_text_only(stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Inference: Text Only ==========\n",
      ">>>>> Sending request to sambanova/Llama-3.2-11B-Vision-Instruct\n",
      "<<<<< Streaming Response\n",
      "Fuzzy llama eyes\n",
      "Softly gaze with gentle soul\n",
      "Mountain's gentle friend\n",
      ">>>>> Sending request to sambanova/Llama-3.2-90B-Vision-Instruct\n",
      "<<<<< Streaming Response\n",
      "Fuzzy gentle eyes\n",
      "Llama's soft and quiet pace\n",
      "Misty mountain friend\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.1-405B-Instruct\n",
      "<<<<< Streaming Response\n",
      "Softly gentle eyes\n",
      "Llama's gentle, fuzzy form\n",
      "Misty Andes home\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.1-70B-Instruct\n",
      "<<<<< Streaming Response\n",
      "Fuzzy gentle eyes\n",
      "Llama's soft and quiet pace\n",
      "Misty mountain friend\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.1-8B-Instruct\n",
      "<<<<< Streaming Response\n",
      "Fuzzy llama eyes\n",
      "Softly gaze with gentle soul\n",
      "Mountain's gentle friend\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.2-1B-Instruct\n",
      "<<<<< Streaming Response\n",
      "Softly padded feet\n",
      "Gentle eyes in the Andes\n",
      "Llama's gentle soul\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.2-3B-Instruct\n",
      "<<<<< Streaming Response\n",
      "Softly humming llama\n",
      "Gentle eyes in misty dawn\n",
      "Peaceful Andean soul\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.3-70B-Instruct\n",
      "<<<<< Streaming Response\n",
      "Fuzzy gentle eyes\n",
      "Llama's soft and quiet pace\n",
      "Misty mountain friend\n"
     ]
    }
   ],
   "source": [
    "test_inference_llm_text_only(stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference_llm_text_tool(stream: bool):\n",
    "    model_ids = [\n",
    "        # \"sambanova/Meta-Llama-3.1-8B-Instruct\",\n",
    "        \"sambanova/Meta-Llama-3.1-70B-Instruct\",\n",
    "        \"sambanova/Meta-Llama-3.1-405B-Instruct\",\n",
    "        \"sambanova/Meta-Llama-3.3-70B-Instruct\",\n",
    "    ]\n",
    "\n",
    "    print(\"========== Inference: Text and Tool ==========\")\n",
    "\n",
    "    assert len(model_ids) > 0\n",
    "    for model_id in model_ids:\n",
    "        print(f\">>>>> Sending request to {model_id}\")\n",
    "        iterator = client.inference.chat_completion(\n",
    "            model_id=model_id,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an assistant that can solve quadratic equations given coefficients a, b, and c.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Find all the roots of a quadratic equation given coefficients a = 3, b = -11, and c = -4.\",\n",
    "                },\n",
    "            ],\n",
    "            tools=[\n",
    "                {\n",
    "                    \"tool_name\": \"solve_quadratic\",\n",
    "                    \"description\": \"Solve a quadratic equation given coefficients a, b, and c.\",\n",
    "                    \"parameters\": {\n",
    "                        \"a\": {\n",
    "                            \"param_type\": \"integer\",\n",
    "                            \"description\": \"Coefficient of the squared term.\",\n",
    "                            \"required\": True,\n",
    "                        },\n",
    "                        \"b\": {\n",
    "                            \"param_type\": \"integer\",\n",
    "                            \"description\": \"Coefficient of the linear term.\",\n",
    "                            \"required\": True,\n",
    "                        },\n",
    "                        \"c\": {\"param_type\": \"integer\", \"description\": \"Constant term.\", \"required\": True},\n",
    "                        \"root_type\": {\n",
    "                            \"param_type\": \"string\",\n",
    "                            \"description\": \"Type of roots: 'real' or 'all'.\",\n",
    "                            \"required\": True,\n",
    "                        },\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "            stream=stream,\n",
    "        )\n",
    "\n",
    "        if stream:\n",
    "            print(\"<<<<< Streaming Response\")\n",
    "            for chunk in iterator:\n",
    "                delta = chunk.event.delta\n",
    "                if delta.type == \"tool_call\":\n",
    "                    print(f\"{delta}\")\n",
    "                else:\n",
    "                    print(delta.text)\n",
    "\n",
    "        else:\n",
    "            print(\"<<<<< Non-streaming Response\")\n",
    "            tool_calls = iterator.completion_message.tool_calls\n",
    "            print(tool_calls)\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Inference: Text and Tool ==========\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.1-70B-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "[ToolCall(arguments={'a': 3.0, 'b': -11.0, 'c': -4.0, 'root_type': 'all'}, call_id='call_be8826350ec044c4aa', tool_name='solve_quadratic')]\n",
      "\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.1-405B-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "[ToolCall(arguments={'a': 3.0, 'b': -11.0, 'c': -4.0, 'root_type': 'all'}, call_id='call_30f6d4dcaf9f4c8e8b', tool_name='solve_quadratic')]\n",
      "\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.3-70B-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "[ToolCall(arguments={'a': 3.0, 'b': -11.0, 'c': -4.0, 'root_type': 'all'}, call_id='call_689758dcdb2647be88', tool_name='solve_quadratic')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inference_llm_text_tool(stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Inference: Text and Tool ==========\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.1-70B-Instruct\n",
      "<<<<< Streaming Response\n",
      "\n",
      "ToolCallDelta(parse_status='in_progress', tool_call='{\"a\":3,\"b\":-11,\"c\":-4,\"root_type\":\"all\"}', type='tool_call')\n",
      "\n",
      "ToolCallDelta(parse_status='in_progress', tool_call=')', type='tool_call')\n",
      "ToolCallDelta(parse_status='succeeded', tool_call=ToolCall(arguments={'a': 3.0, 'b': -11.0, 'c': -4.0, 'root_type': 'all'}, call_id='call_5e56e14949404bc99c', tool_name='solve_quadratic'), type='tool_call')\n",
      "\n",
      "\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.1-405B-Instruct\n",
      "<<<<< Streaming Response\n",
      "\n",
      "ToolCallDelta(parse_status='in_progress', tool_call='{\"a\":3,\"b\":-11,\"c\":-4,\"root_type\":\"all\"}', type='tool_call')\n",
      "\n",
      "ToolCallDelta(parse_status='in_progress', tool_call=')', type='tool_call')\n",
      "ToolCallDelta(parse_status='succeeded', tool_call=ToolCall(arguments={'a': 3.0, 'b': -11.0, 'c': -4.0, 'root_type': 'all'}, call_id='call_78b75aa6ce4a47ce8e', tool_name='solve_quadratic'), type='tool_call')\n",
      "\n",
      "\n",
      ">>>>> Sending request to sambanova/Meta-Llama-3.3-70B-Instruct\n",
      "<<<<< Streaming Response\n",
      "\n",
      "ToolCallDelta(parse_status='in_progress', tool_call='{\"a\":3,\"b\":-11,\"c\":-4,\"root_type\":\"all\"}', type='tool_call')\n",
      "\n",
      "ToolCallDelta(parse_status='in_progress', tool_call=')', type='tool_call')\n",
      "ToolCallDelta(parse_status='succeeded', tool_call=ToolCall(arguments={'a': 3.0, 'b': -11.0, 'c': -4.0, 'root_type': 'all'}, call_id='call_bfbff8cb10fd449299', tool_name='solve_quadratic'), type='tool_call')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inference_llm_text_tool(stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference_llm_text_image(stream: bool):\n",
    "    model_ids = [\"sambanova/Llama-3.2-11B-Vision-Instruct\", \"sambanova/Llama-3.2-90B-Vision-Instruct\"]\n",
    "    data_url = data_url_from_image(\"../ai-starter-kit-snova/images/SambaNova-dark-logo-1.png\")\n",
    "\n",
    "    print(\"========== Inference: Text and Image ==========\")\n",
    "\n",
    "    assert len(model_ids) > 0\n",
    "    for model_id in model_ids:\n",
    "        print(f\">>>>> Sending request to {model_id}\")\n",
    "        iterator = client.inference.chat_completion(\n",
    "            model_id=model_id,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": {\"type\": \"image\", \"image\": {\"url\": {\"uri\": data_url}}}},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"How many different colors are in this image?\",\n",
    "                },\n",
    "            ],\n",
    "            stream=stream,\n",
    "        )\n",
    "\n",
    "        if stream:\n",
    "            print(\"<<<<< Streaming Response\")\n",
    "            text = \"\"\n",
    "            for chunk in iterator:\n",
    "                if chunk.event is not None:\n",
    "                    print(f\"{chunk.event.delta.text}\", end=\"\", flush=True)\n",
    "                    text += chunk.event.delta.text\n",
    "\n",
    "            assert text != \"\"\n",
    "            print()\n",
    "        else:\n",
    "            print(\"<<<<< Non-streaming Response\")\n",
    "            print(f\"Type: {type(iterator.completion_message.content)}, Value:{iterator.completion_message.content}\")\n",
    "            assert iterator.completion_message.content != \"\"\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../ai-starter-kit-snova/images/SambaNova-dark-logo-1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_inference_llm_text_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mtest_inference_llm_text_image\u001b[39m\u001b[34m(stream)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_inference_llm_text_image\u001b[39m(stream: \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m      2\u001b[39m     model_ids = [\u001b[33m\"\u001b[39m\u001b[33msambanova/Llama-3.2-11B-Vision-Instruct\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msambanova/Llama-3.2-90B-Vision-Instruct\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     data_url = \u001b[43mdata_url_from_image\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../ai-starter-kit-snova/images/SambaNova-dark-logo-1.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m========== Inference: Text and Image ==========\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model_ids) > \u001b[32m0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mdata_url_from_image\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mime_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCould not determine MIME type of the file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image_file:\n\u001b[32m      7\u001b[39m     encoded_string = base64.b64encode(image_file.read()).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m data_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmime_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoded_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ai-starter-kit/llamastackenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../ai-starter-kit-snova/images/SambaNova-dark-logo-1.png'"
     ]
    }
   ],
   "source": [
    "test_inference_llm_text_image(stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference_llm_image_only(stream: bool):\n",
    "    model_ids = [\"sambanova/Llama-3.2-11B-Vision-Instruct\", \"sambanova/Llama-3.2-11B-Vision-Instruct\"]\n",
    "\n",
    "    data_url = data_url_from_image(\"../../images/SambaNova-dark-logo-1.png\")\n",
    "\n",
    "    print(\"========== Inference: Text and Image ==========\")\n",
    "\n",
    "    assert len(model_ids) > 0\n",
    "    for model_id in model_ids:\n",
    "        print(f\">>>>> Sending request to {model_id}\")\n",
    "        iterator = client.inference.chat_completion(\n",
    "            model_id=model_id,\n",
    "            messages=[{\"role\": \"user\", \"content\": {\"type\": \"image\", \"image\": {\"url\": {\"uri\": data_url}}}}],\n",
    "            stream=stream,\n",
    "        )\n",
    "\n",
    "        if stream:\n",
    "            print(\"<<<<< Streaming Response\")\n",
    "            text = \"\"\n",
    "            for chunk in iterator:\n",
    "                if chunk.event is not None:\n",
    "                    print(f\"{chunk.event.delta.text}\", end=\"\", flush=True)\n",
    "                    text += chunk.event.delta.text\n",
    "\n",
    "            assert text != \"\"\n",
    "            print()\n",
    "        else:\n",
    "            print(\"<<<<< Non-streaming Response\")\n",
    "            print(f\"Type: {type(iterator.completion_message.content)}, Value:{iterator.completion_message.content}\")\n",
    "            assert iterator.completion_message.content != \"\"\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Inference: Text and Image ==========\n",
      ">>>>> Sending request to sambanova/Llama-3.2-11B-Vision-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "Type: <class 'str'>, Value:The image displays the logo for SambaNova Systems, a company that specializes in artificial intelligence (AI) and machine learning (ML) solutions. The logo is prominently displayed in the center of the image.\n",
      "\n",
      "* The logo features the company name \"SambaNova Systems\" in large, bold letters.\n",
      "\t+ The text is in a modern, sans-serif font and is colored in a dark gray or blue-gray hue.\n",
      "\t+ The word \"SambaNova\" is written in a larger size than the word \"Systems\".\n",
      "* To the left of the company name is a stylized letter \"S\" made up of curved lines.\n",
      "\t+ The letter \"S\" is orange in color and has a smooth, flowing design.\n",
      "\t+ The curved lines of the letter \"S\" are reminiscent of a wave or a spiral, suggesting movement and energy.\n",
      "* The background of the image is a solid gray color.\n",
      "\t+ The gray tone is a medium-light gray, providing a neutral and clean backdrop for the logo.\n",
      "\n",
      "Overall, the logo effectively communicates the company's focus on AI and ML while also conveying a sense of modernity and innovation. The use of a stylized letter \"S\" adds a touch of creativity and visual interest to the design.\n",
      "\n",
      ">>>>> Sending request to sambanova/Llama-3.2-11B-Vision-Instruct\n",
      "<<<<< Non-streaming Response\n",
      "Type: <class 'str'>, Value:The image displays the logo for SambaNova Systems, a company that specializes in artificial intelligence (AI) and machine learning (ML) solutions. The logo is prominently displayed in the center of the image.\n",
      "\n",
      "* The logo features the company name \"SambaNova Systems\" in large, bold letters.\n",
      "\t+ The text is in a modern, sans-serif font and is colored in a dark gray or blue-gray hue.\n",
      "\t+ The word \"SambaNova\" is written in a larger size than the word \"Systems\".\n",
      "* To the left of the company name is a stylized letter \"S\" made up of curved lines.\n",
      "\t+ The letter \"S\" is orange in color and has a smooth, flowing design.\n",
      "\t+ The curved lines of the letter \"S\" are reminiscent of a wave or a spiral, suggesting movement and energy.\n",
      "* The background of the image is a solid gray color.\n",
      "\t+ The gray tone is a medium-light gray, providing a neutral and clean backdrop for the logo.\n",
      "\n",
      "Overall, the logo effectively communicates the company's focus on AI and ML while also conveying a sense of modernity and innovation. The use of a stylized letter \"S\" adds a touch of creativity and visual interest to the design.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inference_llm_image_only(stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Inference: Text and Image ==========\n",
      ">>>>> Sending request to sambanova/Llama-3.2-11B-Vision-Instruct\n",
      "<<<<< Streaming Response\n",
      "The image displays the logo for SambaNova Systems, a company that specializes in artificial intelligence (AI) and machine learning (ML) solutions. The logo is prominently displayed in the center of the image.\n",
      "\n",
      "* The logo features the company name \"SambaNova Systems\" in large, bold letters.\n",
      "\t+ The text is in a modern, sans-serif font and is colored in a dark gray or blue-gray hue.\n",
      "\t+ The word \"SambaNova\" is written in a larger size than the word \"Systems\".\n",
      "* To the left of the company name is a stylized letter \"S\" made up of curved lines.\n",
      "\t+ The letter \"S\" is orange in color and has a smooth, flowing design.\n",
      "\t+ The curved lines of the letter \"S\" are reminiscent of a wave or a spiral, suggesting movement and energy.\n",
      "* The background of the image is a solid gray color.\n",
      "\t+ The gray tone is a medium-light gray, providing a neutral and clean backdrop for the logo.\n",
      "\n",
      "Overall, the logo effectively communicates the company's focus on AI and ML while also conveying a sense of modernity and innovation. The use of a stylized letter \"S\" adds a touch of creativity and visual interest to the design.\n",
      "\n",
      ">>>>> Sending request to sambanova/Llama-3.2-11B-Vision-Instruct\n",
      "<<<<< Streaming Response\n",
      "The image displays the logo for SambaNova Systems, a company that specializes in artificial intelligence (AI) and machine learning (ML) solutions. The logo is prominently displayed in the center of the image.\n",
      "\n",
      "* The logo features the company name \"SambaNova Systems\" in large, bold letters.\n",
      "\t+ The text is in a modern, sans-serif font and is colored in a dark gray or blue-gray hue.\n",
      "\t+ The word \"SambaNova\" is written in a larger size than the word \"Systems\".\n",
      "* To the left of the company name is a stylized letter \"S\" made up of curved lines.\n",
      "\t+ The letter \"S\" is orange in color and has a smooth, flowing design.\n",
      "\t+ The curved lines of the letter \"S\" are reminiscent of a wave or a spiral, suggesting movement and energy.\n",
      "* The background of the image is a solid gray color.\n",
      "\t+ The gray tone is a medium-light gray, providing a neutral and clean backdrop for the logo.\n",
      "\n",
      "Overall, the logo effectively communicates the company's focus on AI and ML while also conveying a sense of modernity and innovation. The use of a stylized letter \"S\" adds a touch of creativity and visual interest to the design.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inference_llm_image_only(stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference_safety_text_only(stream: bool):\n",
    "    model_ids = list_models()\n",
    "    print(\"========== Safety on Inference: Text Only ==========\")\n",
    "    assert len(model_ids) > 0\n",
    "    for model_id in model_ids:\n",
    "        if \"guard\" in model_id.lower() and \"sambanova\" in model_id.lower():\n",
    "            print(f\">>>>> Sending request to {model_id}\")\n",
    "            iterator = client.inference.chat_completion(\n",
    "                model_id=model_id, messages=[{\"role\": \"user\", \"content\": \"Write a haiku on llamas\"}], stream=stream\n",
    "            )\n",
    "\n",
    "            if stream:\n",
    "                print(\"<<<<< Streaming Response\")\n",
    "                text = \"\"\n",
    "                for chunk in iterator:\n",
    "                    if chunk.event is not None:\n",
    "                        print(f\"{chunk.event.delta.text}\", end=\"\", flush=True)\n",
    "                        text += chunk.event.delta.text\n",
    "\n",
    "                assert text != \"\"\n",
    "                print()\n",
    "            else:\n",
    "                print(\"<<<<< Non-streaming Response\")\n",
    "                print(f\"Type: {type(iterator.completion_message.content)}, Value:{iterator.completion_message.content}\")\n",
    "                assert iterator.completion_message.content != \"\"\n",
    "\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Safety on Inference: Text Only ==========\n",
      ">>>>> Sending request to sambanova/Meta-Llama-Guard-3-8B\n",
      "<<<<< Non-streaming Response\n",
      "Type: <class 'str'>, Value:\n",
      "\n",
      "safe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inference_safety_text_only(stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Safety on Inference: Text Only ==========\n",
      ">>>>> Sending request to sambanova/Meta-Llama-Guard-3-8B\n",
      "<<<<< Streaming Response\n",
      "\n",
      "\n",
      "safe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inference_safety_text_only(stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_text_safety():\n",
    "    model_ids = [\n",
    "        # \"Meta-Llama-Guard-3-8B\",\n",
    "        \"sambanova/meta-llama/Llama-Guard-3-8B\"\n",
    "    ]\n",
    "\n",
    "    print(\"========== Safety:Text Only ==========\")\n",
    "\n",
    "    assert len(model_ids) > 0\n",
    "    for model_id in model_ids:\n",
    "        print(f\">>>>> Sending request to {model_id}\")\n",
    "        iterator = client.safety.run_shield(\n",
    "            shield_id=model_id, messages=[{\"role\": \"user\", \"content\": \"how to make a gun\"}], params={}\n",
    "        )\n",
    "\n",
    "        print(\" Response\")\n",
    "        print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Safety:Text Only ==========\n",
      ">>>>> Sending request to meta-llama/Llama-Guard-3-8B\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 500 - {'detail': 'Internal server error: An unexpected error occurred.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalServerError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_text_safety\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtest_text_safety\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_id \u001b[38;5;129;01min\u001b[39;00m model_ids:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>>>>> Sending request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     iterator = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafety\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_shield\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshield_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhow to make a gun\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m Response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(iterator)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ai-starter-kit/llamastackenv/lib/python3.11/site-packages/llama_stack_client/resources/safety.py:73\u001b[39m, in \u001b[36mSafetyResource.run_shield\u001b[39m\u001b[34m(self, messages, params, shield_id, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_shield\u001b[39m(\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     52\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m     62\u001b[39m ) -> RunShieldResponse:\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[33;03m      extra_headers: Send extra headers\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/safety/run-shield\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparams\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshield_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mshield_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m            \u001b[49m\u001b[43msafety_run_shield_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSafetyRunShieldParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRunShieldResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ai-starter-kit/llamastackenv/lib/python3.11/site-packages/llama_stack_client/_base_client.py:1225\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1211\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1212\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1213\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1220\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1221\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1222\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1223\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1224\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ai-starter-kit/llamastackenv/lib/python3.11/site-packages/llama_stack_client/_base_client.py:917\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    914\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    915\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ai-starter-kit/llamastackenv/lib/python3.11/site-packages/llama_stack_client/_base_client.py:1005\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1003\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1004\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1005\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ai-starter-kit/llamastackenv/lib/python3.11/site-packages/llama_stack_client/_base_client.py:1054\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1052\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ai-starter-kit/llamastackenv/lib/python3.11/site-packages/llama_stack_client/_base_client.py:1005\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1003\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1004\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1005\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ai-starter-kit/llamastackenv/lib/python3.11/site-packages/llama_stack_client/_base_client.py:1054\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1052\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ai-starter-kit/llamastackenv/lib/python3.11/site-packages/llama_stack_client/_base_client.py:1020\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1017\u001b[39m         err.response.read()\n\u001b[32m   1019\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1020\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1022\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1023\u001b[39m     cast_to=cast_to,\n\u001b[32m   1024\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1028\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1029\u001b[39m )\n",
      "\u001b[31mInternalServerError\u001b[39m: Error code: 500 - {'detail': 'Internal server error: An unexpected error occurred.'}"
     ]
    }
   ],
   "source": [
    "test_text_safety()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG example\n",
    "import uuid\n",
    "from termcolor import cprint\n",
    "from llama_stack_client.types import Document\n",
    "from llama_stack_client.lib.agents.agent import Agent\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "\n",
    "urls = [\"chat.rst\", \"llama3.rst\", \"memory_optimizations.rst\", \"lora_finetune.rst\"]\n",
    "documents = [\n",
    "    Document(\n",
    "        document_id=f\"num-{i}\",\n",
    "        content=f\"https://raw.githubusercontent.com/pytorch/torchtune/main/docs/source/tutorials/{url}\",\n",
    "        mime_type=\"text/plain\",\n",
    "        metadata={},\n",
    "    )\n",
    "    for i, url in enumerate(urls)\n",
    "]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_providers = [provider for provider in client.providers.list() if provider.api == \"vector_io\"]\n",
    "print(vector_providers)\n",
    "provider_id = vector_providers[0].provider_id  # Use the first available vector provider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a vector database\n",
    "vector_db_id = f\"test-vector-db-{uuid.uuid4().hex}\"\n",
    "client.vector_dbs.register(\n",
    "    vector_db_id=vector_db_id,\n",
    "    provider_id=provider_id,\n",
    "    embedding_model=\"all-MiniLM-L6-v2\",\n",
    "    embedding_dimension=384,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the documents into the vector database\n",
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=documents,\n",
    "    vector_db_id=vector_db_id,\n",
    "    chunk_size_in_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_agent = Agent(\n",
    "    client,\n",
    "    model=\"sambanova/Meta-Llama-3.3-70B-Instruct\",\n",
    "    # Define instructions for the agent ( aka system prompt)\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    enable_session_persistence=False,\n",
    "    # Define tools available to the agent\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"builtin::rag/knowledge_search\",\n",
    "            \"args\": {\n",
    "                \"vector_db_ids\": [vector_db_id],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = rag_agent.create_session(\"test-session\")\n",
    "\n",
    "user_prompts = [\n",
    "    \"How to optimize memory usage in torchtune? use the knowledge_search tool to get information.\",\n",
    "]\n",
    "\n",
    "# Run the agent loop by calling the `create_turn` method\n",
    "for prompt in user_prompts:\n",
    "    cprint(f\"User> {prompt}\", \"green\")\n",
    "    response = rag_agent.create_turn(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        session_id=session_id,\n",
    "    )\n",
    "    for log in EventLogger().log(response):\n",
    "        log.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple react agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client.types.agent_create_params import AgentConfig\n",
    "\n",
    "\n",
    "# Example tool definition\n",
    "def get_weather(city: str) -> int:\n",
    "    \"\"\"\n",
    "    Runs get weather tool.\n",
    "    returns the temperature in celius\n",
    "    :param city: city\n",
    "    \"\"\"\n",
    "    return 26\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=\"sambanova/Meta-Llama-3.1-70B-Instruct\",\n",
    "    instructions=\"You are a helpful assistant. Use the tools you have access to for providing relevant answers\",\n",
    "    sampling_params={\n",
    "        \"strategy\": {\"type\": \"top_p\", \"temperature\": 1.0, \"top_p\": 0.9},\n",
    "    },\n",
    "    tools=[get_weather],\n",
    "    # input_shields=available_shields if available_shields else [],\n",
    "    # output_shields=available_shields if available_shields else [],\n",
    "    enable_session_persistence=False,\n",
    ")\n",
    "\n",
    "\n",
    "response = agent.create_turn(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"how is the weather in paris?\"}],\n",
    "    session_id=agent.create_session(\"tool_session\"),\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# print(response.output_message.content)\n",
    "for event in response:\n",
    "    print(event)\n",
    "    if event.event.payload.event_type == \"turn_complete\":\n",
    "        print(\"#####\")\n",
    "        print(event.event.payload.turn.output_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
