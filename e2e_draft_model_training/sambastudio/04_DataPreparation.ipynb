{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import os\n",
    "import sys\n",
    "from datasets import load_dataset\n",
    "import yaml\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir =  os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from utils.fine_tuning.src import sambastudio_utils\n",
    "from utils.fine_tuning.src.snsdk_wrapper import SnsdkWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SambaNova SDK SambaStudio client\n",
    "sambastudio_client = SnsdkWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the target model config\n",
    "config_target_yaml = '../01_config_target.yaml'\n",
    "\n",
    "# Open and load the YAML file into a dictionary\n",
    "with open(config_target_yaml, 'r') as file:\n",
    "    config_target = yaml.safe_load(file)\n",
    "pprint('Target model:')\n",
    "pprint(config_target)\n",
    "\n",
    "# Load the data generation config\n",
    "config_data_preparation = '../04_config_data_preparation.yaml'\n",
    "\n",
    "# Open and load the YAML file into a dictionary\n",
    "with open(config_data_preparation, 'r') as file:\n",
    "    config_data_preparation = yaml.safe_load(file)\n",
    "pprint('Dataset preparation:')\n",
    "pprint(config_data_preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select your training dataset\n",
    "You can use your own dataset (see [synthetic data generation util](../synthetic_data_gen/notebooks/quickstart_synthetic_data_gen.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset\n",
    "\n",
    "To upload a dataset to SambaStudio we need first to convert it to a suitable format (hdf5), for this we will use the generative data prep utility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data_preparation['files']['input_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_dataset_path = sambastudio_utils.gen_data_prep_pipeline(\n",
    "    input_files = kit_dir + '/' + config_data_preparation['files']['input_files'],\n",
    "    output_path = kit_dir + '/' +  config_data_preparation['files']['output_path'],\n",
    "    tokenizer = config_data_preparation['target_model']['hf_name'], # use the tokenizer of the model to train with\n",
    "    max_seq_length = config_data_preparation['target_model']['max_seq_length'],\n",
    "    shuffle = 'on_RAM',\n",
    "    input_packing_config = 'single::truncate_right', \n",
    "    prompt_keyword = 'prompt',\n",
    "    completion_keyword = 'completion',\n",
    "    num_training_splits = 8,\n",
    "    apply_chat_template = False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find more details about the gen data prep parameters [here](https://github.com/sambanova/generative_data_prep?tab=readme-ov-file#flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataset configs\n",
    "\n",
    "Some parameter should be provided to upload a previously created checkpoint, for this we will keep these parameters in a dataset dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'dataset_path': hdf5_dataset_path,\n",
    "    'dataset_name': config_data_preparation['dataset']['dataset_name'],\n",
    "    'dataset_description': 'This dataset contains question and answer pairs sourced from Q&A pages and FAQs from CDC and WHO pertaining to COVID-19',\n",
    "    'dataset_job_types': [\"evaluation\", \"train\"],\n",
    "    'dataset_source_type': 'localMachine',\n",
    "    'dataset_language': 'english',\n",
    "    'dataset_filetype': 'hdf5',\n",
    "    'dataset_url': \"https://dummy_url\",\n",
    "    'dataset_metadata':{}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should indicate for which apps the uploaded dataset will be available, if not sure you can list all the aps in SambaStudio ans select those you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliable_apps = sambastudio_client.list_apps()\n",
    "avaliable_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case we will train a llama3 model so wi will include all the llama3 apps\n",
    "llama3_apps=[app['name'] for app in avaliable_apps if 'llama3' in app['name'].replace(' ','').lower()]\n",
    "dataset['dataset_apps_availability'] = llama3_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see here all the parameters required to upload the dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Dataset to SambaStudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the create dataset method from client with dataset parameters (this can take a while)\n",
    "sambastudio_client.create_dataset(\n",
    "    dataset_path = dataset['dataset_path'],\n",
    "    dataset_name = dataset['dataset_name'],\n",
    "    dataset_description = dataset['dataset_description'],\n",
    "    dataset_job_types = dataset['dataset_job_types'],\n",
    "    dataset_source_type = dataset['dataset_source_type'],\n",
    "    dataset_language = dataset['dataset_language'],\n",
    "    dataset_url = dataset['dataset_url'],\n",
    "    dataset_apps_availability = dataset['dataset_apps_availability'],\n",
    "    dataset_filetype = dataset['dataset_filetype'],\n",
    "    dataset_metadata = dataset['dataset_metadata']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataset is now in SambaStudio environment\n",
    "sambastudio_client.list_datasets()[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
