{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Draft Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "import yaml\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir =  os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from utils.fine_tuning.src.snsdk_wrapper import SnsdkWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by Step / Manual setting\n",
    "\n",
    "First instantiate the SambaStudio client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 23:38:51,871 [INFO] Using variables from .snapi config to set up Snsdk.\n"
     ]
    }
   ],
   "source": [
    "sambastudio_client = SnsdkWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Draft model training:'\n",
      "{'dataset': {'dataset_description': 'xxx', 'dataset_name': 'dummy_example'},\n",
      " 'model_checkpoint': {'checkpoint_name': '',\n",
      "                      'model_description': 'The Meta Llama 3.1 collection of '\n",
      "                                           'multilingual large language models '\n",
      "                                           '(LLMs) is a collection of '\n",
      "                                           'pretrained and instruction tuned '\n",
      "                                           'generative models in 8B, 70B and '\n",
      "                                           '405B sizes (text in/text out).',\n",
      "                      'model_name': 'meta-llama-3.1-8b-instruct',\n",
      "                      'model_type': 'finetuned'},\n",
      " 'project': {'project_description': 'This project will be used to test the E2E '\n",
      "                                    'Draft Model Training pipeline '\n",
      "                                    'implementation.',\n",
      "             'project_name': 'e2e-draft-model-training-project'},\n",
      " 'sambastudio': {'rdu_arch': 'SN40L-8', 'snapi_path': ''}}\n"
     ]
    }
   ],
   "source": [
    "# Load the data generation config\n",
    "config_draft_model_training_yaml = '../05_config_draft_model_training.yaml'\n",
    "\n",
    "# Open and load the YAML file into a dictionary\n",
    "with open(config_draft_model_training_yaml, 'r') as file:\n",
    "    config_draft_model_training = yaml.safe_load(file)\n",
    "pprint('Draft model training:')\n",
    "pprint(config_draft_model_training)\n",
    "\n",
    "model_name = config_draft_model_training['model_checkpoint']['model_name']\n",
    "dataset_name = config_draft_model_training['dataset']['dataset_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = [model[\"model_checkpoint_name\"]for model in sambastudio_client.list_models(filter_job_types=[\"train\"])]\n",
    "\n",
    "assert model_name in available_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dataset_name in [dataset[\"dataset_name\"] for dataset in sambastudio_client.list_datasets()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Project configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = {\n",
    "    'project_name': config_draft_model_training['project']['project_name'],\n",
    "    'project_description': config_draft_model_training['project']['project_description']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 23:38:58,020 [INFO] Project with name 'e2e-draft-model-training-project' found with id 0b4bf4f5-5e29-409c-8a40-7a2e4183ec95\n",
      "2025-04-02 23:38:58,020 [INFO] Project with name 'e2e-draft-model-training-project' already exists with id '0b4bf4f5-5e29-409c-8a40-7a2e4183ec95', using it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0b4bf4f5-5e29-409c-8a40-7a2e4183ec95'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the create project method from client with project parameters\n",
    "sambastudio_client.create_project(\n",
    "    project_name = project['project_name'],\n",
    "    project_description = project['project_description']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set train job config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 23:38:59,390 [INFO] Default Hyperparameters for train in SN40L-8 for meta-llama-3.1-8b-instruct: \n",
      "\n",
      "                    ['batch_size:`8`', 'debug_mode:`off`', 'do_eval:`false`', 'dump_inputs:`false`', 'eval_steps:`50`', 'evaluation_strategy:`no`', 'fix_rank_rdu_mapping:`false`', 'grad_accumulation_steps:`1`', 'learning_rate:`1.0e-05`', 'logging_steps:`1`', 'lr_schedule:`fixed_lr`', 'max_seq_length:`8192`', 'model_parallel_rdus:`1`', 'model_parameter_count:`8b`', 'num_iterations:`100`', 'prompt_loss_weight:`0.0`', 'run_mode:`balanced`', 'safe_mode:`off`', 'save_optimizer_state:`true`', 'save_steps:`50`', 'skip_checkpoint:`false`', 'subsample_eval:`0.01`', 'subsample_eval_seed:`123`', 'use_token_type_ids:`true`', 'vocab_size:`128256`', 'warmup_steps:`0`', 'weight_decay:`0.1`']\n",
      "\n",
      "                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SN40L-8': [{'constrains': None,\n",
      "              'description': 'The per-worker batch size',\n",
      "              'field_name': 'batch_size',\n",
      "              'settings': {'DEFAULT': '8', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': ['on', 'off']},\n",
      "              'description': \"Toggles debug mode. Debug mode 'on' persists \"\n",
      "                             'logs to the RDU host to help diagnose certain '\n",
      "                             'issues during training.',\n",
      "              'field_name': 'debug_mode',\n",
      "              'settings': {'DEFAULT': 'off', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': ['true', 'false']},\n",
      "              'description': 'whether or not to do final evaluation',\n",
      "              'field_name': 'do_eval',\n",
      "              'settings': {'DEFAULT': 'false', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': ['true', 'false']},\n",
      "              'description': 'Dump input to a file for debugging purposes. '\n",
      "                             'Creates several MB of data per step and slows '\n",
      "                             'down training; should only be used if requested '\n",
      "                             'by Sambanova to collect debug information.',\n",
      "              'field_name': 'dump_inputs',\n",
      "              'settings': {'DEFAULT': 'false', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '1',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': []},\n",
      "              'description': 'Period of evaluating the model in number of '\n",
      "                             'training steps. This parameter is only effective '\n",
      "                             \"when evaluation_strategy is set to 'steps'.\",\n",
      "              'field_name': 'eval_steps',\n",
      "              'settings': {'DEFAULT': '50', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': ['no', 'steps', 'epoch']},\n",
      "              'description': 'Strategy to validate the model during training',\n",
      "              'field_name': 'evaluation_strategy',\n",
      "              'settings': {'DEFAULT': 'no', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': ['true', 'false']},\n",
      "              'description': 'Fix which rank is assigned to which RDU for '\n",
      "                             'data-parallel jobs. Used for reproducibility of '\n",
      "                             'a job. Should only be used with a multiple of 8 '\n",
      "                             'RDUs.',\n",
      "              'field_name': 'fix_rank_rdu_mapping',\n",
      "              'settings': {'DEFAULT': 'false', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '1',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': []},\n",
      "              'description': 'How many steps you want to accumulate before '\n",
      "                             'updating the weights. This parameter can be used '\n",
      "                             'to increase the effective batch size during '\n",
      "                             'gradient decent without exceeding the memory '\n",
      "                             'limit.',\n",
      "              'field_name': 'grad_accumulation_steps',\n",
      "              'settings': {'DEFAULT': '1', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '0',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': []},\n",
      "              'description': 'learning rate to use in optimizer',\n",
      "              'field_name': 'learning_rate',\n",
      "              'settings': {'DEFAULT': '1.0e-05', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '1',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': []},\n",
      "              'description': 'Period of logging training loss in number of '\n",
      "                             'training steps',\n",
      "              'field_name': 'logging_steps',\n",
      "              'settings': {'DEFAULT': '1', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': ['polynomial_decay_schedule_with_warmup',\n",
      "                                        'cosine_schedule_with_warmup',\n",
      "                                        'fixed_lr']},\n",
      "              'description': 'Type of learning rate scheduler to use',\n",
      "              'field_name': 'lr_schedule',\n",
      "              'settings': {'DEFAULT': 'fixed_lr', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': None,\n",
      "              'description': 'Sequence length to pad or truncate the dataset',\n",
      "              'field_name': 'max_seq_length',\n",
      "              'settings': {'DEFAULT': '8192', 'USER_MODIFIABLE': False}},\n",
      "             {'constrains': None,\n",
      "              'description': 'The number of RDUs to run in model parallel.',\n",
      "              'field_name': 'model_parallel_rdus',\n",
      "              'settings': {'DEFAULT': '1', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': None,\n",
      "              'description': 'The parameter count of the model',\n",
      "              'field_name': 'model_parameter_count',\n",
      "              'settings': {'DEFAULT': '8b', 'USER_MODIFIABLE': False}},\n",
      "             {'constrains': {'ge': '1',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': []},\n",
      "              'description': 'number of iterations to run',\n",
      "              'field_name': 'num_iterations',\n",
      "              'settings': {'DEFAULT': '100', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '0',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': []},\n",
      "              'description': 'Loss scale for prompt tokens',\n",
      "              'field_name': 'prompt_loss_weight',\n",
      "              'settings': {'DEFAULT': '0.0', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': None,\n",
      "              'description': 'The mode to run with.',\n",
      "              'field_name': 'run_mode',\n",
      "              'settings': {'DEFAULT': 'balanced', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': None,\n",
      "              'description': 'Toggles safe mode. Safe mode \"on\" runs the job '\n",
      "                             'more conservatively from a power perspective. '\n",
      "                             'This causes the job to run at lower performance '\n",
      "                             '(i.e. fewer steps per second) in exchange for '\n",
      "                             'more robust operation.',\n",
      "              'field_name': 'safe_mode',\n",
      "              'settings': {'DEFAULT': 'off', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': ['true', 'false']},\n",
      "              'description': 'Whether to save the optimizer state when saving '\n",
      "                             'a checkpoint',\n",
      "              'field_name': 'save_optimizer_state',\n",
      "              'settings': {'DEFAULT': 'true', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '1',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': []},\n",
      "              'description': 'Period of saving the model checkpoints in number '\n",
      "                             'of training steps',\n",
      "              'field_name': 'save_steps',\n",
      "              'settings': {'DEFAULT': '50', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': ['true', 'false']},\n",
      "              'description': 'whether or not to skip the checkpoint',\n",
      "              'field_name': 'skip_checkpoint',\n",
      "              'settings': {'DEFAULT': 'false', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '0',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': []},\n",
      "              'description': 'Subsample for the evaluation dataset',\n",
      "              'field_name': 'subsample_eval',\n",
      "              'settings': {'DEFAULT': '0.01', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '1',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': []},\n",
      "              'description': 'Random seed to use for the subsample evaluation',\n",
      "              'field_name': 'subsample_eval_seed',\n",
      "              'settings': {'DEFAULT': '123', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': ['true', 'false']},\n",
      "              'description': 'Whether to use token_type_ids to compute loss',\n",
      "              'field_name': 'use_token_type_ids',\n",
      "              'settings': {'DEFAULT': 'true', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': None,\n",
      "              'description': 'Maximum size of vocabulary',\n",
      "              'field_name': 'vocab_size',\n",
      "              'settings': {'DEFAULT': '128256', 'USER_MODIFIABLE': False}},\n",
      "             {'constrains': {'ge': '0',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': []},\n",
      "              'description': 'warmup steps to use in learning rate scheduler '\n",
      "                             'in optimizer',\n",
      "              'field_name': 'warmup_steps',\n",
      "              'settings': {'DEFAULT': '0', 'USER_MODIFIABLE': True}},\n",
      "             {'constrains': {'ge': '0',\n",
      "                             'gt': '',\n",
      "                             'le': '',\n",
      "                             'lt': '',\n",
      "                             'values': []},\n",
      "              'description': 'weight decay rate to use in optimizer',\n",
      "              'field_name': 'weight_decay',\n",
      "              'settings': {'DEFAULT': '0.1', 'USER_MODIFIABLE': True}}]}\n"
     ]
    }
   ],
   "source": [
    "# check required hyperparams for training job \n",
    "hyperparams = sambastudio_client.get_default_hyperparms(model,'train')\n",
    "pprint(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = {\n",
    "    'job_name': 'e2e_draft_model_training_job',\n",
    "    'job_description': 'dummy_description',\n",
    "    'job_type': 'train',\n",
    "    'model': model_name,\n",
    "    'model_version': '1',\n",
    "    'parallel_instances': '1',\n",
    "    'dataset_name': dataset_name,\n",
    "    'load_state': False,\n",
    "    'sub_path': '',\n",
    "    'hyperparams': {\n",
    "        \"batch_size\": 8,\n",
    "        \"do_eval\": False,\n",
    "        \"eval_steps\":50,\n",
    "        \"evaluation_strategy\": \"no\",\n",
    "        \"learning_rate\": 0.00001,\n",
    "        \"logging_steps\": 1,\n",
    "        \"lr_schedule\": \"fixed_lr\",\n",
    "        \"max_sequence_length\": 8192,\n",
    "        \"num_iterations\": 100,\n",
    "        \"prompt_loss_weight\": 0.0,\n",
    "        \"save_optimizer_state\": True,\n",
    "        \"save_steps\": 50,\n",
    "        \"skip_checkpoint\": False,\n",
    "        \"subsample_eval\": 0.01,\n",
    "        \"subsample_eval_seed\": 123,\n",
    "        \"use_token_type_ids\": True,\n",
    "        \"vocab_size\": 128256,\n",
    "        \"warmup_steps\": 0,\n",
    "        \"weight_decay\": 0.1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 23:39:08,832 [INFO] Project with name 'e2e-draft-model-training-project' found with id 0b4bf4f5-5e29-409c-8a40-7a2e4183ec95\n",
      "2025-04-02 23:39:12,076 [INFO] Model 'meta-llama-3.1-8b-instruct' with id 'd5b59dcf-84db-4f84-a1de-077b217f9b49' available for training and deployment found\n",
      "2025-04-02 23:39:12,312 [INFO] Dataset with name 'dummy_example' found with id a77fc17c-5a75-4e41-98f7-35f1f509bd04\n",
      "2025-04-02 23:39:12,527 [ERROR] Failed to create job with name 'e2e_draft_model_training_job'. Details: {'code': 3, 'message': 'Job with e2e_draft_model_training_job name already exists in project 0b4bf4f5-5e29-409c-8a40-7a2e4183ec95', 'details': [], 'status_code': 400, 'headers': {'access-control-allow-headers': 'Accept, Content-Type, Content-Length, Accept-Encoding, Authorization, ResponseType, Access-Control-Allow-Origin', 'access-control-allow-methods': 'GET, POST, PATCH, DELETE', 'access-control-allow-origin': 'https://sjc3-demo2.sambanova.net', 'content-security-policy': \"default-src 'self'\", 'content-type': 'application/json,application/grpc', 'permissions-policy': 'none', 'referrer-policy': 'no-referrer', 'strict-transport-security': 'max-age=31536000; includeSubDomains, max-age=31536000; includeSubDomains', 'x-content-type-options': 'nosniff', 'x-correlation-id': '39cf5f06-d0c0-484c-8b4c-e4c80860e415', 'x-frame-options': 'DENY', 'date': 'Wed, 02 Apr 2025 22:39:12 GMT', 'content-length': '141', 'x-envoy-upstream-service-time': '60', 'server': 'istio-envoy'}}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error message: {'code': 3, 'message': 'Job with e2e_draft_model_training_job name already exists in project 0b4bf4f5-5e29-409c-8a40-7a2e4183ec95', 'details': [], 'status_code': 400, 'headers': {'access-control-allow-headers': 'Accept, Content-Type, Content-Length, Accept-Encoding, Authorization, ResponseType, Access-Control-Allow-Origin', 'access-control-allow-methods': 'GET, POST, PATCH, DELETE', 'access-control-allow-origin': 'https://sjc3-demo2.sambanova.net', 'content-security-policy': \"default-src 'self'\", 'content-type': 'application/json,application/grpc', 'permissions-policy': 'none', 'referrer-policy': 'no-referrer', 'strict-transport-security': 'max-age=31536000; includeSubDomains, max-age=31536000; includeSubDomains', 'x-content-type-options': 'nosniff', 'x-correlation-id': '39cf5f06-d0c0-484c-8b4c-e4c80860e415', 'x-frame-options': 'DENY', 'date': 'Wed, 02 Apr 2025 22:39:12 GMT', 'content-length': '141', 'x-envoy-upstream-service-time': '60', 'server': 'istio-envoy'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msambastudio_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_training_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproject_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjob_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjob_description\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjob_description\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjob_type\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjob_type\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_version\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel_version\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparallel_instances\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mparallel_instances\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_state\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mload_state\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43msub_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msub_path\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrdu_arch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSN40L-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhyperparams\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ai-starter-kit/utils/fine_tuning/src/snsdk_wrapper.py:1306\u001b[39m, in \u001b[36mSnsdkWrapper.run_training_job\u001b[39m\u001b[34m(self, project_name, job_name, job_description, job_type, model, model_version, dataset_name, parallel_instances, load_state, sub_path, rdu_arch, hyperparams)\u001b[39m\n\u001b[32m   1304\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1305\u001b[39m     logging.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to create job with name \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Details: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcreate_job_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1306\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mError message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcreate_job_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mException\u001b[39m: Error message: {'code': 3, 'message': 'Job with e2e_draft_model_training_job name already exists in project 0b4bf4f5-5e29-409c-8a40-7a2e4183ec95', 'details': [], 'status_code': 400, 'headers': {'access-control-allow-headers': 'Accept, Content-Type, Content-Length, Accept-Encoding, Authorization, ResponseType, Access-Control-Allow-Origin', 'access-control-allow-methods': 'GET, POST, PATCH, DELETE', 'access-control-allow-origin': 'https://sjc3-demo2.sambanova.net', 'content-security-policy': \"default-src 'self'\", 'content-type': 'application/json,application/grpc', 'permissions-policy': 'none', 'referrer-policy': 'no-referrer', 'strict-transport-security': 'max-age=31536000; includeSubDomains, max-age=31536000; includeSubDomains', 'x-content-type-options': 'nosniff', 'x-correlation-id': '39cf5f06-d0c0-484c-8b4c-e4c80860e415', 'x-frame-options': 'DENY', 'date': 'Wed, 02 Apr 2025 22:39:12 GMT', 'content-length': '141', 'x-envoy-upstream-service-time': '60', 'server': 'istio-envoy'}}"
     ]
    }
   ],
   "source": [
    "sambastudio_client.run_training_job(\n",
    "    project_name = project[\"project_name\"],\n",
    "    job_name = job['job_name'],\n",
    "    job_description = job['job_description'],\n",
    "    job_type = job['job_type'],\n",
    "    model = job['model'],\n",
    "    model_version = job['model_version'],\n",
    "    dataset_name = job['dataset_name'],\n",
    "    parallel_instances = job['parallel_instances'],\n",
    "    load_state = job['load_state'],\n",
    "    sub_path = job['sub_path'],\n",
    "    rdu_arch = 'SN40L-8',\n",
    "    hyperparams = job['hyperparams']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 23:39:17,644 [INFO] Project with name 'e2e-draft-model-training-project' found with id 0b4bf4f5-5e29-409c-8a40-7a2e4183ec95\n",
      "2025-04-02 23:39:17,885 [INFO] Project with name 'e2e-draft-model-training-project' found with id 0b4bf4f5-5e29-409c-8a40-7a2e4183ec95\n",
      "2025-04-02 23:39:18,126 [INFO] Job with name 'e2e_draft_model_training_job' in project 'e2e-draft-model-training-project' found with id '63757c29-244e-48da-9972-dc9256edc474'\n",
      "2025-04-02 23:39:18,402 [INFO] Job `e2e_draft_model_training_job` with progress status: TRAINING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': '63757c29-244e-48da-9972-dc9256edc474',\n",
       " 'job_name': 'e2e_draft_model_training_job',\n",
       " 'job_type': 'train',\n",
       " 'user_id': 'francesca.raimondi',\n",
       " 'project_id': '0b4bf4f5-5e29-409c-8a40-7a2e4183ec95',\n",
       " 'tenant_id': 'cf1dd082-103d-4236-b3f2-ca792d73b77d',\n",
       " 'rdu_arch': 'SN40L-8',\n",
       " 'result_path': '',\n",
       " 'parallel_instances': 1,\n",
       " 'app_id': '45c7e5b8-2c12-45c3-aecc-713dded73b8f',\n",
       " 'model_checkpoint': 'meta-llama-3.1-8b-instruct',\n",
       " 'checkpoint_id': '',\n",
       " 'dataset_id': 'a77fc17c-5a75-4e41-98f7-35f1f509bd04',\n",
       " 'description': 'dummy_description',\n",
       " 'status': 'TRAINING',\n",
       " 'image_version': '',\n",
       " 'variant_set_version': '',\n",
       " 'variant_name': '',\n",
       " 'project_name': '',\n",
       " 'dataset_name': '',\n",
       " 'input_data_path': '',\n",
       " 'hyperparams': [{'DATATYPE': '',\n",
       "   'DESCRIPTION': 'The per-worker batch size',\n",
       "   'FIELD_NAME': 'batch_size',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '8'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': \"Toggles debug mode. Debug mode 'on' persists logs to the RDU host to help diagnose certain issues during training.\",\n",
       "   'FIELD_NAME': 'debug_mode',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': 'off'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'whether or not to do final evaluation',\n",
       "   'FIELD_NAME': 'do_eval',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': 'false'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Dump input to a file for debugging purposes. Creates several MB of data per step and slows down training; should only be used if requested by Sambanova to collect debug information.',\n",
       "   'FIELD_NAME': 'dump_inputs',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': 'false'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': \"Period of evaluating the model in number of training steps. This parameter is only effective when evaluation_strategy is set to 'steps'.\",\n",
       "   'FIELD_NAME': 'eval_steps',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '50'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Strategy to validate the model during training',\n",
       "   'FIELD_NAME': 'evaluation_strategy',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': 'no'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Fix which rank is assigned to which RDU for data-parallel jobs. Used for reproducibility of a job. Should only be used with a multiple of 8 RDUs.',\n",
       "   'FIELD_NAME': 'fix_rank_rdu_mapping',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': 'false'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'How many steps you want to accumulate before updating the weights. This parameter can be used to increase the effective batch size during gradient decent without exceeding the memory limit.',\n",
       "   'FIELD_NAME': 'grad_accumulation_steps',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '1'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'learning rate to use in optimizer',\n",
       "   'FIELD_NAME': 'learning_rate',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '0.00001'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Period of logging training loss in number of training steps',\n",
       "   'FIELD_NAME': 'logging_steps',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '1'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Type of learning rate scheduler to use',\n",
       "   'FIELD_NAME': 'lr_schedule',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': 'fixed_lr'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Sequence length to pad or truncate the dataset',\n",
       "   'FIELD_NAME': 'max_seq_length',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '8192'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'The number of RDUs to run in model parallel.',\n",
       "   'FIELD_NAME': 'model_parallel_rdus',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '1'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'The parameter count of the model',\n",
       "   'FIELD_NAME': 'model_parameter_count',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '8b'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'number of iterations to run',\n",
       "   'FIELD_NAME': 'num_iterations',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '100'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Loss scale for prompt tokens',\n",
       "   'FIELD_NAME': 'prompt_loss_weight',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '0'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'The mode to run with.',\n",
       "   'FIELD_NAME': 'run_mode',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': 'balanced'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Toggles safe mode. Safe mode \"on\" runs the job more conservatively from a power perspective. This causes the job to run at lower performance (i.e. fewer steps per second) in exchange for more robust operation.',\n",
       "   'FIELD_NAME': 'safe_mode',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': 'off'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Whether to save the optimizer state when saving a checkpoint',\n",
       "   'FIELD_NAME': 'save_optimizer_state',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': 'true'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Period of saving the model checkpoints in number of training steps',\n",
       "   'FIELD_NAME': 'save_steps',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '50'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'whether or not to skip the checkpoint',\n",
       "   'FIELD_NAME': 'skip_checkpoint',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': 'false'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Subsample for the evaluation dataset',\n",
       "   'FIELD_NAME': 'subsample_eval',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '0.01'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Random seed to use for the subsample evaluation',\n",
       "   'FIELD_NAME': 'subsample_eval_seed',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '123'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Whether to use token_type_ids to compute loss',\n",
       "   'FIELD_NAME': 'use_token_type_ids',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': 'true'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Maximum size of vocabulary',\n",
       "   'FIELD_NAME': 'vocab_size',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '128256'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'warmup steps to use in learning rate scheduler in optimizer',\n",
       "   'FIELD_NAME': 'warmup_steps',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '0'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'weight decay rate to use in optimizer',\n",
       "   'FIELD_NAME': 'weight_decay',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '0.1'},\n",
       "  {'DATATYPE': '',\n",
       "   'DESCRIPTION': 'Number of sockets each instance of the model uses',\n",
       "   'FIELD_NAME': 'sockets',\n",
       "   'MESSAGE': '',\n",
       "   'TASK_TYPE': [],\n",
       "   'TYPE_SPECIFIC_SETTINGS': {},\n",
       "   'CONSTRAINTS': None,\n",
       "   'VARIANT_SELECTION': False,\n",
       "   'FIELD_VALUE': '1'}],\n",
       " 'time_created': '2025-04-02T22:27:21.916740000Z',\n",
       " 'time_updated': '2025-04-02T22:37:58.411475000Z',\n",
       " 'load_state': False,\n",
       " 'app_name': 'Llama 3.1',\n",
       " 'environment_variables': '',\n",
       " 'model_id': 'd5b59dcf-84db-4f84-a1de-077b217f9b49',\n",
       " 'model_status': 'AvailableToDownload',\n",
       " 'model_version': 1,\n",
       " 'dataset': 'dummy_example',\n",
       " 'dataset_path': 'default/cap-engagements/datasets/local-dataset-a77fc17c-5a75-4e41-98f7-35f1f509bd04',\n",
       " 'tracking_id': 'ab3c4f53-ce37-4066-ac9a-e92eec67dfb6',\n",
       " 'config': {'batch_size': '8',\n",
       "  'debug_mode': 'off',\n",
       "  'do_eval': 'false',\n",
       "  'dump_inputs': 'false',\n",
       "  'eval_steps': '50',\n",
       "  'evaluation_strategy': 'no',\n",
       "  'fix_rank_rdu_mapping': 'false',\n",
       "  'grad_accumulation_steps': '1',\n",
       "  'learning_rate': '0.00001',\n",
       "  'logging_steps': '1',\n",
       "  'lr_schedule': 'fixed_lr',\n",
       "  'max_seq_length': '8192',\n",
       "  'max_sequence_length': '8192',\n",
       "  'model_parallel_rdus': '1',\n",
       "  'model_parameter_count': '8b',\n",
       "  'num_iterations': '100',\n",
       "  'prompt_loss_weight': '0',\n",
       "  'run_mode': 'balanced',\n",
       "  'safe_mode': 'off',\n",
       "  'save_optimizer_state': 'true',\n",
       "  'save_steps': '50',\n",
       "  'skip_checkpoint': 'false',\n",
       "  'sockets': '1',\n",
       "  'subsample_eval': '0.01',\n",
       "  'subsample_eval_seed': '123',\n",
       "  'use_token_type_ids': 'true',\n",
       "  'vocab_size': '128256',\n",
       "  'warmup_steps': '0',\n",
       "  'weight_decay': '0.1'}}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sambastudio_client.check_job_progress(\n",
    "    project_name=project['project_name'],\n",
    "    job_name=job['job_name'],\n",
    "    verbose=True,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promote Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 23:27:25,731 [INFO] Project with name 'e2e-draft-model-training-project' found with id 0b4bf4f5-5e29-409c-8a40-7a2e4183ec95\n",
      "2025-04-02 23:27:25,959 [INFO] Project with name 'e2e-draft-model-training-project' found with id 0b4bf4f5-5e29-409c-8a40-7a2e4183ec95\n",
      "2025-04-02 23:27:26,202 [INFO] Job with name 'e2e_draft_model_training_job' in project 'e2e-draft-model-training-project' found with id '63757c29-244e-48da-9972-dc9256edc474'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will promote the checkpoint with less training loss so we list it sorted \n",
    "checkpoints = sambastudio_client.list_checkpoints(\n",
    "    project_name=project['project_name'],\n",
    "    job_name=job['job_name'],\n",
    "    sort=True\n",
    ")\n",
    "checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Promoted checkpoint config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# set checkpoint to promote config\u001b[39;00m\n\u001b[32m      2\u001b[39m model_checkpoint = {\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcheckpoint_name\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mcheckpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mSuzume-Llama-3-8B-Multilingual-Publichealth\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel_description\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mfinetuned suzume multilingual in public health qa dataset\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mfinetuned\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m }\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# set checkpoint to promote config\n",
    "model_checkpoint = {\n",
    "    'checkpoint_name': checkpoints[0]['name'],\n",
    "    'model_name': 'Suzume-Llama-3-8B-Multilingual-Publichealth',\n",
    "    'model_description': 'finetuned suzume multilingual in public health qa dataset',\n",
    "    'model_type': 'finetuned'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:03:51,838 [INFO] Project with name 'byoc fine-tuning project' found with id b11867e6-7ca8-45bd-b09b-41cbc7ba73ce\n",
      "2024-11-25 16:03:52,088 [INFO] Project with name 'byoc fine-tuning project' found with id b11867e6-7ca8-45bd-b09b-41cbc7ba73ce\n",
      "2024-11-25 16:03:52,329 [INFO] Job with name 'e2e_fc_taining_job' in project 'byoc fine-tuning project' found with id '1819ba81-9f93-4197-a7c3-51df6a3f8f0e'\n",
      "2024-11-25 16:03:53,245 [INFO] Model checkpoint '1819ba81-9f93-4197-a7c3-51df6a3f8f0e-10' promoted to model 'Suzume-Llama-3-8B-Multilingual-Publichealth'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c867b392-2d02-453d-9fd8-e14016e39153'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the promote_checkpoint method from client with checkpoint parameters\n",
    "sambastudio_client.promote_checkpoint(\n",
    "    checkpoint_name = model_checkpoint['name'],\n",
    "    project_name=project['project_name'],\n",
    "    job_name=job['job_name'],\n",
    "    model_name=model_checkpoint['model_name'],\n",
    "    model_description=model_checkpoint['model_description'],\n",
    "    model_type=model_checkpoint['model_type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_id': 'c867b392-2d02-453d-9fd8-e14016e39153',\n",
       "  'model_checkpoint_name': 'Suzume-Llama-3-8B-Multilingual-Publichealth',\n",
       "  'version': 1}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the promoted model is now in SambaStudio models\n",
    "[model for model in sambastudio_client.list_models() if model['model_checkpoint_name']==model_checkpoint['model_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all saved training checkpoints, after promotion (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:06:20,296 [INFO] Model checkpoint '1819ba81-9f93-4197-a7c3-51df6a3f8f0e-10' deleted\n",
      "2024-11-25 16:06:20,586 [INFO] Model checkpoint '1819ba81-9f93-4197-a7c3-51df6a3f8f0e-5' deleted\n"
     ]
    }
   ],
   "source": [
    "# We can delete all intermediate checkpoints saved during the training job \n",
    "for checkpoint in checkpoints:\n",
    "    sambastudio_client.delete_checkpoint(checkpoint[\"name\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
