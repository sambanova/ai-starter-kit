{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Draft Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "import yaml\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir =  os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from utils.fine_tuning.src.snsdk_wrapper import SnsdkWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by Step / Manual setting\n",
    "\n",
    "First instantiate the SambaStudio client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sambastudio_client = SnsdkWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data generation config\n",
    "config_draft_model_training_yaml = '../05_config_draft_model_training.yaml'\n",
    "\n",
    "# Open and load the YAML file into a dictionary\n",
    "with open(config_draft_model_training_yaml, 'r') as file:\n",
    "    config_draft_model_training = yaml.safe_load(file)\n",
    "pprint('Draft model training:')\n",
    "pprint(config_draft_model_training)\n",
    "\n",
    "model_name = config_draft_model_training['model_checkpoint']['model_name']\n",
    "dataset_name = config_draft_model_training['dataset']['dataset_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = [model[\"model_checkpoint_name\"]for model in sambastudio_client.list_models(filter_job_types=[\"train\"])]\n",
    "\n",
    "assert model_name in available_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dataset_name in [dataset[\"dataset_name\"] for dataset in sambastudio_client.list_datasets()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Project configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = {\n",
    "    'project_name': config_draft_model_training['project']['project_name'],\n",
    "    'project_description': config_draft_model_training['project']['project_description']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the create project method from client with project parameters\n",
    "sambastudio_client.create_project(\n",
    "    project_name = project['project_name'],\n",
    "    project_description = project['project_description']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set train job config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check required hyperparams for training job \n",
    "hyperparams = sambastudio_client.get_default_hyperparms(model,'train')\n",
    "pprint(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = {\n",
    "    'job_name': 'e2e_draft_model_training_job',\n",
    "    'job_description': 'Training job description.',\n",
    "    'job_type': 'train',\n",
    "    'model': model_name,\n",
    "    'model_version': '1',\n",
    "    'parallel_instances': '1',\n",
    "    'dataset_name': dataset_name,\n",
    "    'load_state': False,\n",
    "    'sub_path': '',\n",
    "    'hyperparams': {\n",
    "        \"batch_size\": 8,\n",
    "        \"do_eval\": False,\n",
    "        \"eval_steps\":50,\n",
    "        \"evaluation_strategy\": \"no\",\n",
    "        \"learning_rate\": 0.00001,\n",
    "        \"logging_steps\": 1,\n",
    "        \"lr_schedule\": \"fixed_lr\",\n",
    "        \"max_sequence_length\": 8192,\n",
    "        \"num_iterations\": 100,\n",
    "        \"prompt_loss_weight\": 0.0,\n",
    "        \"save_optimizer_state\": True,\n",
    "        \"save_steps\": 50,\n",
    "        \"skip_checkpoint\": False,\n",
    "        \"subsample_eval\": 0.01,\n",
    "        \"subsample_eval_seed\": 123,\n",
    "        \"use_token_type_ids\": True,\n",
    "        \"vocab_size\": 128256,\n",
    "        \"warmup_steps\": 0,\n",
    "        \"weight_decay\": 0.1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sambastudio_client.run_training_job(\n",
    "    project_name = project[\"project_name\"],\n",
    "    job_name = job['job_name'],\n",
    "    job_description = job['job_description'],\n",
    "    job_type = job['job_type'],\n",
    "    model = job['model'],\n",
    "    model_version = job['model_version'],\n",
    "    dataset_name = job['dataset_name'],\n",
    "    parallel_instances = job['parallel_instances'],\n",
    "    load_state = job['load_state'],\n",
    "    sub_path = job['sub_path'],\n",
    "    rdu_arch = 'SN40L-8',\n",
    "    hyperparams = job['hyperparams']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sambastudio_client.check_job_progress(\n",
    "    project_name=project['project_name'],\n",
    "    job_name=job['job_name'],\n",
    "    verbose=True,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promote Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will promote the checkpoint with less training loss so we list it sorted \n",
    "checkpoints = sambastudio_client.list_checkpoints(\n",
    "    project_name=project['project_name'],\n",
    "    job_name=job['job_name'],\n",
    "    sort=True\n",
    ")\n",
    "checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Promoted checkpoint config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint to promote config\n",
    "model_checkpoint = {\n",
    "    'checkpoint_name': checkpoints[0]['name'],\n",
    "    'model_name': 'Suzume-Llama-3-8B-Multilingual-Publichealth',\n",
    "    'model_description': 'finetuned suzume multilingual in public health qa dataset',\n",
    "    'model_type': 'finetuned'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the promote_checkpoint method from client with checkpoint parameters\n",
    "sambastudio_client.promote_checkpoint(\n",
    "    checkpoint_name = model_checkpoint['name'],\n",
    "    project_name=project['project_name'],\n",
    "    job_name=job['job_name'],\n",
    "    model_name=model_checkpoint['model_name'],\n",
    "    model_description=model_checkpoint['model_description'],\n",
    "    model_type=model_checkpoint['model_type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the promoted model is now in SambaStudio models\n",
    "[model for model in sambastudio_client.list_models() if model['model_checkpoint_name']==model_checkpoint['model_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all saved training checkpoints, after promotion (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can delete all intermediate checkpoints saved during the training job \n",
    "for checkpoint in checkpoints:\n",
    "    sambastudio_client.delete_checkpoint(checkpoint[\"name\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
