# target:
#   sambastudio:
#    snapi_path: ""
#    rdu_arch: "SN40L-8"

#   checkpoints:
#     - model_name: "Llama3-OpenBioLLM-8B"
#       checkpoint_path: '/Users/francescar/Documents/ai-starter-kit/e2e_draft_model_training/data/models/models--aaditya--Llama3-OpenBioLLM-8B/snapshots/70d6bb521cab6ca755b675ade38831eedf89d31c'
#       publisher: "aaditya"
#       description: "OpenBioLLM-8B is an advanced open source language model designed specifically for the biomedical domain."
#       param_count: 8
#       model_arch: "llama" 
#       seq_length: 8192 
#       vocab_size: 128256 
#       app_id: "61fa0993-04a2-42ca-9db1-1eff693ea978"

target:
  sambastudio:
  snapi_path: ""
  rdu_arch: "SN40L-8"

  checkpoints:
    - model_name: "Llama3-OpenBioLLM-8B"
      checkpoint_path: '/Users/francescar/Documents/ai-starter-kit/e2e_draft_model_training/data/models/models--aaditya--Llama3-OpenBioLLM-8B/snapshots/70d6bb521cab6ca755b675ade38831eedf89d31c'
      publisher: "aaditya"
      description: "OpenBioLLM-8B is an advanced open source language model designed specifically for the biomedical domain."
      param_count: 8
      model_arch: "llama" 
      seq_length: 8192 
      vocab_size: 128256 
      app_id: "61fa0993-04a2-42ca-9db1-1eff693ea978"

# draft:
#   sambastudio:
#    snapi_path: ""
#    rdu_arch: "SN40L-8"

#   checkpoints:
#     - model_name: "Llama-3.2-3B-Instruct"
#       checkpoint_path: '/Users/francescar/Documents/ai-starter-kit/e2e_draft_model_training/data/models/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95'
#       publisher: "meta-llama"
#       description: "The `Llama 3.2` collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out)."
#       param_count: 3
#       model_arch: "llama" 
#       seq_length: 131072 
#       vocab_size: 128256 
#       app_id: "49683c7f-3e42-4217-96dd-6f975d17c393"

draft:
  sambastudio:
    snapi_path: ""
    rdu_arch: "SN40L-8"

  checkpoints:
    - model_name: "Llama-3.2-3B-Instruct"
      checkpoint_path: '/Users/francescar/Documents/ai-starter-kit/e2e_draft_model_training/data/models/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95'
      publisher: "meta-llama"
      description: "The `Llama 3.2` collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out)."
      param_count: 3
      model_arch: "llama" 
      seq_length: 131072 
      vocab_size: 128256 
      app_id: "49683c7f-3e42-4217-96dd-6f975d17c393"

target_inference:
  sambastudio:
    snapi_path: ""
    rdu_arch: "SN40L-8"

  project:
    project_name: "byoc-fine-tuning-project"
    project_description: "this project will be used to test the BYOC and Fine-tuning e2e pipeline implementation"

  composite_model:
    model_name:  "Suzume-Llama-3-8B-Multilingual-Bundle"
    description: "Bundle including base and public health fine-tuned Suzume-Llama-3-8B-Multilingual"
    rdu_required: 8
    model_version: '1'
    model_list:
      - "Suzume-Llama-3-8B-Multilingual"
      - "Suzume-Llama-3-8B-Multilingual-Publichealth"

  endpoint:
    endpoint_name: "suzume-multilingual-endpoint"
    endpoint_description: "endpoint for suzume multilingual bundle"
    endpoint_instances: 1
    hyperparams: null

dataset_train:
  sambastudio:
    snapi_path: ""
    rdu_arch: "SN40L-8"

  dataset:
    dataset_name: "publichealth"
    dataset_description: "This dataset contains question and answer pairs sourced from Q&A pages and FAQs from CDC and WHO pertaining to COVID-19"
    dataset_path: "/Users/my_user/Documents/ai-starter-kit/e2e_fine_tuning/data/datasets/fine_tuning-publichealth-qa"
    dataset_apps_availability: 
      - 'Llama 3'
      - 'Samba1 Llama3 Experts'
      - 'Samba1 Llama3.1 Experts'
      - 'Samba1 Llama3.2 Experts'
    dataset_job_types:
      - "evaluation"
      - "train"
    dataset_source_type: "localMachine"
    dataset_language: "english"
    dataset_filetype: "hdf5"
    dataset_url: "https://huggingface.co/datasets/xhluca/publichealth-qa"
    dataset_metadata:
      labels_file: ""
      train_filepath: ""
      validation_filepath: ""
      test_filepath: ""

draft_model_training:
  sambastudio:
    snapi_path: ""
    rdu_arch: "SN40L-8"

  project:
    project_name: "byoc-fine-tuning-project"
    project_description: "this project will be used to test the BYOC and Fine-tuning e2e pipeline implementation"

  job:
    job_name: "e2e_fc_taining_job"
    job_description: "e2e finetuning training job public health for suzume multilingual"
    job_type: "train"
    model: "Suzume-Llama-3-8B-Multilingual"
    model_version: "1"
    dataset_name: "publichealth"
    parallel_instances: 1
    load_state: false
    sub_path: ""
    hyperparams:
      batch_size: 8
      do_eval: false
      eval_steps: 5
      evaluation_strategy: "no"
      learning_rate: 0.00001
      logging_steps: 1
      lr_schedule: "fixed_lr"
      max_sequence_length: 8192
      num_iterations: 10
      prompt_loss_weight: 0.0
      save_optimizer_state: True
      save_steps: 5
      skip_checkpoint: False
      subsample_eval: 0.01
      subsample_eval_seed: 123
      use_token_type_ids: true
      vocab_size: 128256
      warmup_steps: 0
      weight_decay: 0.1

  model_checkpoint: 
    checkpoint_name: "" #set after listing the generated checkpoints after training
    model_name: "Suzume-Llama-3-8B-Multilingual-Publichealth"
    model_description: "finetuned suzume multilingual in public health qa dataset"
    model_type: "finetuned"