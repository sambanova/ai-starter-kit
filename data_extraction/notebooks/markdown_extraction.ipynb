{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows examples of text extraction from MD files with different packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Methods to load MD files](#toc1_)    \n",
    "  - 1.1. [Load from unstructured local MD loader](#toc1_1_)    \n",
    "  - 1.2. [Load from unstructured io API](#toc1_2_)    \n",
    "- 2. [Evaluate loded docs by embedding similarity](#toc2_)    \n",
    "  - 2.1. [Embedding & Storage](#toc2_1_)    \n",
    "  - 2.2. [Similarity search](#toc2_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=4\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p4/y0q2kh796nx_k_yzfhxs57f00000gp/T/ipykernel_18417/1196758776.py:15: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, \"..\"))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_classic.text_splitter import MarkdownHeaderTextSplitter\n",
    "from tqdm.autonotebook import trange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id='toc1_'></a>[Methods to load MD files](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_loc = kit_dir\n",
    "md_files = list(glob.glob(f'{folder_loc}/*.md'))\n",
    "file_path = md_files[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. <a id='toc1_1_'></a>[Load from unstructured local MD loader](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SambaNova AI Starter Kits\n",
      "---\n",
      "Data Extraction Examples\n",
      "---\n",
      "Data Extraction Examples\n",
      "Overview\n",
      "Getting started\n",
      "Deploy in vitual environment\n",
      "Deploy in Docker container\n",
      "\n",
      "\n",
      "File Loaders\n",
      "CSV Documents\n",
      "XLS/XLSX Documents\n",
      "DOC/DOCX Documents\n",
      "RTF Documents\n",
      "Markdown Documents\n",
      "HTML Documents\n",
      "Multidocument\n",
      "PDF Documents\n",
      "Included Files\n",
      "---\n",
      "Overview\n",
      "---\n",
      "This kit include a series of Notebooks that demonstrates various methods for extracting text from documents in different input formats. including Markdown, PDF, CSV, RTF, DOCX, XLS, HTML\n",
      "---\n",
      "Getting started\n",
      "---\n",
      "Deploy the starter kit\n",
      "---\n",
      "Option 1: Run through local virtual environment\n",
      "---\n",
      "Important: With this option some funcionalities requires to install some pakges directly in your system\n",
      "- pandoc (for local rtf files loading)\n",
      "- tesseract-ocr (for PDF ocr and table extraction)\n",
      "- poppler-utils (for PDF ocr and table extraction)\n",
      "---\n",
      "Clone repo.\n",
      "git clone https://github.sambanovasystems.com/SambaNova/ai-starter-kit.git\n",
      "2.1 Install requirements: It is recommended to use virtualenv or conda environment for installation.\n",
      "cd ai-starter-kit\n",
      "python3 -m venv data_extract_env\n",
      "source data_extract_env/bin/activate\n",
      "cd data_extraction\n",
      "pip install -r requirements.txt\n",
      "2.2 Install requirements for paddle utility: ,It is recommended to use virtualenv or conda environment for installation.\n",
      "Use this in case you want to use Paddle OCR recipe for PDF OCR and table extraction you shold use the requirementsPaddle file instead\n",
      "cd ai-starter-kit\n",
      "python3 -m venv data_extract_env\n",
      "source data_extract_env/bin/activate\n",
      "cd data_extraction\n",
      "pip install -r requirementsPaddle.txt\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "loader = UnstructuredMarkdownLoader(file_path, mode=\"elements\")\n",
    "docs_unstructured_local = loader.load()\n",
    "for doc in docs_unstructured_local[:10]:\n",
    "    print(f'{doc.page_content}\\n---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. <a id='toc1_2_'></a>[Load from unstructured io API](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SambaNova AI Starter Kits\n",
      "---\n",
      "Data Extraction Examples\n",
      "---\n",
      "Data Extraction Examples\n",
      "Overview\n",
      "Getting started\n",
      "Deploy in vitual environment\n",
      "Deploy in Docker container\n",
      "\n",
      "\n",
      "File Loaders\n",
      "CSV Documents\n",
      "XLS/XLSX Documents\n",
      "DOC/DOCX Documents\n",
      "RTF Documents\n",
      "Markdown Documents\n",
      "HTML Documents\n",
      "Multidocument\n",
      "PDF Documents\n",
      "Included Files\n",
      "---\n",
      "Overview\n",
      "---\n",
      "This kit include a series of Notebooks that demonstrates various methods for extracting text from documents in different input formats. including Markdown, PDF, CSV, RTF, DOCX, XLS, HTML\n",
      "---\n",
      "Getting started\n",
      "---\n",
      "Deploy the starter kit\n",
      "---\n",
      "Option 1: Run through local virtual environment\n",
      "---\n",
      "Important: With this option some funcionalities requires to install some pakges directly in your system\n",
      "- pandoc (for local rtf files loading)\n",
      "- tesseract-ocr (for PDF ocr and table extraction)\n",
      "- poppler-utils (for PDF ocr and table extraction)\n",
      "---\n",
      "Clone repo.\n",
      "git clone https://github.sambanovasystems.com/SambaNova/ai-starter-kit.git\n",
      "2.1 Install requirements: It is recommended to use virtualenv or conda environment for installation.\n",
      "cd ai-starter-kit\n",
      "python3 -m venv data_extract_env\n",
      "source data_extract_env/bin/activate\n",
      "cd data_extraction\n",
      "pip install -r requirements.txt\n",
      "2.2 Install requirements for paddle utility: ,It is recommended to use virtualenv or conda environment for installation.\n",
      "Use this in case you want to use Paddle OCR recipe for PDF OCR and table extraction you shold use the requirementsPaddle file instead\n",
      "cd ai-starter-kit\n",
      "python3 -m venv data_extract_env\n",
      "source data_extract_env/bin/activate\n",
      "cd data_extraction\n",
      "pip install -r requirementsPaddle.txt\n",
      "---\n",
      "Some text extraction examples use Unstructured lib. Please register at Unstructured.io to get a free API Key. then create an enviroment file to store the APIkey and URL provided.\n",
      "echo 'UNSTRUCTURED_API_KEY=\"your_API_key_here\"\\nUNSTRUCTURED_API_KEY=\"your_API_url_here\"' > export.env\n",
      "---\n",
      "Option 2: Run via Docker\n",
      "---\n",
      "With this option all funcionalities and notebook are ready to use\n",
      "---\n",
      "You need to have the Docker engine installed Docker installation\n",
      "---\n",
      "Clone repo.\n",
      "git clone https://github.sambanovasystems.com/SambaNova/ai-starter-kit.git\n",
      "---\n",
      "Some text extraction examples use Unstructured lib. Please register at Unstructured.io to get a free API Key. then create an enviroment file to store the APIkey and URL provided.\n",
      "echo 'UNSTRUCTURED_API_KEY=\"your_API_key_here\"\\nUNSTRUCTURED_API_KEY=\"your_API_url_here\"' > export.env\n",
      "3.1 Run data extraction docker container\n",
      "sudo docker-compose up data_extraction_service\n",
      "3.2 Run data extraction docker container for Paddle utility\n",
      "Use this in case you want to use Paddle OCR recipe for PDF OCR and table extraction you shold use the startPaddle script instead\n",
      "sudo docker-compose up data_extraction_paddle_service\n",
      "---\n",
      "File loaders\n",
      "---\n",
      "You will find several data extraction recipes and pipelines in the notebooks folder as follows:\n",
      "---\n",
      "CSV Documents\n",
      "---\n",
      "csv_extraction.ipynb: This notebook provides examples of text extraction from CSV files using different packages. Depending on your specific use case, some packages may perform better than others.\n",
      "---\n",
      "unstructured_extraction.ipynb: This notebook provides examples of text extraction from files in different input format using Unstructured lib. Section 1 includes two loading examples first one using unstructured API and the other using local unstructured loader\n",
      "---\n",
      "XLS/XLSX Documents\n",
      "---\n",
      "unstructured_extraction.ipynb: This notebook provides examples of text extraction from files in different input format using Unstructured lib. Section 2 includes two loading examples first one using unstructured API and the other using local unstructured loader\n",
      "---\n",
      "DOC/DOCX Documents\n",
      "---\n",
      "unstructured_extraction.ipynb: This notebook provides examples of text extraction from files in different input format using Unstructured lib. Section 3 includes two loading examples first one using unstructured API and the other using local unstructured loader\n",
      "---\n",
      "RTF Documents\n",
      "---\n",
      "unstructured_extraction.ipynb: This notebook provides examples of text extraction from files in different input format using Unstructured lib. Section 4 includes two loading examples first one using unstructured API and the other using local unstructured loader\n",
      "---\n",
      "Markdown Documents\n",
      "---\n",
      "unstructured_extraction.ipynb: This notebook provides examples of text extraction from files in different input format using Unstructured lib. Section 5 includes two loading examples first one using unstructured API and the other using local unstructured loader\n",
      "---\n",
      "HTML Documents\n",
      "---\n",
      "unstructured_extraction.ipynb: This notebook provides examples of text extraction from files in different input format using Unstructured lib. Section 6 includes two loading examples first one using unstructured API and the other using local unstructured loader\n",
      "---\n",
      "PDF Documents\n",
      "---\n",
      "pdf_extraction_non_OCR.ipynb: This notebook provides examples of text extraction from PDF documents using different packages. Depending on your specific use case, some packages may perform better than others.\n",
      "---\n",
      "pdf_extraction_ocr_tables.ipynb: This notebook provides examples of text and tables extraction from PDF documents using different OCR packages. Depending on your specific use case, some packages may perform better than others. It also provides an example of a simple RAG retiever an an example of a multivector RAG retriever. For SambaNova model endpoint usage refer here\n",
      "---\n",
      "qa_qc_util.ipynb: This notebook offers a simple utility for visualizing text boxes extracted using the PyMuPDF or Fitz package. This visualization can be particularly helpful when dealing with complex multi-column PDF documents, aiding in the debugging process.\n",
      "---\n",
      "unstructured_extraction.ipynb: This notebook provides examples of text extraction from files in different input format using Unstructured lib. Section 7 includes two loading examples first one using unstructured API and the other using local unstructured loader\n",
      "---\n",
      "Multidocument\n",
      "---\n",
      "multidocs_extraction.ipynb: This notebook provides examples of text extraction from multiple docs using Unstructured.io as file loader. The input format could be a mixed of formats.\n",
      "---\n",
      "Included files\n",
      "---\n",
      "data: Contains sample data for running the notebooks, and is used as storage for intermediate steps for recipes.\n",
      "---\n",
      "src: contains the source code for some functionalities used in the notebooks.\n",
      "---\n",
      "docker: contains Dockerfile for data extraction starter kit\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.document_loaders import UnstructuredAPIFileLoader\n",
    "# register at Unstructured.io to get a free API Key\n",
    "load_dotenv(os.path.join(repo_dir,'.env'))\n",
    "\n",
    "loader = UnstructuredAPIFileLoader(file_path,\n",
    "                                   mode=\"elements\",\n",
    "                                   api_key=os.environ.get('UNSTRUCTURED_API_KEY'),\n",
    "                                   url=os.environ.get(\"UNSTRUCTURED_URL\"))\n",
    "docs_unstructured_api = loader.load()\n",
    "for doc in docs_unstructured_api:\n",
    "    print(f'{doc.page_content}\\n---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[Evaluate loded docs by embedding similarity](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. <a id='toc2_1_'></a>[Embedding & Storage](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain_classic.vectorstores import FAISS\n",
    "\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embd_model = HuggingFaceInstructEmbeddings( model_name='intfloat/e5-large-v2',\n",
    "                                            embed_instruction=\"\", # no instructions needed for candidate passages\n",
    "                                            query_instruction=\"Represent this sentence for searching relevant passages: \",\n",
    "                                            encode_kwargs=encode_kwargs)\n",
    "vectorstore_unstructured_local = FAISS.from_documents(documents=docs_unstructured_local, embedding=embd_model)\n",
    "vectorstore_unstructured_api = FAISS.from_documents(documents=docs_unstructured_api, embedding=embd_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. <a id='toc2_2_'></a>[Similarity search](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Unstructured local Loader----------\n",
      "\n",
      "Clone repo.\n",
      "git clone https://github.sambanovasystems.com/SambaNova/ai-starter-kit.git\n",
      "--------Unstructured api loader------------\n",
      "\n",
      "Clone repo.\n",
      "git clone https://github.sambanovasystems.com/SambaNova/ai-starter-kit.git\n"
     ]
    }
   ],
   "source": [
    "query = \"how I clone the repo?\"\n",
    "\n",
    "ans = vectorstore_unstructured_local.similarity_search(query)\n",
    "print(\"-------Unstructured local Loader----------\\n\")\n",
    "print(ans[0].page_content)\n",
    "\n",
    "\n",
    "ans_2 = vectorstore_unstructured_api.similarity_search(query)\n",
    "print(\"--------Unstructured api loader------------\\n\")\n",
    "print(ans_2[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c141c502b4874f6f7cd85d57d9f08ebe5bc7ea264c7dc3d59361b279d0075653"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
