{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/feiwu/Documents/ai-starter-kit-personal/ai-starter-kit/routing/routing_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/feiwu/Documents/ai-starter-kit-personal/ai-starter-kit/routing/routing_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/feiwu/Documents/ai-starter-kit-personal/ai-starter-kit/routing/routing_env/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_API_KEY is not set. Weave initialization skipped.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, \"..\"))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from src.routing import Router\n",
    "from enterprise_knowledge_retriever.src.document_retrieval import DocumentRetrieval\n",
    "\n",
    "CONFIG_PATH = os.path.join(kit_dir,'config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "router = Router(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 14:30:40,557 [INFO] - Load pretrained SentenceTransformer: intfloat/e5-large-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/feiwu/Documents/ai-starter-kit-personal/ai-starter-kit/routing/routing_env/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-09-06 14:30:42,700 [INFO] - Use pytorch device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n",
      "Loading collection name is None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 14:30:42,934 [INFO] - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "document_retrieval =  DocumentRetrieval()\n",
    "embeddings = document_retrieval.load_embedding_model()\n",
    "# print(os.path.join(kit_dir, \"data/800_20\"))\n",
    "vectorstore = document_retrieval.load_vdb(db_path = os.path.join(kit_dir, \"data/800_20\"), embeddings=embeddings)\n",
    "document_retrieval.init_retriever(vectorstore)\n",
    "conversation = document_retrieval.get_qa_retrieval_chain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"How to measure performance using sambatune?\"\n",
    "# query = \"Who is the CEO of Sambanova?\"\n",
    "query = \"What is LLM?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/feiwu/Documents/ai-starter-kit-personal/ai-starter-kit/routing/routing_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM can refer to several things, but I'll cover the most common meanings:\n",
      "\n",
      "1. **Large Language Model**: In natural language processing (NLP), a Large Language Model (LLM) is a type of artificial intelligence (AI) model that is trained on a massive corpus of text data to generate human-like language. These models are designed to understand and generate text, and they can be used for a wide range of applications, such as language translation, text summarization, and chatbots.\n",
      "2. **Law Library of Congress**: The Law Library of Congress (LLM) is a research library that provides access to legal information and resources for the U.S. Congress and the public. It is part of the Library of Congress and is one of the largest and most comprehensive law libraries in the world.\n",
      "3. **Language Learning Method**: In language education, LLM can refer to a Language Learning Method, which is a systematic approach to learning a language. This can include various techniques, such as immersion, language exchange, and language learning software.\n",
      "4. **LLM (Legal Liability Management)**: In the context of business and finance, LLM can refer to a risk management strategy that involves identifying and mitigating potential legal liabilities.\n",
      "\n",
      "Without more context, it's difficult to determine which meaning is most relevant. If you have any additional information or clarification, I'd be happy to try and provide a more specific answer!\n"
     ]
    }
   ],
   "source": [
    "datasource = router.routing(query)\n",
    "if datasource == \"vectorstore\":\n",
    "    output = conversation.invoke({\"question\":query})\n",
    "    response = output['answer']\n",
    "else:\n",
    "    response = document_retrieval.llm(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# response router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerouting to Vectorstore\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"dict\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# send the query to the vectorstore instead\u001b[39;00m\n\u001b[1;32m     13\u001b[0m revised_answer \u001b[38;5;241m=\u001b[39m conversation\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m:query})\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnswer: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrevised_answer\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"dict\") to str"
     ]
    }
   ],
   "source": [
    "router.init_response_router()\n",
    "reroute = router.check_response(query, response, datasource)\n",
    "if reroute == \"true\" and datasource == \"vectorstore\":\n",
    "    print(\"Rerouting to LLM\")\n",
    "    # send the query to the llm instead\n",
    "    revised_answer = document_retrieval.llm(query)\n",
    "    # printing the new answer\n",
    "    print(\"Answer: \" + \"\\n\" + revised_answer)\n",
    "\n",
    "elif reroute == \"true\" and datasource == \"llm\":\n",
    "    print(\"Rerouting to Vectorstore\")\n",
    "    # send the query to the vectorstore instead\n",
    "    revised_answer = conversation.invoke({\"question\":query})\n",
    "    print(\"Answer: \" + \"\\n\" + revised_answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is LLM?',\n",
       " 'answer': 'According to the provided context, Large Language Models (LLMs) are a type of foundation model specifically focused on language, which enables them to generate an understanding of the context of language and generate new language content. They are an emerging type of transformer model that can deliver a high degree of accuracy across dozens of different tasks, including text generation, classification, question answering, sentiment analysis, and entailment.',\n",
       " 'source_documents': [Document(metadata={'source': 'blog_enabling-open-source-llms-to-become-effective-tool-manipulators.txt'}, page_content='# Enabling Open Source LLMs to Become Effective Tool Manipulators\\n\\n#### **Introduction**'),\n",
       "  Document(metadata={'source': 'blog_achieving-gpt-175b-level-accuracy-with-a-10x-more-efficient-model.txt'}, page_content='To explore new tasks, in-context learning is a powerful technique. It allows\\nrapid prototyping to determine whether LLMs can be deployed for your\\nparticular use case. Under this setting, we show how the same accuracy can be\\nachieved as the 175B model from OpenAI using a much smaller SambaNova GPT 13B\\nmodel.\\n\\nWe use 15 benchmarks that are available in standard LLM evaluation suites.\\nThese include text generation, classification, question answering, sentiment\\nanalysis, and entailment. All are essential for powering a variety of real\\nworld use cases, and showcase how our services provide a clear benefit. The\\nnames of these benchmarks can be found in Figure 1.'),\n",
       "  Document(metadata={'source': 'blog_generative-ai-terms.txt'}, page_content='**2\\\\. Generative AI:** AI models that are able to generate new content, such\\nas new language or images, after being trained on very large amounts of data,\\noften referred to as ‘web-scale’ or ‘internet-scale’ _(similar to foundation\\nmodels in #1 above)_. These models are also known for being able to interact\\nwith and understand users through natural language interfaces ‘prompts’. _(see\\n#12 below)_\\n\\n**3\\\\. Large Language Models (LLMs):** LLMs are a type of foundation model\\nspecifically focused on language. Because of their scale, they are able to\\ngenerate an understanding of the context of language, enabling impressive\\nversatility as well as the ability to generate new language content. _(see #1\\nand #2 above)_'),\n",
       "  Document(metadata={'source': 'blog_foundation-models-are-accelerating-scientific-research.txt'}, page_content='Large Language Models (LLMs) have been one of the most exciting areas of AI\\ninnovation over the past several years. LLMs are an emerging type of\\ntransformer model that can deliver a high degree of accuracy across dozens of\\ndifferent tasks. LLMs are able to achieve this versatility by not just\\nprocessing language data, but by developing an understanding of language\\nstructure and context. However, this approach to understanding the structure\\nand context of data isn’t limited to just language data - it can be applied to\\nmultiple different scientific domains. There are many areas of research that\\ncan benefit from this application of this methodology. SambaNova’s world\\nrecord performance for large language models is enabling leading research'),\n",
       "  Document(metadata={'source': 'blog_achieving-best-in-class-large-language-model-accuracy-in-low-resource-settings.txt'}, page_content='# Achieving Best-in-Class Large Language Model Accuracy in Low-Resource\\nSettings\\n\\n**The opportunity: solving a range of language tasks using large language\\nmodels with zero and few-shot learning**\\n\\nRecent advances in AI have allowed large language models (LLMs) to deliver\\nvery impressive capabilities with zero-shot and few-shot learning. These\\napproaches enable impressive versatility, giving LLMs the potential to\\ntransform every aspect of an enterprise. As a result we see a race in the LLM\\nspace to compete on and improve the zero-shot and few-shot accuracies across a\\nwide variety of tasks to deliver value.\\n\\n**The challenge: achieving consistent accuracy with zero-shot and few-shot\\nlearning**')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revised_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
