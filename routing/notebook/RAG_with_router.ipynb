{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from IPython.display import display, Markdown\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, \"..\"))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from src.routing import Router\n",
    "from enterprise_knowledge_retriever.src.document_retrieval import DocumentRetrieval\n",
    "\n",
    "CONFIG_PATH = os.path.join(kit_dir,'config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "router = Router(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 16:13:33,100 [INFO] - Load pretrained SentenceTransformer: intfloat/e5-large-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 16:13:37,244 [INFO] - Use pytorch device: cpu\n",
      "2024-09-23 16:13:37,245 [INFO] - This is the collection name: collection_b069af78-72b2-4bfb-af70-cc80159b693f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n",
      "Collection name is None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 16:13:39,275 [INFO] - Vector store saved to data/vectordb/\n"
     ]
    }
   ],
   "source": [
    "folder_loc = os.path.join(kit_dir,'data/')\n",
    "docx_files = list(glob.glob(f'{folder_loc}/*.txt'))\n",
    "docs = []\n",
    "for doc in docx_files:\n",
    "    with open(doc) as f:\n",
    "        docs.append(f.read())\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 800,\n",
    "        chunk_overlap  = 20,\n",
    "        length_function = len,\n",
    "        add_start_index = True,\n",
    "        separators = [\"\\n\\n\\n\",\"\\n\\n\", \"\\n\", \"*\", \".\"]\n",
    "    )\n",
    "text_chunks = text_splitter.create_documents(docs)\n",
    "document_retrieval =  DocumentRetrieval()\n",
    "embeddings = document_retrieval.load_embedding_model()\n",
    "vectorstore = document_retrieval.create_vector_store(text_chunks, embeddings, output_db=\"data/vectordb/\")\n",
    "document_retrieval.init_retriever(vectorstore)\n",
    "conversation = document_retrieval.get_qa_retrieval_chain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How to use sambatune?\"\n",
    "# query = \"What is LLM?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline\n",
    "The router returns the correct datasource based on the user's query and then uses the appropriate pipeline to answer the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use SambaTune, you need to run it with the application YAML file as input. Here are the steps:\n",
      "\n",
      "1. First, run `sambatune` and pass in a YAML file for your model. You can see an example of how to do this in the \"Run the sample application\" section.\n",
      "2. Then, run the `sambatune_ui` command.\n",
      "3. Finally, you can explore the results of the SambaTune run in the SambaTune GUI.\n",
      "\n",
      "You can also run SambaTune with specific modes, such as instrument-only mode or all modes, by using the `--modes` option. For example, to run in instrument-only mode, you can use the command `sambatune --modes instrument -- /path/to/config.yaml`.\n",
      "\n",
      "You can also specify other arguments, such as `model-args`, `compile-args`, and `run-args`, to customize the run. You can see a list of all options by running `sambatune --help`.\n",
      "\n",
      "It's worth noting that you need to install the SambaTune GUI on the client system where the web browser runs, and you can get client install instructions from SambaNova customer support through the SambaNova support portal.\n",
      "--------------------------\n",
      "datasource: vectorstore\n"
     ]
    }
   ],
   "source": [
    "datasource = router.routing(query)\n",
    "if datasource == \"vectorstore\":\n",
    "    output = conversation.invoke({\"question\":query})\n",
    "    response = output['answer']\n",
    "else:\n",
    "    response = document_retrieval.llm(query)\n",
    "\n",
    "print(response)\n",
    "print(\"--------------------------\")\n",
    "print(f\"datasource: {datasource}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
