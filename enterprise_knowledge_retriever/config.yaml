llm:
    "model": "gpt-oss-120b" 
    "temperature": 0.0
    "top_p": null
    "top_k": null
    "max_tokens": 8192

embedding_model: 
    "model": "E5-Mistral-7B-Instruct"

retrieval:
    "db_type": "chroma"
    "k_retrieved_documents": 15 #set if rerank enabled 
    "score_threshold": 0.2
    "rerank": False # set if you want to rerank retriever results 
    "reranker": 'BAAI/bge-reranker-large' # set if you rerank enabled
    "final_k_retrieved_documents": 5
    "conversational": true # set to enable query rephrasing with history in streamlit application 

prompts: 
    "qa_prompt": "enterprise_knowledge_retriever/prompts/qa_prompt.yaml"
    "summary_prompt": "enterprise_knowledge_retriever/prompts/conversation-summary.yaml"
    "condensed_query_prompt": "enterprise_knowledge_retriever/prompts/multiturn_custom_condensed_query.yaml"

pdf_only_mode: True  # Set to true for PDF-only lite parsing mode (use PyMuPdf instead of Sambaparse)
prod_mode: False
